
=============
FEATURES (show 1 for each):
returns_lag_1, dir_lag_1, sma_lag_1, boll_lag_1, boll7_lag_1, boll14_lag_1, boll21_lag_1, min_lag_1, min7_lag_1, min14_lag_1, min21_lag_1, max_lag_1, max7_lag_1, max14_lag_1, max21_lag_1, mom_lag_1, mom7_lag_1, mom14_lag_1, mom21_lag_1, vol_lag_1, vol7_lag_1, vol14_lag_1, vol21_lag_1, obv_lag_1, mfi7_lag_1, mfi14_lag_1, mfi21_lag_1, rsi7_lag_1, rsi14_lag_1, rsi21_lag_1, adx7_lag_1, adx14_lag_1, adx21_lag_1, roc_lag_1, roc7_lag_1, roc14_lag_1, roc21_lag_1, atr7_lag_1, atr14_lag_1, atr21_lag_1, bop_lag_1, ad_lag_1, adosc_lag_1, trange_lag_1, ado_lag_1, willr7_lag_1, willr14_lag_1, willr21_lag_1, dx7_lag_1, dx14_lag_1, dx21_lag_1, trix_lag_1, ultosc_lag_1, high_lag_1, low_lag_1, 


>>>>>> LAP 1

==========
DATA:
Data Train: 1206, Validation: 258, Test: 260

Train:
Label 0: 418(34.66%)
Label 1: 409(33.91%)
Label 2: 379(31.43%)

Validation:
Label 0: 104(40.31%)
Label 1: 89(34.5%)
Label 2: 65(25.19%)

Test:
Label 0: 97(37.31%)
Label 1: 76(29.23%)
Label 2: 87(33.46%)

=============
PARAMS:
random_state:1
is_shuffle:True
categorical_label:True
rebalance:None
hu:2000
output_bias:[0.039903826239926485, 0.01813754975797201, -0.058041401202403496]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.76      0.70      0.73        97
           1       0.67      0.80      0.73        76
           2       0.82      0.76      0.79        87

    accuracy                           0.75       260
   macro avg       0.75      0.75      0.75       260
weighted avg       0.76      0.75      0.75       260


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       68   20    9     97  0.701  0.206  0.093
1       10   61    5     76  0.132  0.803  0.066
2       11   10   66     87  0.126  0.115  0.759
Total   89   91   80    260  0.342  0.350  0.308

>>>>>>
EVALUATION SUMMARY:
       loss     tp    fp     tn    fn  accuracy  precision  precision-0.40  \
1     1.094  194.0  63.0  457.0  66.0      0.75      0.755           0.742   
mean  1.094  194.0  63.0  457.0  66.0      0.75      0.755           0.742   
std     NaN    NaN   NaN    NaN   NaN       NaN        NaN             NaN   
min   1.094  194.0  63.0  457.0  66.0      0.75      0.755           0.742   
max   1.094  194.0  63.0  457.0  66.0      0.75      0.755           0.742   

      precision-0.45  precision-0.50  ...  recall-0.50  recall-0.55  \
1               0.75           0.755  ...        0.746        0.731   
mean            0.75           0.755  ...        0.746        0.731   
std              NaN             NaN  ...          NaN          NaN   
min             0.75           0.755  ...        0.746        0.731   
max             0.75           0.755  ...        0.746        0.731   

      recall-0.60  recall-0.65  recall-0.70  recall-0.75  recall-0.80  \
1           0.719          0.7        0.688        0.665        0.619   
mean        0.719          0.7        0.688        0.665        0.619   
std           NaN          NaN          NaN          NaN          NaN   
min         0.719          0.7        0.688        0.665        0.619   
max         0.719          0.7        0.688        0.665        0.619   

      recall-0.85  recall-0.90  recall-0.95  
1           0.592        0.562        0.496  
mean        0.592        0.562        0.496  
std           NaN          NaN          NaN  
min         0.592        0.562        0.496  
max         0.592        0.562        0.496  

[5 rows x 32 columns]
