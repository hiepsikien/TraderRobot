
======= Lap 1 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 418(34.66%)
Label 1: 409(33.91%)
Label 2: 379(31.43%)
Data validation label:
Label 0: 104(40.31%)
Label 1: 89(34.5%)
Label 2: 65(25.19%)
Data test label:
Label 0: 97(37.31%)
Label 2: 87(33.46%)
Label 1: 76(29.23%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:1
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.039903826239926485, 0.01813754975797201, -0.058041401202403496]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5353 - tp: 767.0000 - fp: 618.0000 - tn: 2314.0000 - fn: 699.0000 - accuracy: 0.7005 - precision: 0.5538 - recall: 0.5232 - auc: 0.7274 - prc: 0.5814 - val_loss: 1.1935 - val_tp: 145.0000 - val_fp: 92.0000 - val_tn: 424.0000 - val_fn: 113.0000 - val_accuracy: 0.7351 - val_precision: 0.6118 - val_recall: 0.5620 - val_auc: 0.7667 - val_prc: 0.6287 - 8s/epoch - 137ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6636 - tp: 903.0000 - fp: 264.0000 - tn: 2148.0000 - fn: 303.0000 - accuracy: 0.8433 - precision: 0.7738 - recall: 0.7488 - auc: 0.9034 - prc: 0.8312 - val_loss: 1.0918 - val_tp: 168.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 90.0000 - val_accuracy: 0.7829 - val_precision: 0.6829 - val_recall: 0.6512 - val_auc: 0.8168 - val_prc: 0.6919 - 6s/epoch - 94ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4475 - tp: 1007.0000 - fp: 167.0000 - tn: 2245.0000 - fn: 199.0000 - accuracy: 0.8988 - precision: 0.8578 - recall: 0.8350 - auc: 0.9507 - prc: 0.9154 - val_loss: 0.9998 - val_tp: 165.0000 - val_fp: 85.0000 - val_tn: 431.0000 - val_fn: 93.0000 - val_accuracy: 0.7700 - val_precision: 0.6600 - val_recall: 0.6395 - val_auc: 0.8291 - val_prc: 0.7065 - 6s/epoch - 98ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3470 - tp: 1050.0000 - fp: 139.0000 - tn: 2273.0000 - fn: 156.0000 - accuracy: 0.9185 - precision: 0.8831 - recall: 0.8706 - auc: 0.9675 - prc: 0.9416 - val_loss: 1.4800 - val_tp: 159.0000 - val_fp: 95.0000 - val_tn: 421.0000 - val_fn: 99.0000 - val_accuracy: 0.7494 - val_precision: 0.6260 - val_recall: 0.6163 - val_auc: 0.7820 - val_prc: 0.6469 - 6s/epoch - 94ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2676 - tp: 1082.0000 - fp: 113.0000 - tn: 2299.0000 - fn: 124.0000 - accuracy: 0.9345 - precision: 0.9054 - recall: 0.8972 - auc: 0.9791 - prc: 0.9618 - val_loss: 1.0712 - val_tp: 179.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 79.0000 - val_accuracy: 0.8049 - val_precision: 0.7131 - val_recall: 0.6938 - val_auc: 0.8435 - val_prc: 0.7305 - 6s/epoch - 92ms/step
Epoch 6/200
61/61 - 6s - loss: 0.1512 - tp: 1138.0000 - fp: 55.0000 - tn: 2357.0000 - fn: 68.0000 - accuracy: 0.9660 - precision: 0.9539 - recall: 0.9436 - auc: 0.9938 - prc: 0.9887 - val_loss: 0.9541 - val_tp: 182.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 76.0000 - val_accuracy: 0.8127 - val_precision: 0.7251 - val_recall: 0.7054 - val_auc: 0.8664 - val_prc: 0.7701 - 6s/epoch - 92ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1270 - tp: 1157.0000 - fp: 42.0000 - tn: 2370.0000 - fn: 49.0000 - accuracy: 0.9748 - precision: 0.9650 - recall: 0.9594 - auc: 0.9949 - prc: 0.9910 - val_loss: 0.9928 - val_tp: 181.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 77.0000 - val_accuracy: 0.8049 - val_precision: 0.7098 - val_recall: 0.7016 - val_auc: 0.8574 - val_prc: 0.7591 - 6s/epoch - 96ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1496 - tp: 1132.0000 - fp: 66.0000 - tn: 2346.0000 - fn: 74.0000 - accuracy: 0.9613 - precision: 0.9449 - recall: 0.9386 - auc: 0.9927 - prc: 0.9858 - val_loss: 1.1341 - val_tp: 171.0000 - val_fp: 79.0000 - val_tn: 437.0000 - val_fn: 87.0000 - val_accuracy: 0.7855 - val_precision: 0.6840 - val_recall: 0.6628 - val_auc: 0.8432 - val_prc: 0.7370 - 6s/epoch - 96ms/step
Epoch 9/200
61/61 - 6s - loss: 0.1100 - tp: 1160.0000 - fp: 39.0000 - tn: 2373.0000 - fn: 46.0000 - accuracy: 0.9765 - precision: 0.9675 - recall: 0.9619 - auc: 0.9959 - prc: 0.9920 - val_loss: 1.0044 - val_tp: 188.0000 - val_fp: 62.0000 - val_tn: 454.0000 - val_fn: 70.0000 - val_accuracy: 0.8295 - val_precision: 0.7520 - val_recall: 0.7287 - val_auc: 0.8659 - val_prc: 0.7646 - 6s/epoch - 98ms/step
Epoch 10/200
61/61 - 6s - loss: 0.1163 - tp: 1168.0000 - fp: 33.0000 - tn: 2379.0000 - fn: 38.0000 - accuracy: 0.9804 - precision: 0.9725 - recall: 0.9685 - auc: 0.9952 - prc: 0.9905 - val_loss: 1.1713 - val_tp: 172.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 86.0000 - val_accuracy: 0.7881 - val_precision: 0.6880 - val_recall: 0.6667 - val_auc: 0.8480 - val_prc: 0.7483 - 6s/epoch - 95ms/step
Epoch 11/200
61/61 - 6s - loss: 0.0844 - tp: 1169.0000 - fp: 33.0000 - tn: 2379.0000 - fn: 37.0000 - accuracy: 0.9807 - precision: 0.9725 - recall: 0.9693 - auc: 0.9980 - prc: 0.9962 - val_loss: 1.1067 - val_tp: 185.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 73.0000 - val_accuracy: 0.8178 - val_precision: 0.7312 - val_recall: 0.7171 - val_auc: 0.8620 - val_prc: 0.7629 - 6s/epoch - 94ms/step
Epoch 11: early stopping
9/9 [==============================] - 0s 26ms/step
13/13 [==============================] - 0s 20ms/step - loss: 1.0945 - tp: 194.0000 - fp: 63.0000 - tn: 457.0000 - fn: 66.0000 - accuracy: 0.8346 - precision: 0.7549 - recall: 0.7462 - auc: 0.8764 - prc: 0.7965

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.76      0.70      0.73        97
           1       0.67      0.80      0.73        76
           2       0.82      0.76      0.79        87

    accuracy                           0.75       260
   macro avg       0.75      0.75      0.75       260
weighted avg       0.76      0.75      0.75       260




=============
CONFUSION MATRIX:
[[68 20  9]
 [10 61  5]
 [11 10 66]]



======= Lap 2 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 447(37.06%)
Label 1: 387(32.09%)
Label 2: 372(30.85%)
Data validation label:
Label 1: 92(35.66%)
Label 0: 86(33.33%)
Label 2: 80(31.01%)
Data test label:
Label 1: 95(36.54%)
Label 0: 86(33.08%)
Label 2: 79(30.38%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:2
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.10926621052533671, -0.03486769105844862, -0.0743985298150877]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5408 - tp: 787.0000 - fp: 595.0000 - tn: 2337.0000 - fn: 679.0000 - accuracy: 0.7103 - precision: 0.5695 - recall: 0.5368 - auc: 0.7340 - prc: 0.5922 - val_loss: 0.9769 - val_tp: 160.0000 - val_fp: 87.0000 - val_tn: 429.0000 - val_fn: 98.0000 - val_accuracy: 0.7610 - val_precision: 0.6478 - val_recall: 0.6202 - val_auc: 0.8177 - val_prc: 0.7037 - 8s/epoch - 131ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6542 - tp: 887.0000 - fp: 273.0000 - tn: 2139.0000 - fn: 319.0000 - accuracy: 0.8364 - precision: 0.7647 - recall: 0.7355 - auc: 0.9083 - prc: 0.8424 - val_loss: 0.9541 - val_tp: 174.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 84.0000 - val_accuracy: 0.7972 - val_precision: 0.7045 - val_recall: 0.6744 - val_auc: 0.8551 - val_prc: 0.7573 - 6s/epoch - 92ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4368 - tp: 1015.0000 - fp: 153.0000 - tn: 2259.0000 - fn: 191.0000 - accuracy: 0.9049 - precision: 0.8690 - recall: 0.8416 - auc: 0.9521 - prc: 0.9162 - val_loss: 1.2973 - val_tp: 166.0000 - val_fp: 81.0000 - val_tn: 435.0000 - val_fn: 92.0000 - val_accuracy: 0.7765 - val_precision: 0.6721 - val_recall: 0.6434 - val_auc: 0.8178 - val_prc: 0.6853 - 6s/epoch - 93ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3517 - tp: 1043.0000 - fp: 137.0000 - tn: 2275.0000 - fn: 163.0000 - accuracy: 0.9171 - precision: 0.8839 - recall: 0.8648 - auc: 0.9661 - prc: 0.9376 - val_loss: 0.9328 - val_tp: 186.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 72.0000 - val_accuracy: 0.8217 - val_precision: 0.7381 - val_recall: 0.7209 - val_auc: 0.8616 - val_prc: 0.7586 - 6s/epoch - 92ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2525 - tp: 1086.0000 - fp: 106.0000 - tn: 2306.0000 - fn: 120.0000 - accuracy: 0.9375 - precision: 0.9111 - recall: 0.9005 - auc: 0.9812 - prc: 0.9656 - val_loss: 0.9482 - val_tp: 187.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 71.0000 - val_accuracy: 0.8256 - val_precision: 0.7450 - val_recall: 0.7248 - val_auc: 0.8720 - val_prc: 0.7838 - 6s/epoch - 92ms/step
Epoch 6/200
61/61 - 6s - loss: 0.2385 - tp: 1093.0000 - fp: 99.0000 - tn: 2313.0000 - fn: 113.0000 - accuracy: 0.9414 - precision: 0.9169 - recall: 0.9063 - auc: 0.9834 - prc: 0.9700 - val_loss: 0.8979 - val_tp: 186.0000 - val_fp: 60.0000 - val_tn: 456.0000 - val_fn: 72.0000 - val_accuracy: 0.8295 - val_precision: 0.7561 - val_recall: 0.7209 - val_auc: 0.8733 - val_prc: 0.7797 - 6s/epoch - 91ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1528 - tp: 1140.0000 - fp: 60.0000 - tn: 2352.0000 - fn: 66.0000 - accuracy: 0.9652 - precision: 0.9500 - recall: 0.9453 - auc: 0.9924 - prc: 0.9854 - val_loss: 1.0322 - val_tp: 184.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 74.0000 - val_accuracy: 0.8165 - val_precision: 0.7302 - val_recall: 0.7132 - val_auc: 0.8615 - val_prc: 0.7635 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1150 - tp: 1157.0000 - fp: 40.0000 - tn: 2372.0000 - fn: 49.0000 - accuracy: 0.9754 - precision: 0.9666 - recall: 0.9594 - auc: 0.9958 - prc: 0.9918 - val_loss: 0.9529 - val_tp: 189.0000 - val_fp: 63.0000 - val_tn: 453.0000 - val_fn: 69.0000 - val_accuracy: 0.8295 - val_precision: 0.7500 - val_recall: 0.7326 - val_auc: 0.8787 - val_prc: 0.7910 - 6s/epoch - 92ms/step
Epoch 9/200
61/61 - 6s - loss: 0.0915 - tp: 1164.0000 - fp: 40.0000 - tn: 2372.0000 - fn: 42.0000 - accuracy: 0.9773 - precision: 0.9668 - recall: 0.9652 - auc: 0.9973 - prc: 0.9946 - val_loss: 1.0514 - val_tp: 196.0000 - val_fp: 55.0000 - val_tn: 461.0000 - val_fn: 62.0000 - val_accuracy: 0.8488 - val_precision: 0.7809 - val_recall: 0.7597 - val_auc: 0.8660 - val_prc: 0.7540 - 6s/epoch - 91ms/step
Epoch 10/200
61/61 - 6s - loss: 0.1077 - tp: 1164.0000 - fp: 38.0000 - tn: 2374.0000 - fn: 42.0000 - accuracy: 0.9779 - precision: 0.9684 - recall: 0.9652 - auc: 0.9966 - prc: 0.9938 - val_loss: 1.0813 - val_tp: 189.0000 - val_fp: 63.0000 - val_tn: 453.0000 - val_fn: 69.0000 - val_accuracy: 0.8295 - val_precision: 0.7500 - val_recall: 0.7326 - val_auc: 0.8686 - val_prc: 0.7909 - 6s/epoch - 93ms/step
Epoch 11/200
61/61 - 5s - loss: 0.0691 - tp: 1179.0000 - fp: 26.0000 - tn: 2386.0000 - fn: 27.0000 - accuracy: 0.9854 - precision: 0.9784 - recall: 0.9776 - auc: 0.9988 - prc: 0.9977 - val_loss: 0.9776 - val_tp: 197.0000 - val_fp: 57.0000 - val_tn: 459.0000 - val_fn: 61.0000 - val_accuracy: 0.8475 - val_precision: 0.7756 - val_recall: 0.7636 - val_auc: 0.8839 - val_prc: 0.7961 - 5s/epoch - 90ms/step
Epoch 11: early stopping
9/9 [==============================] - 0s 21ms/step
13/13 [==============================] - 0s 20ms/step - loss: 1.0574 - tp: 185.0000 - fp: 71.0000 - tn: 449.0000 - fn: 75.0000 - accuracy: 0.8128 - precision: 0.7227 - recall: 0.7115 - auc: 0.8599 - prc: 0.7579

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.65      0.78      0.71        86
           1       0.79      0.64      0.71        95
           2       0.72      0.73      0.73        79

    accuracy                           0.72       260
   macro avg       0.72      0.72      0.72       260
weighted avg       0.72      0.72      0.72       260




=============
CONFUSION MATRIX:
[[67  9 10]
 [22 61 12]
 [14  7 58]]



======= Lap 3 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 427(35.41%)
Label 1: 408(33.83%)
Label 2: 371(30.76%)
Data validation label:
Label 0: 91(35.27%)
Label 2: 84(32.56%)
Label 1: 83(32.17%)
Data test label:
Label 0: 101(38.85%)
Label 1: 83(31.92%)
Label 2: 76(29.23%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:3
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.06203292028968094, 0.016516081465218123, -0.0785490303315086]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5089 - tp: 797.0000 - fp: 593.0000 - tn: 2339.0000 - fn: 669.0000 - accuracy: 0.7131 - precision: 0.5734 - recall: 0.5437 - auc: 0.7370 - prc: 0.5913 - val_loss: 1.4716 - val_tp: 141.0000 - val_fp: 103.0000 - val_tn: 413.0000 - val_fn: 117.0000 - val_accuracy: 0.7158 - val_precision: 0.5779 - val_recall: 0.5465 - val_auc: 0.7357 - val_prc: 0.5860 - 8s/epoch - 124ms/step
Epoch 2/200
61/61 - 6s - loss: 0.7121 - tp: 895.0000 - fp: 274.0000 - tn: 2138.0000 - fn: 311.0000 - accuracy: 0.8383 - precision: 0.7656 - recall: 0.7421 - auc: 0.9011 - prc: 0.8303 - val_loss: 1.0934 - val_tp: 167.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 91.0000 - val_accuracy: 0.7817 - val_precision: 0.6816 - val_recall: 0.6473 - val_auc: 0.8182 - val_prc: 0.6892 - 6s/epoch - 92ms/step
Epoch 3/200
61/61 - 6s - loss: 0.5376 - tp: 968.0000 - fp: 210.0000 - tn: 2202.0000 - fn: 238.0000 - accuracy: 0.8762 - precision: 0.8217 - recall: 0.8027 - auc: 0.9355 - prc: 0.8867 - val_loss: 1.0026 - val_tp: 181.0000 - val_fp: 70.0000 - val_tn: 446.0000 - val_fn: 77.0000 - val_accuracy: 0.8101 - val_precision: 0.7211 - val_recall: 0.7016 - val_auc: 0.8414 - val_prc: 0.7253 - 6s/epoch - 91ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3016 - tp: 1064.0000 - fp: 118.0000 - tn: 2294.0000 - fn: 142.0000 - accuracy: 0.9281 - precision: 0.9002 - recall: 0.8823 - auc: 0.9747 - prc: 0.9545 - val_loss: 1.0780 - val_tp: 179.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 79.0000 - val_accuracy: 0.8088 - val_precision: 0.7218 - val_recall: 0.6938 - val_auc: 0.8499 - val_prc: 0.7403 - 6s/epoch - 91ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2530 - tp: 1088.0000 - fp: 106.0000 - tn: 2306.0000 - fn: 118.0000 - accuracy: 0.9381 - precision: 0.9112 - recall: 0.9022 - auc: 0.9816 - prc: 0.9658 - val_loss: 1.0224 - val_tp: 174.0000 - val_fp: 75.0000 - val_tn: 441.0000 - val_fn: 84.0000 - val_accuracy: 0.7946 - val_precision: 0.6988 - val_recall: 0.6744 - val_auc: 0.8572 - val_prc: 0.7604 - 6s/epoch - 93ms/step
Epoch 6/200
61/61 - 6s - loss: 0.1699 - tp: 1134.0000 - fp: 57.0000 - tn: 2355.0000 - fn: 72.0000 - accuracy: 0.9643 - precision: 0.9521 - recall: 0.9403 - auc: 0.9901 - prc: 0.9799 - val_loss: 1.0345 - val_tp: 185.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 73.0000 - val_accuracy: 0.8191 - val_precision: 0.7341 - val_recall: 0.7171 - val_auc: 0.8538 - val_prc: 0.7384 - 6s/epoch - 92ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1538 - tp: 1137.0000 - fp: 55.0000 - tn: 2357.0000 - fn: 69.0000 - accuracy: 0.9657 - precision: 0.9539 - recall: 0.9428 - auc: 0.9923 - prc: 0.9861 - val_loss: 0.9906 - val_tp: 190.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 68.0000 - val_accuracy: 0.8295 - val_precision: 0.7480 - val_recall: 0.7364 - val_auc: 0.8696 - val_prc: 0.7778 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1421 - tp: 1143.0000 - fp: 59.0000 - tn: 2353.0000 - fn: 63.0000 - accuracy: 0.9663 - precision: 0.9509 - recall: 0.9478 - auc: 0.9941 - prc: 0.9887 - val_loss: 1.0395 - val_tp: 187.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 71.0000 - val_accuracy: 0.8243 - val_precision: 0.7421 - val_recall: 0.7248 - val_auc: 0.8641 - val_prc: 0.7635 - 6s/epoch - 91ms/step
Epoch 9/200
61/61 - 6s - loss: 0.1070 - tp: 1155.0000 - fp: 39.0000 - tn: 2373.0000 - fn: 51.0000 - accuracy: 0.9751 - precision: 0.9673 - recall: 0.9577 - auc: 0.9957 - prc: 0.9912 - val_loss: 1.1065 - val_tp: 190.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 68.0000 - val_accuracy: 0.8295 - val_precision: 0.7480 - val_recall: 0.7364 - val_auc: 0.8585 - val_prc: 0.7636 - 6s/epoch - 90ms/step
Epoch 10/200
61/61 - 6s - loss: 0.0763 - tp: 1178.0000 - fp: 25.0000 - tn: 2387.0000 - fn: 28.0000 - accuracy: 0.9854 - precision: 0.9792 - recall: 0.9768 - auc: 0.9986 - prc: 0.9975 - val_loss: 1.0436 - val_tp: 181.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 77.0000 - val_accuracy: 0.8088 - val_precision: 0.7183 - val_recall: 0.7016 - val_auc: 0.8735 - val_prc: 0.7802 - 6s/epoch - 93ms/step
Epoch 11/200
61/61 - 6s - loss: 0.0932 - tp: 1165.0000 - fp: 37.0000 - tn: 2375.0000 - fn: 41.0000 - accuracy: 0.9784 - precision: 0.9692 - recall: 0.9660 - auc: 0.9970 - prc: 0.9950 - val_loss: 1.0520 - val_tp: 188.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 70.0000 - val_accuracy: 0.8256 - val_precision: 0.7431 - val_recall: 0.7287 - val_auc: 0.8690 - val_prc: 0.7781 - 6s/epoch - 91ms/step
Epoch 12/200
61/61 - 6s - loss: 0.0855 - tp: 1161.0000 - fp: 40.0000 - tn: 2372.0000 - fn: 45.0000 - accuracy: 0.9765 - precision: 0.9667 - recall: 0.9627 - auc: 0.9979 - prc: 0.9960 - val_loss: 1.0419 - val_tp: 189.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 69.0000 - val_accuracy: 0.8256 - val_precision: 0.7412 - val_recall: 0.7326 - val_auc: 0.8705 - val_prc: 0.7766 - 6s/epoch - 92ms/step
Epoch 12: early stopping
9/9 [==============================] - 0s 21ms/step
13/13 [==============================] - 0s 23ms/step - loss: 1.0560 - tp: 183.0000 - fp: 72.0000 - tn: 448.0000 - fn: 77.0000 - accuracy: 0.8090 - precision: 0.7176 - recall: 0.7038 - auc: 0.8643 - prc: 0.7750

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.70      0.58      0.64       101
           1       0.73      0.81      0.77        83
           2       0.70      0.78      0.74        76

    accuracy                           0.71       260
   macro avg       0.71      0.72      0.71       260
weighted avg       0.71      0.71      0.71       260




=============
CONFUSION MATRIX:
[[59 21 21]
 [12 67  4]
 [13  4 59]]



======= Lap 4 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 425(35.24%)
Label 1: 413(34.25%)
Label 2: 368(30.51%)
Data validation label:
Label 0: 105(40.7%)
Label 1: 83(32.17%)
Label 2: 70(27.13%)
Data test label:
Label 2: 93(35.77%)
Label 0: 89(34.23%)
Label 1: 78(30.0%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:4
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.05754927293885754, 0.028907696975473404, -0.08645695781662842]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 7s - loss: 1.5948 - tp: 765.0000 - fp: 614.0000 - tn: 2318.0000 - fn: 701.0000 - accuracy: 0.7010 - precision: 0.5547 - recall: 0.5218 - auc: 0.7257 - prc: 0.5773 - val_loss: 1.2297 - val_tp: 158.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 100.0000 - val_accuracy: 0.7636 - val_precision: 0.6556 - val_recall: 0.6124 - val_auc: 0.7918 - val_prc: 0.6533 - 7s/epoch - 123ms/step
Epoch 2/200
61/61 - 6s - loss: 0.7548 - tp: 879.0000 - fp: 284.0000 - tn: 2128.0000 - fn: 327.0000 - accuracy: 0.8311 - precision: 0.7558 - recall: 0.7289 - auc: 0.8898 - prc: 0.8142 - val_loss: 1.3018 - val_tp: 156.0000 - val_fp: 88.0000 - val_tn: 428.0000 - val_fn: 102.0000 - val_accuracy: 0.7545 - val_precision: 0.6393 - val_recall: 0.6047 - val_auc: 0.7932 - val_prc: 0.6675 - 6s/epoch - 91ms/step
Epoch 3/200
61/61 - 6s - loss: 0.5177 - tp: 965.0000 - fp: 216.0000 - tn: 2196.0000 - fn: 241.0000 - accuracy: 0.8737 - precision: 0.8171 - recall: 0.8002 - auc: 0.9365 - prc: 0.8874 - val_loss: 0.8802 - val_tp: 185.0000 - val_fp: 62.0000 - val_tn: 454.0000 - val_fn: 73.0000 - val_accuracy: 0.8256 - val_precision: 0.7490 - val_recall: 0.7171 - val_auc: 0.8623 - val_prc: 0.7753 - 6s/epoch - 91ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3251 - tp: 1060.0000 - fp: 124.0000 - tn: 2288.0000 - fn: 146.0000 - accuracy: 0.9254 - precision: 0.8953 - recall: 0.8789 - auc: 0.9711 - prc: 0.9475 - val_loss: 0.8606 - val_tp: 190.0000 - val_fp: 58.0000 - val_tn: 458.0000 - val_fn: 68.0000 - val_accuracy: 0.8372 - val_precision: 0.7661 - val_recall: 0.7364 - val_auc: 0.8761 - val_prc: 0.7928 - 6s/epoch - 93ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2567 - tp: 1094.0000 - fp: 93.0000 - tn: 2319.0000 - fn: 112.0000 - accuracy: 0.9433 - precision: 0.9217 - recall: 0.9071 - auc: 0.9798 - prc: 0.9630 - val_loss: 0.8715 - val_tp: 179.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 79.0000 - val_accuracy: 0.8127 - val_precision: 0.7306 - val_recall: 0.6938 - val_auc: 0.8722 - val_prc: 0.7956 - 6s/epoch - 91ms/step
Epoch 6/200
61/61 - 6s - loss: 0.2661 - tp: 1099.0000 - fp: 97.0000 - tn: 2315.0000 - fn: 107.0000 - accuracy: 0.9436 - precision: 0.9189 - recall: 0.9113 - auc: 0.9808 - prc: 0.9688 - val_loss: 0.9612 - val_tp: 191.0000 - val_fp: 54.0000 - val_tn: 462.0000 - val_fn: 67.0000 - val_accuracy: 0.8437 - val_precision: 0.7796 - val_recall: 0.7403 - val_auc: 0.8731 - val_prc: 0.7748 - 6s/epoch - 91ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1948 - tp: 1126.0000 - fp: 71.0000 - tn: 2341.0000 - fn: 80.0000 - accuracy: 0.9583 - precision: 0.9407 - recall: 0.9337 - auc: 0.9881 - prc: 0.9770 - val_loss: 0.8833 - val_tp: 195.0000 - val_fp: 55.0000 - val_tn: 461.0000 - val_fn: 63.0000 - val_accuracy: 0.8475 - val_precision: 0.7800 - val_recall: 0.7558 - val_auc: 0.8791 - val_prc: 0.8003 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1279 - tp: 1154.0000 - fp: 44.0000 - tn: 2368.0000 - fn: 52.0000 - accuracy: 0.9735 - precision: 0.9633 - recall: 0.9569 - auc: 0.9948 - prc: 0.9900 - val_loss: 1.1149 - val_tp: 185.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 73.0000 - val_accuracy: 0.8191 - val_precision: 0.7341 - val_recall: 0.7171 - val_auc: 0.8611 - val_prc: 0.7624 - 6s/epoch - 91ms/step
Epoch 9/200
61/61 - 6s - loss: 0.1303 - tp: 1146.0000 - fp: 53.0000 - tn: 2359.0000 - fn: 60.0000 - accuracy: 0.9688 - precision: 0.9558 - recall: 0.9502 - auc: 0.9946 - prc: 0.9895 - val_loss: 0.9029 - val_tp: 194.0000 - val_fp: 57.0000 - val_tn: 459.0000 - val_fn: 64.0000 - val_accuracy: 0.8437 - val_precision: 0.7729 - val_recall: 0.7519 - val_auc: 0.8873 - val_prc: 0.8207 - 6s/epoch - 94ms/step
Epoch 9: early stopping
9/9 [==============================] - 0s 21ms/step
13/13 [==============================] - 0s 23ms/step - loss: 0.7809 - tp: 203.0000 - fp: 52.0000 - tn: 468.0000 - fn: 57.0000 - accuracy: 0.8603 - precision: 0.7961 - recall: 0.7808 - auc: 0.8985 - prc: 0.8381

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.77      0.81      0.79        89
           1       0.78      0.76      0.77        78
           2       0.81      0.80      0.80        93

    accuracy                           0.79       260
   macro avg       0.79      0.79      0.79       260
weighted avg       0.79      0.79      0.79       260




=============
CONFUSION MATRIX:
[[72  8  9]
 [11 59  8]
 [10  9 74]]



======= Lap 5 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 436(36.15%)
Label 1: 402(33.33%)
Label 2: 368(30.51%)
Data validation label:
Label 1: 88(34.11%)
Label 2: 86(33.33%)
Label 0: 84(32.56%)
Data test label:
Label 0: 99(38.08%)
Label 1: 84(32.31%)
Label 2: 77(29.62%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:5
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.08358315680864217, 0.002393002078628901, -0.08597614837146135]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5022 - tp: 801.0000 - fp: 573.0000 - tn: 2359.0000 - fn: 665.0000 - accuracy: 0.7185 - precision: 0.5830 - recall: 0.5464 - auc: 0.7436 - prc: 0.6028 - val_loss: 1.0237 - val_tp: 154.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 104.0000 - val_accuracy: 0.7584 - val_precision: 0.6498 - val_recall: 0.5969 - val_auc: 0.8004 - val_prc: 0.6699 - 8s/epoch - 129ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6415 - tp: 895.0000 - fp: 269.0000 - tn: 2143.0000 - fn: 311.0000 - accuracy: 0.8397 - precision: 0.7689 - recall: 0.7421 - auc: 0.9084 - prc: 0.8440 - val_loss: 0.9854 - val_tp: 171.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 87.0000 - val_accuracy: 0.7984 - val_precision: 0.7125 - val_recall: 0.6628 - val_auc: 0.8329 - val_prc: 0.7201 - 6s/epoch - 93ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4324 - tp: 1012.0000 - fp: 170.0000 - tn: 2242.0000 - fn: 194.0000 - accuracy: 0.8994 - precision: 0.8562 - recall: 0.8391 - auc: 0.9532 - prc: 0.9180 - val_loss: 0.9701 - val_tp: 178.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 80.0000 - val_accuracy: 0.8075 - val_precision: 0.7206 - val_recall: 0.6899 - val_auc: 0.8385 - val_prc: 0.7401 - 6s/epoch - 94ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3010 - tp: 1074.0000 - fp: 110.0000 - tn: 2302.0000 - fn: 132.0000 - accuracy: 0.9331 - precision: 0.9071 - recall: 0.8905 - auc: 0.9742 - prc: 0.9539 - val_loss: 1.0810 - val_tp: 172.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 86.0000 - val_accuracy: 0.7972 - val_precision: 0.7078 - val_recall: 0.6667 - val_auc: 0.8346 - val_prc: 0.7257 - 6s/epoch - 94ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2096 - tp: 1117.0000 - fp: 76.0000 - tn: 2336.0000 - fn: 89.0000 - accuracy: 0.9544 - precision: 0.9363 - recall: 0.9262 - auc: 0.9866 - prc: 0.9751 - val_loss: 0.9932 - val_tp: 188.0000 - val_fp: 61.0000 - val_tn: 455.0000 - val_fn: 70.0000 - val_accuracy: 0.8307 - val_precision: 0.7550 - val_recall: 0.7287 - val_auc: 0.8672 - val_prc: 0.7757 - 6s/epoch - 93ms/step
Epoch 6/200
61/61 - 6s - loss: 0.1460 - tp: 1142.0000 - fp: 53.0000 - tn: 2359.0000 - fn: 64.0000 - accuracy: 0.9677 - precision: 0.9556 - recall: 0.9469 - auc: 0.9939 - prc: 0.9886 - val_loss: 1.0159 - val_tp: 191.0000 - val_fp: 61.0000 - val_tn: 455.0000 - val_fn: 67.0000 - val_accuracy: 0.8346 - val_precision: 0.7579 - val_recall: 0.7403 - val_auc: 0.8641 - val_prc: 0.7680 - 6s/epoch - 94ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1425 - tp: 1150.0000 - fp: 48.0000 - tn: 2364.0000 - fn: 56.0000 - accuracy: 0.9713 - precision: 0.9599 - recall: 0.9536 - auc: 0.9926 - prc: 0.9858 - val_loss: 1.1917 - val_tp: 180.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 78.0000 - val_accuracy: 0.8049 - val_precision: 0.7115 - val_recall: 0.6977 - val_auc: 0.8417 - val_prc: 0.7321 - 6s/epoch - 93ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1327 - tp: 1149.0000 - fp: 52.0000 - tn: 2360.0000 - fn: 57.0000 - accuracy: 0.9699 - precision: 0.9567 - recall: 0.9527 - auc: 0.9943 - prc: 0.9894 - val_loss: 1.1529 - val_tp: 184.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 74.0000 - val_accuracy: 0.8114 - val_precision: 0.7188 - val_recall: 0.7132 - val_auc: 0.8496 - val_prc: 0.7316 - 6s/epoch - 93ms/step
Epoch 8: early stopping
9/9 [==============================] - 0s 23ms/step
13/13 [==============================] - 0s 21ms/step - loss: 1.0567 - tp: 187.0000 - fp: 69.0000 - tn: 451.0000 - fn: 73.0000 - accuracy: 0.8179 - precision: 0.7305 - recall: 0.7192 - auc: 0.8541 - prc: 0.7609

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.73      0.68      0.70        99
           1       0.67      0.82      0.74        84
           2       0.82      0.69      0.75        77

    accuracy                           0.73       260
   macro avg       0.74      0.73      0.73       260
weighted avg       0.74      0.73      0.73       260




=============
CONFUSION MATRIX:
[[67 23  9]
 [12 69  3]
 [13 11 53]]



======= Lap 6 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 435(36.07%)
Label 1: 399(33.08%)
Label 2: 372(30.85%)
Data validation label:
Label 0: 95(36.82%)
Label 1: 88(34.11%)
Label 2: 75(29.07%)
Data test label:
Label 0: 89(34.23%)
Label 1: 87(33.46%)
Label 2: 84(32.31%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:6
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.08094559047542678, -0.005439023723393909, -0.07550658634011088]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5174 - tp: 804.0000 - fp: 575.0000 - tn: 2357.0000 - fn: 662.0000 - accuracy: 0.7187 - precision: 0.5830 - recall: 0.5484 - auc: 0.7340 - prc: 0.5910 - val_loss: 1.0247 - val_tp: 159.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 99.0000 - val_accuracy: 0.7649 - val_precision: 0.6570 - val_recall: 0.6163 - val_auc: 0.8004 - val_prc: 0.6665 - 8s/epoch - 134ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6933 - tp: 900.0000 - fp: 260.0000 - tn: 2152.0000 - fn: 306.0000 - accuracy: 0.8436 - precision: 0.7759 - recall: 0.7463 - auc: 0.9039 - prc: 0.8436 - val_loss: 1.2211 - val_tp: 151.0000 - val_fp: 91.0000 - val_tn: 425.0000 - val_fn: 107.0000 - val_accuracy: 0.7442 - val_precision: 0.6240 - val_recall: 0.5853 - val_auc: 0.7811 - val_prc: 0.6296 - 6s/epoch - 93ms/step
Epoch 3/200
61/61 - 6s - loss: 0.5178 - tp: 976.0000 - fp: 200.0000 - tn: 2212.0000 - fn: 230.0000 - accuracy: 0.8811 - precision: 0.8299 - recall: 0.8093 - auc: 0.9386 - prc: 0.8939 - val_loss: 1.0241 - val_tp: 172.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 86.0000 - val_accuracy: 0.7933 - val_precision: 0.6992 - val_recall: 0.6667 - val_auc: 0.8409 - val_prc: 0.7399 - 6s/epoch - 93ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3773 - tp: 1053.0000 - fp: 132.0000 - tn: 2280.0000 - fn: 153.0000 - accuracy: 0.9212 - precision: 0.8886 - recall: 0.8731 - auc: 0.9639 - prc: 0.9336 - val_loss: 0.9456 - val_tp: 188.0000 - val_fp: 60.0000 - val_tn: 456.0000 - val_fn: 70.0000 - val_accuracy: 0.8320 - val_precision: 0.7581 - val_recall: 0.7287 - val_auc: 0.8662 - val_prc: 0.7837 - 6s/epoch - 93ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2639 - tp: 1082.0000 - fp: 108.0000 - tn: 2304.0000 - fn: 124.0000 - accuracy: 0.9359 - precision: 0.9092 - recall: 0.8972 - auc: 0.9799 - prc: 0.9653 - val_loss: 1.1719 - val_tp: 179.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 79.0000 - val_accuracy: 0.8049 - val_precision: 0.7131 - val_recall: 0.6938 - val_auc: 0.8242 - val_prc: 0.6999 - 6s/epoch - 94ms/step
Epoch 6/200
61/61 - 6s - loss: 0.2166 - tp: 1111.0000 - fp: 81.0000 - tn: 2331.0000 - fn: 95.0000 - accuracy: 0.9514 - precision: 0.9320 - recall: 0.9212 - auc: 0.9859 - prc: 0.9753 - val_loss: 1.0357 - val_tp: 182.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 76.0000 - val_accuracy: 0.8088 - val_precision: 0.7165 - val_recall: 0.7054 - val_auc: 0.8570 - val_prc: 0.7663 - 6s/epoch - 95ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1625 - tp: 1143.0000 - fp: 57.0000 - tn: 2355.0000 - fn: 63.0000 - accuracy: 0.9668 - precision: 0.9525 - recall: 0.9478 - auc: 0.9912 - prc: 0.9835 - val_loss: 0.9625 - val_tp: 191.0000 - val_fp: 59.0000 - val_tn: 457.0000 - val_fn: 67.0000 - val_accuracy: 0.8372 - val_precision: 0.7640 - val_recall: 0.7403 - val_auc: 0.8713 - val_prc: 0.7889 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1614 - tp: 1127.0000 - fp: 69.0000 - tn: 2343.0000 - fn: 79.0000 - accuracy: 0.9591 - precision: 0.9423 - recall: 0.9345 - auc: 0.9919 - prc: 0.9870 - val_loss: 0.9995 - val_tp: 183.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 75.0000 - val_accuracy: 0.8165 - val_precision: 0.7320 - val_recall: 0.7093 - val_auc: 0.8703 - val_prc: 0.7757 - 6s/epoch - 93ms/step
Epoch 9/200
61/61 - 6s - loss: 0.1158 - tp: 1149.0000 - fp: 48.0000 - tn: 2364.0000 - fn: 57.0000 - accuracy: 0.9710 - precision: 0.9599 - recall: 0.9527 - auc: 0.9958 - prc: 0.9918 - val_loss: 0.9992 - val_tp: 187.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 71.0000 - val_accuracy: 0.8230 - val_precision: 0.7391 - val_recall: 0.7248 - val_auc: 0.8733 - val_prc: 0.7810 - 6s/epoch - 94ms/step
Epoch 9: early stopping
9/9 [==============================] - 0s 23ms/step
13/13 [==============================] - 0s 20ms/step - loss: 0.8800 - tp: 201.0000 - fp: 56.0000 - tn: 464.0000 - fn: 59.0000 - accuracy: 0.8526 - precision: 0.7821 - recall: 0.7731 - auc: 0.8826 - prc: 0.7904

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.69      0.79      0.74        89
           1       0.81      0.76      0.79        87
           2       0.85      0.79      0.81        84

    accuracy                           0.78       260
   macro avg       0.78      0.78      0.78       260
weighted avg       0.78      0.78      0.78       260




=============
CONFUSION MATRIX:
[[70 13  6]
 [15 66  6]
 [16  2 66]]



======= Lap 7 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 439(36.4%)
Label 1: 388(32.17%)
Label 2: 379(31.43%)
Data validation label:
Label 0: 105(40.7%)
Label 1: 86(33.33%)
Label 2: 67(25.97%)
Data test label:
Label 1: 100(38.46%)
Label 2: 85(32.69%)
Label 0: 75(28.85%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:7
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.09015242551668473, -0.033341647935213374, -0.0568107824760604]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5030 - tp: 803.0000 - fp: 572.0000 - tn: 2360.0000 - fn: 663.0000 - accuracy: 0.7192 - precision: 0.5840 - recall: 0.5477 - auc: 0.7402 - prc: 0.5946 - val_loss: 1.4438 - val_tp: 139.0000 - val_fp: 106.0000 - val_tn: 410.0000 - val_fn: 119.0000 - val_accuracy: 0.7093 - val_precision: 0.5673 - val_recall: 0.5388 - val_auc: 0.7424 - val_prc: 0.5943 - 8s/epoch - 129ms/step
Epoch 2/200
61/61 - 6s - loss: 0.7053 - tp: 899.0000 - fp: 259.0000 - tn: 2153.0000 - fn: 307.0000 - accuracy: 0.8436 - precision: 0.7763 - recall: 0.7454 - auc: 0.9013 - prc: 0.8294 - val_loss: 1.1873 - val_tp: 172.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 86.0000 - val_accuracy: 0.7946 - val_precision: 0.7020 - val_recall: 0.6667 - val_auc: 0.7993 - val_prc: 0.6444 - 6s/epoch - 92ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4685 - tp: 991.0000 - fp: 186.0000 - tn: 2226.0000 - fn: 215.0000 - accuracy: 0.8892 - precision: 0.8420 - recall: 0.8217 - auc: 0.9468 - prc: 0.9073 - val_loss: 0.9489 - val_tp: 175.0000 - val_fp: 76.0000 - val_tn: 440.0000 - val_fn: 83.0000 - val_accuracy: 0.7946 - val_precision: 0.6972 - val_recall: 0.6783 - val_auc: 0.8473 - val_prc: 0.7436 - 6s/epoch - 92ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3173 - tp: 1058.0000 - fp: 131.0000 - tn: 2281.0000 - fn: 148.0000 - accuracy: 0.9229 - precision: 0.8898 - recall: 0.8773 - auc: 0.9717 - prc: 0.9491 - val_loss: 0.9456 - val_tp: 180.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 78.0000 - val_accuracy: 0.8075 - val_precision: 0.7171 - val_recall: 0.6977 - val_auc: 0.8551 - val_prc: 0.7504 - 6s/epoch - 93ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2507 - tp: 1099.0000 - fp: 100.0000 - tn: 2312.0000 - fn: 107.0000 - accuracy: 0.9428 - precision: 0.9166 - recall: 0.9113 - auc: 0.9813 - prc: 0.9669 - val_loss: 1.2029 - val_tp: 180.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 78.0000 - val_accuracy: 0.8062 - val_precision: 0.7143 - val_recall: 0.6977 - val_auc: 0.8348 - val_prc: 0.7178 - 6s/epoch - 93ms/step
Epoch 6/200
61/61 - 6s - loss: 0.2303 - tp: 1107.0000 - fp: 93.0000 - tn: 2319.0000 - fn: 99.0000 - accuracy: 0.9469 - precision: 0.9225 - recall: 0.9179 - auc: 0.9849 - prc: 0.9718 - val_loss: 1.0622 - val_tp: 182.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 76.0000 - val_accuracy: 0.8152 - val_precision: 0.7309 - val_recall: 0.7054 - val_auc: 0.8467 - val_prc: 0.7395 - 6s/epoch - 93ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1407 - tp: 1145.0000 - fp: 53.0000 - tn: 2359.0000 - fn: 61.0000 - accuracy: 0.9685 - precision: 0.9558 - recall: 0.9494 - auc: 0.9937 - prc: 0.9882 - val_loss: 1.0401 - val_tp: 184.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 74.0000 - val_accuracy: 0.8217 - val_precision: 0.7419 - val_recall: 0.7132 - val_auc: 0.8507 - val_prc: 0.7357 - 6s/epoch - 91ms/step
Epoch 8/200
61/61 - 6s - loss: 0.0886 - tp: 1170.0000 - fp: 29.0000 - tn: 2383.0000 - fn: 36.0000 - accuracy: 0.9820 - precision: 0.9758 - recall: 0.9701 - auc: 0.9979 - prc: 0.9960 - val_loss: 1.1479 - val_tp: 187.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 71.0000 - val_accuracy: 0.8191 - val_precision: 0.7305 - val_recall: 0.7248 - val_auc: 0.8469 - val_prc: 0.7288 - 6s/epoch - 91ms/step
Epoch 9/200
61/61 - 6s - loss: 0.0973 - tp: 1163.0000 - fp: 38.0000 - tn: 2374.0000 - fn: 43.0000 - accuracy: 0.9776 - precision: 0.9684 - recall: 0.9643 - auc: 0.9974 - prc: 0.9952 - val_loss: 1.0982 - val_tp: 186.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 72.0000 - val_accuracy: 0.8191 - val_precision: 0.7323 - val_recall: 0.7209 - val_auc: 0.8608 - val_prc: 0.7614 - 6s/epoch - 91ms/step
Epoch 9: early stopping
9/9 [==============================] - 0s 21ms/step
13/13 [==============================] - 0s 24ms/step - loss: 0.9170 - tp: 186.0000 - fp: 67.0000 - tn: 453.0000 - fn: 74.0000 - accuracy: 0.8192 - precision: 0.7352 - recall: 0.7154 - auc: 0.8794 - prc: 0.7994

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.64      0.69      0.67        75
           1       0.77      0.72      0.75       100
           2       0.76      0.76      0.76        85

    accuracy                           0.73       260
   macro avg       0.72      0.73      0.72       260
weighted avg       0.73      0.73      0.73       260




=============
CONFUSION MATRIX:
[[52 13 10]
 [17 72 11]
 [12  8 65]]



======= Lap 8 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 450(37.31%)
Label 1: 394(32.67%)
Label 2: 362(30.02%)
Data validation label:
Label 0: 90(34.88%)
Label 2: 84(32.56%)
Label 1: 84(32.56%)
Data test label:
Label 1: 96(36.92%)
Label 2: 85(32.69%)
Label 0: 79(30.38%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:8
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.11683335982459347, -0.016063313641838037, -0.10077001111400082]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.5486 - tp: 772.0000 - fp: 592.0000 - tn: 2340.0000 - fn: 694.0000 - accuracy: 0.7076 - precision: 0.5660 - recall: 0.5266 - auc: 0.7285 - prc: 0.5858 - val_loss: 1.1134 - val_tp: 164.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 94.0000 - val_accuracy: 0.7713 - val_precision: 0.6640 - val_recall: 0.6357 - val_auc: 0.8052 - val_prc: 0.6763 - 8s/epoch - 128ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6547 - tp: 916.0000 - fp: 244.0000 - tn: 2168.0000 - fn: 290.0000 - accuracy: 0.8524 - precision: 0.7897 - recall: 0.7595 - auc: 0.9083 - prc: 0.8431 - val_loss: 0.8741 - val_tp: 170.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 88.0000 - val_accuracy: 0.7933 - val_precision: 0.7025 - val_recall: 0.6589 - val_auc: 0.8514 - val_prc: 0.7707 - 6s/epoch - 93ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4089 - tp: 1009.0000 - fp: 159.0000 - tn: 2253.0000 - fn: 197.0000 - accuracy: 0.9016 - precision: 0.8639 - recall: 0.8367 - auc: 0.9567 - prc: 0.9267 - val_loss: 0.9213 - val_tp: 172.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 86.0000 - val_accuracy: 0.7881 - val_precision: 0.6880 - val_recall: 0.6667 - val_auc: 0.8496 - val_prc: 0.7597 - 6s/epoch - 92ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3386 - tp: 1051.0000 - fp: 128.0000 - tn: 2284.0000 - fn: 155.0000 - accuracy: 0.9218 - precision: 0.8914 - recall: 0.8715 - auc: 0.9683 - prc: 0.9444 - val_loss: 0.9681 - val_tp: 169.0000 - val_fp: 80.0000 - val_tn: 436.0000 - val_fn: 89.0000 - val_accuracy: 0.7817 - val_precision: 0.6787 - val_recall: 0.6550 - val_auc: 0.8554 - val_prc: 0.7601 - 6s/epoch - 92ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2766 - tp: 1089.0000 - fp: 106.0000 - tn: 2306.0000 - fn: 117.0000 - accuracy: 0.9384 - precision: 0.9113 - recall: 0.9030 - auc: 0.9786 - prc: 0.9612 - val_loss: 1.1789 - val_tp: 166.0000 - val_fp: 81.0000 - val_tn: 435.0000 - val_fn: 92.0000 - val_accuracy: 0.7765 - val_precision: 0.6721 - val_recall: 0.6434 - val_auc: 0.8245 - val_prc: 0.7124 - 6s/epoch - 91ms/step
Epoch 6/200
61/61 - 6s - loss: 0.1883 - tp: 1124.0000 - fp: 67.0000 - tn: 2345.0000 - fn: 82.0000 - accuracy: 0.9588 - precision: 0.9437 - recall: 0.9320 - auc: 0.9891 - prc: 0.9796 - val_loss: 0.9242 - val_tp: 179.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 79.0000 - val_accuracy: 0.8023 - val_precision: 0.7075 - val_recall: 0.6938 - val_auc: 0.8621 - val_prc: 0.7681 - 6s/epoch - 92ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1913 - tp: 1127.0000 - fp: 63.0000 - tn: 2349.0000 - fn: 79.0000 - accuracy: 0.9608 - precision: 0.9471 - recall: 0.9345 - auc: 0.9890 - prc: 0.9801 - val_loss: 1.0088 - val_tp: 178.0000 - val_fp: 75.0000 - val_tn: 441.0000 - val_fn: 80.0000 - val_accuracy: 0.7997 - val_precision: 0.7036 - val_recall: 0.6899 - val_auc: 0.8545 - val_prc: 0.7644 - 6s/epoch - 92ms/step
Epoch 7: early stopping
9/9 [==============================] - 0s 22ms/step
13/13 [==============================] - 0s 24ms/step - loss: 1.0833 - tp: 177.0000 - fp: 73.0000 - tn: 447.0000 - fn: 83.0000 - accuracy: 0.8000 - precision: 0.7080 - recall: 0.6808 - auc: 0.8481 - prc: 0.7390

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.63      0.59      0.61        79
           1       0.71      0.76      0.73        96
           2       0.76      0.73      0.74        85

    accuracy                           0.70       260
   macro avg       0.70      0.69      0.70       260
weighted avg       0.70      0.70      0.70       260




=============
CONFUSION MATRIX:
[[47 22 10]
 [13 73 10]
 [15  8 62]]



======= Lap 9 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 433(35.9%)
Label 1: 389(32.26%)
Label 2: 384(31.84%)
Data validation label:
Label 0: 94(36.43%)
Label 1: 94(36.43%)
Label 2: 70(27.13%)
Data test label:
Label 0: 92(35.38%)
Label 1: 91(35.0%)
Label 2: 77(29.62%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:9
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.07575118765407839, -0.03140719672996517, -0.044343987760684614]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.6686 - tp: 743.0000 - fp: 635.0000 - tn: 2297.0000 - fn: 723.0000 - accuracy: 0.6912 - precision: 0.5392 - recall: 0.5068 - auc: 0.7084 - prc: 0.5473 - val_loss: 1.1456 - val_tp: 152.0000 - val_fp: 89.0000 - val_tn: 427.0000 - val_fn: 106.0000 - val_accuracy: 0.7481 - val_precision: 0.6307 - val_recall: 0.5891 - val_auc: 0.7932 - val_prc: 0.6790 - 8s/epoch - 127ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6751 - tp: 918.0000 - fp: 239.0000 - tn: 2173.0000 - fn: 288.0000 - accuracy: 0.8543 - precision: 0.7934 - recall: 0.7612 - auc: 0.9026 - prc: 0.8321 - val_loss: 0.9168 - val_tp: 179.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 79.0000 - val_accuracy: 0.8140 - val_precision: 0.7336 - val_recall: 0.6938 - val_auc: 0.8523 - val_prc: 0.7317 - 6s/epoch - 92ms/step
Epoch 3/200
61/61 - 6s - loss: 0.4383 - tp: 1007.0000 - fp: 168.0000 - tn: 2244.0000 - fn: 199.0000 - accuracy: 0.8986 - precision: 0.8570 - recall: 0.8350 - auc: 0.9521 - prc: 0.9192 - val_loss: 0.8871 - val_tp: 182.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 76.0000 - val_accuracy: 0.8152 - val_precision: 0.7309 - val_recall: 0.7054 - val_auc: 0.8616 - val_prc: 0.7490 - 6s/epoch - 91ms/step
Epoch 4/200
61/61 - 6s - loss: 0.2704 - tp: 1071.0000 - fp: 110.0000 - tn: 2302.0000 - fn: 135.0000 - accuracy: 0.9323 - precision: 0.9069 - recall: 0.8881 - auc: 0.9794 - prc: 0.9632 - val_loss: 1.0539 - val_tp: 190.0000 - val_fp: 62.0000 - val_tn: 454.0000 - val_fn: 68.0000 - val_accuracy: 0.8320 - val_precision: 0.7540 - val_recall: 0.7364 - val_auc: 0.8596 - val_prc: 0.7645 - 6s/epoch - 90ms/step
Epoch 5/200
61/61 - 6s - loss: 0.2018 - tp: 1108.0000 - fp: 71.0000 - tn: 2341.0000 - fn: 98.0000 - accuracy: 0.9533 - precision: 0.9398 - recall: 0.9187 - auc: 0.9882 - prc: 0.9788 - val_loss: 0.9969 - val_tp: 181.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 77.0000 - val_accuracy: 0.8088 - val_precision: 0.7183 - val_recall: 0.7016 - val_auc: 0.8670 - val_prc: 0.7668 - 6s/epoch - 92ms/step
Epoch 6/200
61/61 - 6s - loss: 0.1803 - tp: 1121.0000 - fp: 72.0000 - tn: 2340.0000 - fn: 85.0000 - accuracy: 0.9566 - precision: 0.9396 - recall: 0.9295 - auc: 0.9908 - prc: 0.9830 - val_loss: 0.8838 - val_tp: 196.0000 - val_fp: 56.0000 - val_tn: 460.0000 - val_fn: 62.0000 - val_accuracy: 0.8475 - val_precision: 0.7778 - val_recall: 0.7597 - val_auc: 0.8826 - val_prc: 0.7938 - 6s/epoch - 92ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1307 - tp: 1159.0000 - fp: 40.0000 - tn: 2372.0000 - fn: 47.0000 - accuracy: 0.9760 - precision: 0.9666 - recall: 0.9610 - auc: 0.9941 - prc: 0.9901 - val_loss: 0.9326 - val_tp: 193.0000 - val_fp: 56.0000 - val_tn: 460.0000 - val_fn: 65.0000 - val_accuracy: 0.8437 - val_precision: 0.7751 - val_recall: 0.7481 - val_auc: 0.8732 - val_prc: 0.7693 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1111 - tp: 1160.0000 - fp: 39.0000 - tn: 2373.0000 - fn: 46.0000 - accuracy: 0.9765 - precision: 0.9675 - recall: 0.9619 - auc: 0.9958 - prc: 0.9922 - val_loss: 0.9101 - val_tp: 195.0000 - val_fp: 57.0000 - val_tn: 459.0000 - val_fn: 63.0000 - val_accuracy: 0.8450 - val_precision: 0.7738 - val_recall: 0.7558 - val_auc: 0.8851 - val_prc: 0.7968 - 6s/epoch - 92ms/step
Epoch 9/200
61/61 - 6s - loss: 0.0828 - tp: 1169.0000 - fp: 30.0000 - tn: 2382.0000 - fn: 37.0000 - accuracy: 0.9815 - precision: 0.9750 - recall: 0.9693 - auc: 0.9984 - prc: 0.9972 - val_loss: 0.9784 - val_tp: 200.0000 - val_fp: 57.0000 - val_tn: 459.0000 - val_fn: 58.0000 - val_accuracy: 0.8514 - val_precision: 0.7782 - val_recall: 0.7752 - val_auc: 0.8804 - val_prc: 0.7884 - 6s/epoch - 92ms/step
Epoch 10/200
61/61 - 6s - loss: 0.0524 - tp: 1187.0000 - fp: 16.0000 - tn: 2396.0000 - fn: 19.0000 - accuracy: 0.9903 - precision: 0.9867 - recall: 0.9842 - auc: 0.9996 - prc: 0.9992 - val_loss: 1.0592 - val_tp: 188.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 70.0000 - val_accuracy: 0.8230 - val_precision: 0.7373 - val_recall: 0.7287 - val_auc: 0.8771 - val_prc: 0.7796 - 6s/epoch - 93ms/step
Epoch 11/200
61/61 - 6s - loss: 0.0803 - tp: 1177.0000 - fp: 26.0000 - tn: 2386.0000 - fn: 29.0000 - accuracy: 0.9848 - precision: 0.9784 - recall: 0.9760 - auc: 0.9981 - prc: 0.9963 - val_loss: 0.9587 - val_tp: 198.0000 - val_fp: 56.0000 - val_tn: 460.0000 - val_fn: 60.0000 - val_accuracy: 0.8501 - val_precision: 0.7795 - val_recall: 0.7674 - val_auc: 0.8815 - val_prc: 0.7862 - 6s/epoch - 91ms/step
Epoch 11: early stopping
9/9 [==============================] - 0s 22ms/step
13/13 [==============================] - 0s 20ms/step - loss: 1.0232 - tp: 196.0000 - fp: 61.0000 - tn: 459.0000 - fn: 64.0000 - accuracy: 0.8397 - precision: 0.7626 - recall: 0.7538 - auc: 0.8758 - prc: 0.7943

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.77      0.70      0.73        92
           1       0.78      0.78      0.78        91
           2       0.73      0.82      0.77        77

    accuracy                           0.76       260
   macro avg       0.76      0.76      0.76       260
weighted avg       0.76      0.76      0.76       260




=============
CONFUSION MATRIX:
[[64 15 13]
 [10 71 10]
 [ 9  5 63]]



======= Lap 10 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 440(36.48%)
Label 1: 399(33.08%)
Label 2: 367(30.43%)
Data validation label:
Label 1: 89(34.5%)
Label 2: 86(33.33%)
Label 0: 83(32.17%)
Data test label:
Label 0: 96(36.92%)
Label 1: 86(33.08%)
Label 2: 78(30.0%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:10
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:2000
output_bias:[0.09307539768624283, -0.004737912336200705, -0.08833748117149397]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20


Epoch 1/200
61/61 - 8s - loss: 1.4845 - tp: 791.0000 - fp: 586.0000 - tn: 2346.0000 - fn: 675.0000 - accuracy: 0.7133 - precision: 0.5744 - recall: 0.5396 - auc: 0.7391 - prc: 0.5969 - val_loss: 1.0994 - val_tp: 158.0000 - val_fp: 86.0000 - val_tn: 430.0000 - val_fn: 100.0000 - val_accuracy: 0.7597 - val_precision: 0.6475 - val_recall: 0.6124 - val_auc: 0.7990 - val_prc: 0.6826 - 8s/epoch - 125ms/step
Epoch 2/200
61/61 - 6s - loss: 0.6930 - tp: 880.0000 - fp: 283.0000 - tn: 2129.0000 - fn: 326.0000 - accuracy: 0.8317 - precision: 0.7567 - recall: 0.7297 - auc: 0.9003 - prc: 0.8303 - val_loss: 0.9239 - val_tp: 166.0000 - val_fp: 85.0000 - val_tn: 431.0000 - val_fn: 92.0000 - val_accuracy: 0.7713 - val_precision: 0.6614 - val_recall: 0.6434 - val_auc: 0.8360 - val_prc: 0.7332 - 6s/epoch - 91ms/step
Epoch 3/200
61/61 - 6s - loss: 0.5092 - tp: 974.0000 - fp: 200.0000 - tn: 2212.0000 - fn: 232.0000 - accuracy: 0.8806 - precision: 0.8296 - recall: 0.8076 - auc: 0.9397 - prc: 0.8930 - val_loss: 0.7856 - val_tp: 187.0000 - val_fp: 62.0000 - val_tn: 454.0000 - val_fn: 71.0000 - val_accuracy: 0.8282 - val_precision: 0.7510 - val_recall: 0.7248 - val_auc: 0.8775 - val_prc: 0.7835 - 6s/epoch - 93ms/step
Epoch 4/200
61/61 - 6s - loss: 0.3288 - tp: 1053.0000 - fp: 129.0000 - tn: 2283.0000 - fn: 153.0000 - accuracy: 0.9221 - precision: 0.8909 - recall: 0.8731 - auc: 0.9693 - prc: 0.9456 - val_loss: 1.2070 - val_tp: 175.0000 - val_fp: 77.0000 - val_tn: 439.0000 - val_fn: 83.0000 - val_accuracy: 0.7933 - val_precision: 0.6944 - val_recall: 0.6783 - val_auc: 0.8316 - val_prc: 0.7332 - 6s/epoch - 91ms/step
Epoch 5/200
61/61 - 6s - loss: 0.3165 - tp: 1064.0000 - fp: 126.0000 - tn: 2286.0000 - fn: 142.0000 - accuracy: 0.9259 - precision: 0.8941 - recall: 0.8823 - auc: 0.9725 - prc: 0.9481 - val_loss: 0.8910 - val_tp: 190.0000 - val_fp: 61.0000 - val_tn: 455.0000 - val_fn: 68.0000 - val_accuracy: 0.8333 - val_precision: 0.7570 - val_recall: 0.7364 - val_auc: 0.8765 - val_prc: 0.7943 - 6s/epoch - 91ms/step
Epoch 6/200
61/61 - 6s - loss: 0.2078 - tp: 1112.0000 - fp: 83.0000 - tn: 2329.0000 - fn: 94.0000 - accuracy: 0.9511 - precision: 0.9305 - recall: 0.9221 - auc: 0.9874 - prc: 0.9784 - val_loss: 0.9901 - val_tp: 187.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 71.0000 - val_accuracy: 0.8204 - val_precision: 0.7333 - val_recall: 0.7248 - val_auc: 0.8762 - val_prc: 0.7999 - 6s/epoch - 91ms/step
Epoch 7/200
61/61 - 6s - loss: 0.1214 - tp: 1161.0000 - fp: 36.0000 - tn: 2376.0000 - fn: 45.0000 - accuracy: 0.9776 - precision: 0.9699 - recall: 0.9627 - auc: 0.9951 - prc: 0.9902 - val_loss: 0.8307 - val_tp: 195.0000 - val_fp: 58.0000 - val_tn: 458.0000 - val_fn: 63.0000 - val_accuracy: 0.8437 - val_precision: 0.7708 - val_recall: 0.7558 - val_auc: 0.8961 - val_prc: 0.8296 - 6s/epoch - 92ms/step
Epoch 8/200
61/61 - 6s - loss: 0.1019 - tp: 1160.0000 - fp: 37.0000 - tn: 2375.0000 - fn: 46.0000 - accuracy: 0.9771 - precision: 0.9691 - recall: 0.9619 - auc: 0.9970 - prc: 0.9942 - val_loss: 0.9022 - val_tp: 196.0000 - val_fp: 59.0000 - val_tn: 457.0000 - val_fn: 62.0000 - val_accuracy: 0.8437 - val_precision: 0.7686 - val_recall: 0.7597 - val_auc: 0.8863 - val_prc: 0.8144 - 6s/epoch - 91ms/step
Epoch 8: early stopping
9/9 [==============================] - 0s 23ms/step
13/13 [==============================] - 0s 19ms/step - loss: 0.8754 - tp: 192.0000 - fp: 56.0000 - tn: 464.0000 - fn: 68.0000 - accuracy: 0.8410 - precision: 0.7742 - recall: 0.7385 - auc: 0.8842 - prc: 0.8099

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.73      0.72      0.73        96
           1       0.80      0.78      0.79        86
           2       0.78      0.82      0.80        78

    accuracy                           0.77       260
   macro avg       0.77      0.77      0.77       260
weighted avg       0.77      0.77      0.77       260




=============
CONFUSION MATRIX:
[[69 11 16]
 [17 67  2]
 [ 8  6 64]]



=============
TEST SUMMARY REPORT:
Loss mean: 0.9824309945106506, std: 0.10381950689258256
Accuracy mean: 0.8287179589271545, std: 0.018826523119293784
Precsion mean: 0.7483832776546478, std: 0.028383143411571693
Recall mean: 0.7323076903820038, std: 0.030098468689624614


