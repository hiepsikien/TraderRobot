
>>>>>> LAP 1

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 430(36.29%)
Label 1: 390(32.91%)
Label 2: 365(30.8%)
Data validation:
Label 0: 95(37.4%)
Label 1: 89(35.04%)
Label 2: 70(27.56%)
Data test:
Label 0: 90(35.29%)
Label 2: 84(32.94%)
Label 1: 81(31.76%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:1
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.08717545191248942, -0.010463017651426544, -0.07671240319262713]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6111 - tp: 809.0000 - fp: 574.0000 - tn: 2306.0000 - fn: 631.0000 - accuracy: 0.7211 - precision: 0.5850 - recall: 0.5618 - auc: 0.7612 - prc: 0.6350 - val_loss: 1.2285 - val_tp: 168.0000 - val_fp: 84.0000 - val_tn: 424.0000 - val_fn: 86.0000 - val_accuracy: 0.7769 - val_precision: 0.6667 - val_recall: 0.6614 - val_auc: 0.8229 - val_prc: 0.6924 - 12s/epoch - 204ms/step
Epoch 2/200
60/60 - 10s - loss: 0.6433 - tp: 949.0000 - fp: 214.0000 - tn: 2156.0000 - fn: 236.0000 - accuracy: 0.8734 - precision: 0.8160 - recall: 0.8008 - auc: 0.9287 - prc: 0.8782 - val_loss: 1.3092 - val_tp: 166.0000 - val_fp: 82.0000 - val_tn: 426.0000 - val_fn: 88.0000 - val_accuracy: 0.7769 - val_precision: 0.6694 - val_recall: 0.6535 - val_auc: 0.8022 - val_prc: 0.6560 - 10s/epoch - 162ms/step
Epoch 3/200
60/60 - 10s - loss: 0.3918 - tp: 1025.0000 - fp: 143.0000 - tn: 2227.0000 - fn: 160.0000 - accuracy: 0.9148 - precision: 0.8776 - recall: 0.8650 - auc: 0.9622 - prc: 0.9305 - val_loss: 1.5041 - val_tp: 171.0000 - val_fp: 76.0000 - val_tn: 432.0000 - val_fn: 83.0000 - val_accuracy: 0.7913 - val_precision: 0.6923 - val_recall: 0.6732 - val_auc: 0.8148 - val_prc: 0.6950 - 10s/epoch - 161ms/step
Epoch 4/200
60/60 - 10s - loss: 0.4261 - tp: 1036.0000 - fp: 134.0000 - tn: 2236.0000 - fn: 149.0000 - accuracy: 0.9204 - precision: 0.8855 - recall: 0.8743 - auc: 0.9615 - prc: 0.9260 - val_loss: 1.4780 - val_tp: 171.0000 - val_fp: 80.0000 - val_tn: 428.0000 - val_fn: 83.0000 - val_accuracy: 0.7861 - val_precision: 0.6813 - val_recall: 0.6732 - val_auc: 0.8216 - val_prc: 0.7035 - 10s/epoch - 161ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2437 - tp: 1094.0000 - fp: 84.0000 - tn: 2286.0000 - fn: 91.0000 - accuracy: 0.9508 - precision: 0.9287 - recall: 0.9232 - auc: 0.9816 - prc: 0.9637 - val_loss: 1.2654 - val_tp: 172.0000 - val_fp: 76.0000 - val_tn: 432.0000 - val_fn: 82.0000 - val_accuracy: 0.7927 - val_precision: 0.6935 - val_recall: 0.6772 - val_auc: 0.8392 - val_prc: 0.7291 - 10s/epoch - 161ms/step
Epoch 6/200
60/60 - 10s - loss: 0.1751 - tp: 1107.0000 - fp: 71.0000 - tn: 2299.0000 - fn: 78.0000 - accuracy: 0.9581 - precision: 0.9397 - recall: 0.9342 - auc: 0.9907 - prc: 0.9827 - val_loss: 1.3426 - val_tp: 177.0000 - val_fp: 76.0000 - val_tn: 432.0000 - val_fn: 77.0000 - val_accuracy: 0.7992 - val_precision: 0.6996 - val_recall: 0.6969 - val_auc: 0.8402 - val_prc: 0.7293 - 10s/epoch - 163ms/step
Epoch 6: early stopping
8/8 [==============================] - 0s 39ms/step
13/13 [==============================] - 1s 36ms/step - loss: 1.1744 - tp: 176.0000 - fp: 72.0000 - tn: 438.0000 - fn: 79.0000 - accuracy: 0.8026 - precision: 0.7097 - recall: 0.6902 - auc: 0.8624 - prc: 0.7738

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.70      0.62      0.66        90
           1       0.70      0.85      0.77        81
           2       0.70      0.63      0.66        84

    accuracy                           0.70       255
   macro avg       0.70      0.70      0.70       255
weighted avg       0.70      0.70      0.69       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       56   18   16     90  0.622  0.200  0.178
1        5   69    7     81  0.062  0.852  0.086
2       19   12   53     84  0.226  0.143  0.631
Total   80   99   76    255  0.314  0.388  0.298

>>>>>> LAP 2

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 416(35.11%)
Label 1: 392(33.08%)
Label 2: 377(31.81%)
Data validation:
Label 0: 94(37.01%)
Label 1: 89(35.04%)
Label 2: 71(27.95%)
Data test:
Label 0: 105(41.18%)
Label 1: 79(30.98%)
Label 2: 71(27.84%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:2
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.05262116778471842, -0.0068022526860766225, -0.045818905028538595]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.8025 - tp: 790.0000 - fp: 587.0000 - tn: 2293.0000 - fn: 650.0000 - accuracy: 0.7137 - precision: 0.5737 - recall: 0.5486 - auc: 0.7419 - prc: 0.6018 - val_loss: 1.2847 - val_tp: 152.0000 - val_fp: 92.0000 - val_tn: 416.0000 - val_fn: 102.0000 - val_accuracy: 0.7454 - val_precision: 0.6230 - val_recall: 0.5984 - val_auc: 0.8061 - val_prc: 0.6721 - 12s/epoch - 194ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7015 - tp: 913.0000 - fp: 244.0000 - tn: 2126.0000 - fn: 272.0000 - accuracy: 0.8549 - precision: 0.7891 - recall: 0.7705 - auc: 0.9149 - prc: 0.8492 - val_loss: 1.1933 - val_tp: 174.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 80.0000 - val_accuracy: 0.8045 - val_precision: 0.7160 - val_recall: 0.6850 - val_auc: 0.8520 - val_prc: 0.7594 - 10s/epoch - 159ms/step
Epoch 3/200
60/60 - 10s - loss: 0.4597 - tp: 1012.0000 - fp: 159.0000 - tn: 2211.0000 - fn: 173.0000 - accuracy: 0.9066 - precision: 0.8642 - recall: 0.8540 - auc: 0.9541 - prc: 0.9171 - val_loss: 1.2489 - val_tp: 172.0000 - val_fp: 73.0000 - val_tn: 435.0000 - val_fn: 82.0000 - val_accuracy: 0.7966 - val_precision: 0.7020 - val_recall: 0.6772 - val_auc: 0.8361 - val_prc: 0.7347 - 10s/epoch - 161ms/step
Epoch 4/200
60/60 - 10s - loss: 0.2901 - tp: 1067.0000 - fp: 108.0000 - tn: 2262.0000 - fn: 118.0000 - accuracy: 0.9364 - precision: 0.9081 - recall: 0.9004 - auc: 0.9784 - prc: 0.9597 - val_loss: 1.1138 - val_tp: 191.0000 - val_fp: 58.0000 - val_tn: 450.0000 - val_fn: 63.0000 - val_accuracy: 0.8412 - val_precision: 0.7671 - val_recall: 0.7520 - val_auc: 0.8645 - val_prc: 0.7745 - 10s/epoch - 161ms/step
Epoch 5/200
60/60 - 10s - loss: 0.3140 - tp: 1076.0000 - fp: 105.0000 - tn: 2265.0000 - fn: 109.0000 - accuracy: 0.9398 - precision: 0.9111 - recall: 0.9080 - auc: 0.9762 - prc: 0.9566 - val_loss: 1.3939 - val_tp: 186.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.7381 - val_recall: 0.7323 - val_auc: 0.8383 - val_prc: 0.7325 - 10s/epoch - 162ms/step
Epoch 6/200
60/60 - 9s - loss: 0.2976 - tp: 1060.0000 - fp: 112.0000 - tn: 2258.0000 - fn: 125.0000 - accuracy: 0.9333 - precision: 0.9044 - recall: 0.8945 - auc: 0.9773 - prc: 0.9582 - val_loss: 1.3391 - val_tp: 199.0000 - val_fp: 53.0000 - val_tn: 455.0000 - val_fn: 55.0000 - val_accuracy: 0.8583 - val_precision: 0.7897 - val_recall: 0.7835 - val_auc: 0.8699 - val_prc: 0.7753 - 9s/epoch - 155ms/step
Epoch 7/200
60/60 - 9s - loss: 0.2141 - tp: 1105.0000 - fp: 74.0000 - tn: 2296.0000 - fn: 80.0000 - accuracy: 0.9567 - precision: 0.9372 - recall: 0.9325 - auc: 0.9862 - prc: 0.9737 - val_loss: 1.2190 - val_tp: 185.0000 - val_fp: 67.0000 - val_tn: 441.0000 - val_fn: 69.0000 - val_accuracy: 0.8215 - val_precision: 0.7341 - val_recall: 0.7283 - val_auc: 0.8759 - val_prc: 0.7926 - 9s/epoch - 155ms/step
Epoch 8/200
60/60 - 9s - loss: 0.2210 - tp: 1103.0000 - fp: 71.0000 - tn: 2299.0000 - fn: 82.0000 - accuracy: 0.9570 - precision: 0.9395 - recall: 0.9308 - auc: 0.9886 - prc: 0.9772 - val_loss: 1.2848 - val_tp: 197.0000 - val_fp: 53.0000 - val_tn: 455.0000 - val_fn: 57.0000 - val_accuracy: 0.8556 - val_precision: 0.7880 - val_recall: 0.7756 - val_auc: 0.8842 - val_prc: 0.7925 - 9s/epoch - 157ms/step
Epoch 9/200
60/60 - 9s - loss: 0.0949 - tp: 1148.0000 - fp: 34.0000 - tn: 2336.0000 - fn: 37.0000 - accuracy: 0.9800 - precision: 0.9712 - recall: 0.9688 - auc: 0.9967 - prc: 0.9942 - val_loss: 1.0987 - val_tp: 193.0000 - val_fp: 58.0000 - val_tn: 450.0000 - val_fn: 61.0000 - val_accuracy: 0.8438 - val_precision: 0.7689 - val_recall: 0.7598 - val_auc: 0.9040 - val_prc: 0.8377 - 9s/epoch - 157ms/step
Epoch 10/200
60/60 - 10s - loss: 0.0946 - tp: 1148.0000 - fp: 34.0000 - tn: 2336.0000 - fn: 37.0000 - accuracy: 0.9800 - precision: 0.9712 - recall: 0.9688 - auc: 0.9961 - prc: 0.9929 - val_loss: 1.1313 - val_tp: 189.0000 - val_fp: 63.0000 - val_tn: 445.0000 - val_fn: 65.0000 - val_accuracy: 0.8320 - val_precision: 0.7500 - val_recall: 0.7441 - val_auc: 0.8968 - val_prc: 0.8299 - 10s/epoch - 159ms/step
Epoch 11/200
60/60 - 10s - loss: 0.1441 - tp: 1142.0000 - fp: 41.0000 - tn: 2329.0000 - fn: 43.0000 - accuracy: 0.9764 - precision: 0.9653 - recall: 0.9637 - auc: 0.9928 - prc: 0.9867 - val_loss: 1.1384 - val_tp: 193.0000 - val_fp: 57.0000 - val_tn: 451.0000 - val_fn: 61.0000 - val_accuracy: 0.8451 - val_precision: 0.7720 - val_recall: 0.7598 - val_auc: 0.8952 - val_prc: 0.8245 - 10s/epoch - 164ms/step
Epoch 12/200
60/60 - 10s - loss: 0.1270 - tp: 1135.0000 - fp: 49.0000 - tn: 2321.0000 - fn: 50.0000 - accuracy: 0.9722 - precision: 0.9586 - recall: 0.9578 - auc: 0.9941 - prc: 0.9896 - val_loss: 1.3694 - val_tp: 187.0000 - val_fp: 65.0000 - val_tn: 443.0000 - val_fn: 67.0000 - val_accuracy: 0.8268 - val_precision: 0.7421 - val_recall: 0.7362 - val_auc: 0.8683 - val_prc: 0.7780 - 10s/epoch - 166ms/step
Epoch 13/200
60/60 - 9s - loss: 0.0916 - tp: 1145.0000 - fp: 39.0000 - tn: 2331.0000 - fn: 40.0000 - accuracy: 0.9778 - precision: 0.9671 - recall: 0.9662 - auc: 0.9971 - prc: 0.9943 - val_loss: 1.4132 - val_tp: 188.0000 - val_fp: 64.0000 - val_tn: 444.0000 - val_fn: 66.0000 - val_accuracy: 0.8294 - val_precision: 0.7460 - val_recall: 0.7402 - val_auc: 0.8781 - val_prc: 0.7906 - 9s/epoch - 158ms/step
Epoch 14/200
60/60 - 10s - loss: 0.1253 - tp: 1141.0000 - fp: 43.0000 - tn: 2327.0000 - fn: 44.0000 - accuracy: 0.9755 - precision: 0.9637 - recall: 0.9629 - auc: 0.9923 - prc: 0.9852 - val_loss: 1.6675 - val_tp: 185.0000 - val_fp: 67.0000 - val_tn: 441.0000 - val_fn: 69.0000 - val_accuracy: 0.8215 - val_precision: 0.7341 - val_recall: 0.7283 - val_auc: 0.8653 - val_prc: 0.7738 - 10s/epoch - 159ms/step
Epoch 14: early stopping
8/8 [==============================] - 0s 36ms/step
13/13 [==============================] - 1s 38ms/step - loss: 1.4367 - tp: 196.0000 - fp: 57.0000 - tn: 453.0000 - fn: 59.0000 - accuracy: 0.8484 - precision: 0.7747 - recall: 0.7686 - auc: 0.8762 - prc: 0.7932

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.91      0.67      0.77       105
           1       0.73      0.87      0.79        79
           2       0.71      0.83      0.77        71

    accuracy                           0.78       255
   macro avg       0.78      0.79      0.78       255
weighted avg       0.80      0.78      0.78       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       70   18   17    105  0.667  0.171  0.162
1        3   69    7     79  0.038  0.873  0.089
2        4    8   59     71  0.056  0.113  0.831
Total   77   95   83    255  0.302  0.373  0.325

>>>>>> LAP 3

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 427(36.03%)
Label 1: 394(33.25%)
Label 2: 364(30.72%)
Data validation:
Label 0: 98(38.58%)
Label 1: 83(32.68%)
Label 2: 73(28.74%)
Data test:
Label 0: 90(35.29%)
Label 1: 83(32.55%)
Label 2: 82(32.16%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:3
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.08002108041455396, -0.00041202351613680286, -0.07960906517732992]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.7546 - tp: 824.0000 - fp: 567.0000 - tn: 2313.0000 - fn: 616.0000 - accuracy: 0.7262 - precision: 0.5924 - recall: 0.5722 - auc: 0.7544 - prc: 0.6162 - val_loss: 1.4245 - val_tp: 147.0000 - val_fp: 93.0000 - val_tn: 415.0000 - val_fn: 107.0000 - val_accuracy: 0.7375 - val_precision: 0.6125 - val_recall: 0.5787 - val_auc: 0.7854 - val_prc: 0.6729 - 12s/epoch - 193ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7332 - tp: 921.0000 - fp: 242.0000 - tn: 2128.0000 - fn: 264.0000 - accuracy: 0.8577 - precision: 0.7919 - recall: 0.7772 - auc: 0.9162 - prc: 0.8536 - val_loss: 1.3725 - val_tp: 161.0000 - val_fp: 87.0000 - val_tn: 421.0000 - val_fn: 93.0000 - val_accuracy: 0.7638 - val_precision: 0.6492 - val_recall: 0.6339 - val_auc: 0.8069 - val_prc: 0.6887 - 10s/epoch - 163ms/step
Epoch 3/200
60/60 - 10s - loss: 0.5013 - tp: 980.0000 - fp: 191.0000 - tn: 2179.0000 - fn: 205.0000 - accuracy: 0.8886 - precision: 0.8369 - recall: 0.8270 - auc: 0.9493 - prc: 0.9081 - val_loss: 1.1410 - val_tp: 173.0000 - val_fp: 76.0000 - val_tn: 432.0000 - val_fn: 81.0000 - val_accuracy: 0.7940 - val_precision: 0.6948 - val_recall: 0.6811 - val_auc: 0.8454 - val_prc: 0.7423 - 10s/epoch - 163ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3058 - tp: 1069.0000 - fp: 110.0000 - tn: 2260.0000 - fn: 116.0000 - accuracy: 0.9364 - precision: 0.9067 - recall: 0.9021 - auc: 0.9772 - prc: 0.9580 - val_loss: 1.0151 - val_tp: 181.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 73.0000 - val_accuracy: 0.8136 - val_precision: 0.7240 - val_recall: 0.7126 - val_auc: 0.8674 - val_prc: 0.7835 - 10s/epoch - 162ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2710 - tp: 1082.0000 - fp: 94.0000 - tn: 2276.0000 - fn: 103.0000 - accuracy: 0.9446 - precision: 0.9201 - recall: 0.9131 - auc: 0.9805 - prc: 0.9641 - val_loss: 1.1292 - val_tp: 179.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 75.0000 - val_accuracy: 0.8150 - val_precision: 0.7306 - val_recall: 0.7047 - val_auc: 0.8612 - val_prc: 0.7638 - 10s/epoch - 164ms/step
Epoch 6/200
60/60 - 10s - loss: 0.1695 - tp: 1117.0000 - fp: 62.0000 - tn: 2308.0000 - fn: 68.0000 - accuracy: 0.9634 - precision: 0.9474 - recall: 0.9426 - auc: 0.9905 - prc: 0.9836 - val_loss: 1.2777 - val_tp: 179.0000 - val_fp: 70.0000 - val_tn: 438.0000 - val_fn: 75.0000 - val_accuracy: 0.8097 - val_precision: 0.7189 - val_recall: 0.7047 - val_auc: 0.8482 - val_prc: 0.7415 - 10s/epoch - 158ms/step
Epoch 7/200
60/60 - 9s - loss: 0.1956 - tp: 1108.0000 - fp: 69.0000 - tn: 2301.0000 - fn: 77.0000 - accuracy: 0.9589 - precision: 0.9414 - recall: 0.9350 - auc: 0.9894 - prc: 0.9797 - val_loss: 1.2378 - val_tp: 178.0000 - val_fp: 73.0000 - val_tn: 435.0000 - val_fn: 76.0000 - val_accuracy: 0.8045 - val_precision: 0.7092 - val_recall: 0.7008 - val_auc: 0.8519 - val_prc: 0.7565 - 9s/epoch - 157ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1377 - tp: 1117.0000 - fp: 61.0000 - tn: 2309.0000 - fn: 68.0000 - accuracy: 0.9637 - precision: 0.9482 - recall: 0.9426 - auc: 0.9934 - prc: 0.9870 - val_loss: 1.4479 - val_tp: 182.0000 - val_fp: 67.0000 - val_tn: 441.0000 - val_fn: 72.0000 - val_accuracy: 0.8176 - val_precision: 0.7309 - val_recall: 0.7165 - val_auc: 0.8377 - val_prc: 0.7248 - 10s/epoch - 159ms/step
Epoch 9/200
60/60 - 10s - loss: 0.0716 - tp: 1156.0000 - fp: 25.0000 - tn: 2345.0000 - fn: 29.0000 - accuracy: 0.9848 - precision: 0.9788 - recall: 0.9755 - auc: 0.9981 - prc: 0.9962 - val_loss: 1.3646 - val_tp: 179.0000 - val_fp: 72.0000 - val_tn: 436.0000 - val_fn: 75.0000 - val_accuracy: 0.8071 - val_precision: 0.7131 - val_recall: 0.7047 - val_auc: 0.8417 - val_prc: 0.7327 - 10s/epoch - 161ms/step
Epoch 9: early stopping
8/8 [==============================] - 0s 35ms/step
13/13 [==============================] - 0s 36ms/step - loss: 1.2576 - tp: 188.0000 - fp: 65.0000 - tn: 445.0000 - fn: 67.0000 - accuracy: 0.8275 - precision: 0.7431 - recall: 0.7373 - auc: 0.8665 - prc: 0.7840

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.69      0.73      0.71        90
           1       0.74      0.75      0.74        83
           2       0.80      0.74      0.77        82

    accuracy                           0.74       255
   macro avg       0.75      0.74      0.74       255
weighted avg       0.74      0.74      0.74       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       66   13   11     90  0.733  0.144  0.122
1       17   62    4     83  0.205  0.747  0.048
2       12    9   61     82  0.146  0.110  0.744
Total   95   84   76    255  0.373  0.329  0.298

>>>>>> LAP 4

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 416(35.11%)
Label 1: 397(33.5%)
Label 2: 372(31.39%)
Data validation:
Label 0: 95(37.4%)
Label 1: 85(33.46%)
Label 2: 74(29.13%)
Data test:
Label 0: 104(40.78%)
Label 1: 78(30.59%)
Label 2: 73(28.63%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:4
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.05284680755724874, 0.006097827983175964, -0.05894459843086805]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6313 - tp: 804.0000 - fp: 561.0000 - tn: 2319.0000 - fn: 636.0000 - accuracy: 0.7229 - precision: 0.5890 - recall: 0.5583 - auc: 0.7576 - prc: 0.6199 - val_loss: 1.3799 - val_tp: 159.0000 - val_fp: 88.0000 - val_tn: 420.0000 - val_fn: 95.0000 - val_accuracy: 0.7598 - val_precision: 0.6437 - val_recall: 0.6260 - val_auc: 0.7904 - val_prc: 0.6565 - 12s/epoch - 198ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7447 - tp: 912.0000 - fp: 253.0000 - tn: 2117.0000 - fn: 273.0000 - accuracy: 0.8520 - precision: 0.7828 - recall: 0.7696 - auc: 0.9103 - prc: 0.8432 - val_loss: 1.6264 - val_tp: 161.0000 - val_fp: 84.0000 - val_tn: 424.0000 - val_fn: 93.0000 - val_accuracy: 0.7677 - val_precision: 0.6571 - val_recall: 0.6339 - val_auc: 0.7831 - val_prc: 0.6506 - 10s/epoch - 166ms/step
Epoch 3/200
60/60 - 10s - loss: 0.4761 - tp: 1003.0000 - fp: 172.0000 - tn: 2198.0000 - fn: 182.0000 - accuracy: 0.9004 - precision: 0.8536 - recall: 0.8464 - auc: 0.9539 - prc: 0.9154 - val_loss: 1.1103 - val_tp: 183.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.7349 - val_recall: 0.7205 - val_auc: 0.8598 - val_prc: 0.7874 - 10s/epoch - 163ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3491 - tp: 1059.0000 - fp: 113.0000 - tn: 2257.0000 - fn: 126.0000 - accuracy: 0.9328 - precision: 0.9036 - recall: 0.8937 - auc: 0.9711 - prc: 0.9447 - val_loss: 1.5043 - val_tp: 171.0000 - val_fp: 79.0000 - val_tn: 429.0000 - val_fn: 83.0000 - val_accuracy: 0.7874 - val_precision: 0.6840 - val_recall: 0.6732 - val_auc: 0.8307 - val_prc: 0.7055 - 10s/epoch - 164ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2968 - tp: 1076.0000 - fp: 92.0000 - tn: 2278.0000 - fn: 109.0000 - accuracy: 0.9435 - precision: 0.9212 - recall: 0.9080 - auc: 0.9784 - prc: 0.9612 - val_loss: 1.3618 - val_tp: 173.0000 - val_fp: 78.0000 - val_tn: 430.0000 - val_fn: 81.0000 - val_accuracy: 0.7913 - val_precision: 0.6892 - val_recall: 0.6811 - val_auc: 0.8388 - val_prc: 0.7314 - 10s/epoch - 164ms/step
Epoch 6/200
60/60 - 10s - loss: 0.3396 - tp: 1085.0000 - fp: 94.0000 - tn: 2276.0000 - fn: 100.0000 - accuracy: 0.9454 - precision: 0.9203 - recall: 0.9156 - auc: 0.9754 - prc: 0.9562 - val_loss: 1.4957 - val_tp: 177.0000 - val_fp: 75.0000 - val_tn: 433.0000 - val_fn: 77.0000 - val_accuracy: 0.8005 - val_precision: 0.7024 - val_recall: 0.6969 - val_auc: 0.8298 - val_prc: 0.7120 - 10s/epoch - 163ms/step
Epoch 7/200
60/60 - 10s - loss: 0.1534 - tp: 1125.0000 - fp: 57.0000 - tn: 2313.0000 - fn: 60.0000 - accuracy: 0.9671 - precision: 0.9518 - recall: 0.9494 - auc: 0.9905 - prc: 0.9820 - val_loss: 1.3947 - val_tp: 176.0000 - val_fp: 77.0000 - val_tn: 431.0000 - val_fn: 78.0000 - val_accuracy: 0.7966 - val_precision: 0.6957 - val_recall: 0.6929 - val_auc: 0.8419 - val_prc: 0.7328 - 10s/epoch - 165ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1222 - tp: 1142.0000 - fp: 39.0000 - tn: 2331.0000 - fn: 43.0000 - accuracy: 0.9769 - precision: 0.9670 - recall: 0.9637 - auc: 0.9940 - prc: 0.9899 - val_loss: 1.4353 - val_tp: 179.0000 - val_fp: 71.0000 - val_tn: 437.0000 - val_fn: 75.0000 - val_accuracy: 0.8084 - val_precision: 0.7160 - val_recall: 0.7047 - val_auc: 0.8411 - val_prc: 0.7332 - 10s/epoch - 162ms/step
Epoch 8: early stopping
8/8 [==============================] - 0s 48ms/step
13/13 [==============================] - 1s 36ms/step - loss: 1.2351 - tp: 193.0000 - fp: 60.0000 - tn: 450.0000 - fn: 62.0000 - accuracy: 0.8405 - precision: 0.7628 - recall: 0.7569 - auc: 0.8698 - prc: 0.7853

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.78      0.73      0.76       104
           1       0.78      0.73      0.75        78
           2       0.73      0.85      0.78        73

    accuracy                           0.76       255
   macro avg       0.76      0.77      0.77       255
weighted avg       0.77      0.76      0.76       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       76   14   14    104  0.731  0.135  0.135
1       12   57    9     78  0.154  0.731  0.115
2        9    2   62     73  0.123  0.027  0.849
Total   97   73   85    255  0.380  0.286  0.333

>>>>>> LAP 5

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 434(36.62%)
Label 1: 390(32.91%)
Label 2: 361(30.46%)
Data validation:
Label 0: 91(35.83%)
Label 2: 89(35.04%)
Label 1: 74(29.13%)
Data test:
Label 1: 96(37.65%)
Label 0: 90(35.29%)
Label 2: 69(27.06%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:5
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.09702144179219334, -0.009876353184519392, -0.08714513397533065]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6613 - tp: 838.0000 - fp: 544.0000 - tn: 2336.0000 - fn: 602.0000 - accuracy: 0.7347 - precision: 0.6064 - recall: 0.5819 - auc: 0.7644 - prc: 0.6331 - val_loss: 1.7907 - val_tp: 141.0000 - val_fp: 103.0000 - val_tn: 405.0000 - val_fn: 113.0000 - val_accuracy: 0.7165 - val_precision: 0.5779 - val_recall: 0.5551 - val_auc: 0.7260 - val_prc: 0.5595 - 12s/epoch - 197ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7272 - tp: 921.0000 - fp: 236.0000 - tn: 2134.0000 - fn: 264.0000 - accuracy: 0.8594 - precision: 0.7960 - recall: 0.7772 - auc: 0.9131 - prc: 0.8491 - val_loss: 1.3333 - val_tp: 165.0000 - val_fp: 81.0000 - val_tn: 427.0000 - val_fn: 89.0000 - val_accuracy: 0.7769 - val_precision: 0.6707 - val_recall: 0.6496 - val_auc: 0.8201 - val_prc: 0.6897 - 10s/epoch - 163ms/step
Epoch 3/200
60/60 - 10s - loss: 0.5467 - tp: 981.0000 - fp: 189.0000 - tn: 2181.0000 - fn: 204.0000 - accuracy: 0.8895 - precision: 0.8385 - recall: 0.8278 - auc: 0.9418 - prc: 0.8976 - val_loss: 1.2712 - val_tp: 177.0000 - val_fp: 70.0000 - val_tn: 438.0000 - val_fn: 77.0000 - val_accuracy: 0.8071 - val_precision: 0.7166 - val_recall: 0.6969 - val_auc: 0.8387 - val_prc: 0.7368 - 10s/epoch - 161ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3175 - tp: 1058.0000 - fp: 118.0000 - tn: 2252.0000 - fn: 127.0000 - accuracy: 0.9311 - precision: 0.8997 - recall: 0.8928 - auc: 0.9757 - prc: 0.9582 - val_loss: 1.3952 - val_tp: 169.0000 - val_fp: 80.0000 - val_tn: 428.0000 - val_fn: 85.0000 - val_accuracy: 0.7835 - val_precision: 0.6787 - val_recall: 0.6654 - val_auc: 0.8273 - val_prc: 0.7079 - 10s/epoch - 161ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2608 - tp: 1086.0000 - fp: 99.0000 - tn: 2271.0000 - fn: 99.0000 - accuracy: 0.9443 - precision: 0.9165 - recall: 0.9165 - auc: 0.9813 - prc: 0.9645 - val_loss: 1.3881 - val_tp: 186.0000 - val_fp: 63.0000 - val_tn: 445.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.7470 - val_recall: 0.7323 - val_auc: 0.8535 - val_prc: 0.7405 - 10s/epoch - 162ms/step
Epoch 6/200
60/60 - 10s - loss: 0.2345 - tp: 1089.0000 - fp: 88.0000 - tn: 2282.0000 - fn: 96.0000 - accuracy: 0.9482 - precision: 0.9252 - recall: 0.9190 - auc: 0.9864 - prc: 0.9751 - val_loss: 1.6028 - val_tp: 168.0000 - val_fp: 80.0000 - val_tn: 428.0000 - val_fn: 86.0000 - val_accuracy: 0.7822 - val_precision: 0.6774 - val_recall: 0.6614 - val_auc: 0.8275 - val_prc: 0.6996 - 10s/epoch - 161ms/step
Epoch 7/200
60/60 - 10s - loss: 0.1952 - tp: 1120.0000 - fp: 59.0000 - tn: 2311.0000 - fn: 65.0000 - accuracy: 0.9651 - precision: 0.9500 - recall: 0.9451 - auc: 0.9892 - prc: 0.9805 - val_loss: 1.6090 - val_tp: 166.0000 - val_fp: 83.0000 - val_tn: 425.0000 - val_fn: 88.0000 - val_accuracy: 0.7756 - val_precision: 0.6667 - val_recall: 0.6535 - val_auc: 0.8260 - val_prc: 0.6929 - 10s/epoch - 161ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1943 - tp: 1106.0000 - fp: 72.0000 - tn: 2298.0000 - fn: 79.0000 - accuracy: 0.9575 - precision: 0.9389 - recall: 0.9333 - auc: 0.9883 - prc: 0.9770 - val_loss: 1.5444 - val_tp: 186.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.7381 - val_recall: 0.7323 - val_auc: 0.8312 - val_prc: 0.7152 - 10s/epoch - 163ms/step
Epoch 8: early stopping
8/8 [==============================] - 0s 38ms/step
13/13 [==============================] - 1s 37ms/step - loss: 1.3726 - tp: 180.0000 - fp: 68.0000 - tn: 442.0000 - fn: 75.0000 - accuracy: 0.8131 - precision: 0.7258 - recall: 0.7059 - auc: 0.8676 - prc: 0.7777

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.70      0.63      0.67        90
           1       0.75      0.73      0.74        96
           2       0.70      0.83      0.76        69

    accuracy                           0.72       255
   macro avg       0.72      0.73      0.72       255
weighted avg       0.72      0.72      0.72       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       57   17   16     90  0.633  0.189  0.178
1       18   70    8     96  0.188  0.729  0.083
2        6    6   57     69  0.087  0.087  0.826
Total   81   93   81    255  0.318  0.365  0.318

>>>>>> LAP 6

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 444(37.47%)
Label 1: 384(32.41%)
Label 2: 357(30.13%)
Data validation:
Label 1: 93(36.61%)
Label 0: 81(31.89%)
Label 2: 80(31.5%)
Data test:
Label 0: 90(35.29%)
Label 1: 83(32.55%)
Label 2: 82(32.16%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:6
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.1210902650503026, -0.02409174479419453, -0.09699851560228419]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6939 - tp: 812.0000 - fp: 563.0000 - tn: 2317.0000 - fn: 628.0000 - accuracy: 0.7243 - precision: 0.5905 - recall: 0.5639 - auc: 0.7530 - prc: 0.6212 - val_loss: 0.9538 - val_tp: 176.0000 - val_fp: 71.0000 - val_tn: 437.0000 - val_fn: 78.0000 - val_accuracy: 0.8045 - val_precision: 0.7126 - val_recall: 0.6929 - val_auc: 0.8503 - val_prc: 0.7578 - 12s/epoch - 206ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7870 - tp: 895.0000 - fp: 266.0000 - tn: 2104.0000 - fn: 290.0000 - accuracy: 0.8436 - precision: 0.7709 - recall: 0.7553 - auc: 0.9036 - prc: 0.8328 - val_loss: 0.9744 - val_tp: 180.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 74.0000 - val_accuracy: 0.8123 - val_precision: 0.7229 - val_recall: 0.7087 - val_auc: 0.8700 - val_prc: 0.7841 - 10s/epoch - 164ms/step
Epoch 3/200
60/60 - 10s - loss: 0.5158 - tp: 998.0000 - fp: 171.0000 - tn: 2199.0000 - fn: 187.0000 - accuracy: 0.8993 - precision: 0.8537 - recall: 0.8422 - auc: 0.9519 - prc: 0.9165 - val_loss: 1.2871 - val_tp: 167.0000 - val_fp: 81.0000 - val_tn: 427.0000 - val_fn: 87.0000 - val_accuracy: 0.7795 - val_precision: 0.6734 - val_recall: 0.6575 - val_auc: 0.8280 - val_prc: 0.7234 - 10s/epoch - 166ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3180 - tp: 1050.0000 - fp: 120.0000 - tn: 2250.0000 - fn: 135.0000 - accuracy: 0.9283 - precision: 0.8974 - recall: 0.8861 - auc: 0.9740 - prc: 0.9505 - val_loss: 1.0374 - val_tp: 186.0000 - val_fp: 59.0000 - val_tn: 449.0000 - val_fn: 68.0000 - val_accuracy: 0.8333 - val_precision: 0.7592 - val_recall: 0.7323 - val_auc: 0.8797 - val_prc: 0.8105 - 10s/epoch - 163ms/step
Epoch 5/200
60/60 - 10s - loss: 0.3070 - tp: 1064.0000 - fp: 112.0000 - tn: 2258.0000 - fn: 121.0000 - accuracy: 0.9345 - precision: 0.9048 - recall: 0.8979 - auc: 0.9760 - prc: 0.9567 - val_loss: 1.0212 - val_tp: 187.0000 - val_fp: 65.0000 - val_tn: 443.0000 - val_fn: 67.0000 - val_accuracy: 0.8268 - val_precision: 0.7421 - val_recall: 0.7362 - val_auc: 0.8709 - val_prc: 0.7954 - 10s/epoch - 163ms/step
Epoch 6/200
60/60 - 10s - loss: 0.1986 - tp: 1107.0000 - fp: 71.0000 - tn: 2299.0000 - fn: 78.0000 - accuracy: 0.9581 - precision: 0.9397 - recall: 0.9342 - auc: 0.9876 - prc: 0.9771 - val_loss: 0.9519 - val_tp: 190.0000 - val_fp: 60.0000 - val_tn: 448.0000 - val_fn: 64.0000 - val_accuracy: 0.8373 - val_precision: 0.7600 - val_recall: 0.7480 - val_auc: 0.8885 - val_prc: 0.8191 - 10s/epoch - 164ms/step
Epoch 7/200
60/60 - 10s - loss: 0.2009 - tp: 1104.0000 - fp: 77.0000 - tn: 2293.0000 - fn: 81.0000 - accuracy: 0.9556 - precision: 0.9348 - recall: 0.9316 - auc: 0.9881 - prc: 0.9778 - val_loss: 1.1365 - val_tp: 181.0000 - val_fp: 65.0000 - val_tn: 443.0000 - val_fn: 73.0000 - val_accuracy: 0.8189 - val_precision: 0.7358 - val_recall: 0.7126 - val_auc: 0.8717 - val_prc: 0.7799 - 10s/epoch - 164ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1249 - tp: 1126.0000 - fp: 56.0000 - tn: 2314.0000 - fn: 59.0000 - accuracy: 0.9677 - precision: 0.9526 - recall: 0.9502 - auc: 0.9950 - prc: 0.9903 - val_loss: 0.9930 - val_tp: 185.0000 - val_fp: 64.0000 - val_tn: 444.0000 - val_fn: 69.0000 - val_accuracy: 0.8255 - val_precision: 0.7430 - val_recall: 0.7283 - val_auc: 0.8900 - val_prc: 0.8168 - 10s/epoch - 161ms/step
Epoch 9/200
60/60 - 10s - loss: 0.1506 - tp: 1130.0000 - fp: 51.0000 - tn: 2319.0000 - fn: 55.0000 - accuracy: 0.9702 - precision: 0.9568 - recall: 0.9536 - auc: 0.9907 - prc: 0.9818 - val_loss: 1.1158 - val_tp: 192.0000 - val_fp: 59.0000 - val_tn: 449.0000 - val_fn: 62.0000 - val_accuracy: 0.8412 - val_precision: 0.7649 - val_recall: 0.7559 - val_auc: 0.8853 - val_prc: 0.7930 - 10s/epoch - 163ms/step
Epoch 10/200
60/60 - 10s - loss: 0.1366 - tp: 1143.0000 - fp: 36.0000 - tn: 2334.0000 - fn: 42.0000 - accuracy: 0.9781 - precision: 0.9695 - recall: 0.9646 - auc: 0.9930 - prc: 0.9858 - val_loss: 1.1258 - val_tp: 190.0000 - val_fp: 62.0000 - val_tn: 446.0000 - val_fn: 64.0000 - val_accuracy: 0.8346 - val_precision: 0.7540 - val_recall: 0.7480 - val_auc: 0.8735 - val_prc: 0.7877 - 10s/epoch - 164ms/step
Epoch 11/200
60/60 - 10s - loss: 0.0799 - tp: 1152.0000 - fp: 33.0000 - tn: 2337.0000 - fn: 33.0000 - accuracy: 0.9814 - precision: 0.9722 - recall: 0.9722 - auc: 0.9966 - prc: 0.9931 - val_loss: 1.0470 - val_tp: 195.0000 - val_fp: 54.0000 - val_tn: 454.0000 - val_fn: 59.0000 - val_accuracy: 0.8517 - val_precision: 0.7831 - val_recall: 0.7677 - val_auc: 0.8882 - val_prc: 0.8095 - 10s/epoch - 162ms/step
Epoch 11: early stopping
8/8 [==============================] - 0s 39ms/step
13/13 [==============================] - 1s 44ms/step - loss: 1.4078 - tp: 183.0000 - fp: 69.0000 - tn: 441.0000 - fn: 72.0000 - accuracy: 0.8157 - precision: 0.7262 - recall: 0.7176 - auc: 0.8677 - prc: 0.7841

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.66      0.68      0.67        90
           1       0.72      0.65      0.68        83
           2       0.77      0.83      0.80        82

    accuracy                           0.72       255
   macro avg       0.72      0.72      0.72       255
weighted avg       0.72      0.72      0.72       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       61   18   11     90  0.678  0.200  0.122
1       20   54    9     83  0.241  0.651  0.108
2       11    3   68     82  0.134  0.037  0.829
Total   92   75   88    255  0.361  0.294  0.345

>>>>>> LAP 7

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 427(36.03%)
Label 1: 398(33.59%)
Label 2: 360(30.38%)
Data validation:
Label 0: 91(35.83%)
Label 2: 82(32.28%)
Label 1: 81(31.89%)
Data test:
Label 0: 97(38.04%)
Label 1: 81(31.76%)
Label 2: 77(30.2%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:7
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.08033732905536464, 0.010005321111177799, -0.09034265272310414]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6387 - tp: 834.0000 - fp: 560.0000 - tn: 2320.0000 - fn: 606.0000 - accuracy: 0.7301 - precision: 0.5983 - recall: 0.5792 - auc: 0.7627 - prc: 0.6216 - val_loss: 1.5221 - val_tp: 148.0000 - val_fp: 95.0000 - val_tn: 413.0000 - val_fn: 106.0000 - val_accuracy: 0.7362 - val_precision: 0.6091 - val_recall: 0.5827 - val_auc: 0.7668 - val_prc: 0.6242 - 12s/epoch - 202ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7840 - tp: 910.0000 - fp: 251.0000 - tn: 2119.0000 - fn: 275.0000 - accuracy: 0.8520 - precision: 0.7838 - recall: 0.7679 - auc: 0.9098 - prc: 0.8453 - val_loss: 1.5863 - val_tp: 160.0000 - val_fp: 89.0000 - val_tn: 419.0000 - val_fn: 94.0000 - val_accuracy: 0.7598 - val_precision: 0.6426 - val_recall: 0.6299 - val_auc: 0.8127 - val_prc: 0.7041 - 10s/epoch - 162ms/step
Epoch 3/200
60/60 - 10s - loss: 0.4494 - tp: 1010.0000 - fp: 161.0000 - tn: 2209.0000 - fn: 175.0000 - accuracy: 0.9055 - precision: 0.8625 - recall: 0.8523 - auc: 0.9583 - prc: 0.9239 - val_loss: 1.1385 - val_tp: 174.0000 - val_fp: 65.0000 - val_tn: 443.0000 - val_fn: 80.0000 - val_accuracy: 0.8097 - val_precision: 0.7280 - val_recall: 0.6850 - val_auc: 0.8574 - val_prc: 0.7440 - 10s/epoch - 164ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3656 - tp: 1039.0000 - fp: 140.0000 - tn: 2230.0000 - fn: 146.0000 - accuracy: 0.9195 - precision: 0.8813 - recall: 0.8768 - auc: 0.9683 - prc: 0.9400 - val_loss: 1.5323 - val_tp: 168.0000 - val_fp: 81.0000 - val_tn: 427.0000 - val_fn: 86.0000 - val_accuracy: 0.7808 - val_precision: 0.6747 - val_recall: 0.6614 - val_auc: 0.8233 - val_prc: 0.7010 - 10s/epoch - 164ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2959 - tp: 1070.0000 - fp: 105.0000 - tn: 2265.0000 - fn: 115.0000 - accuracy: 0.9381 - precision: 0.9106 - recall: 0.9030 - auc: 0.9771 - prc: 0.9578 - val_loss: 1.2829 - val_tp: 181.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 73.0000 - val_accuracy: 0.8176 - val_precision: 0.7328 - val_recall: 0.7126 - val_auc: 0.8568 - val_prc: 0.7478 - 10s/epoch - 170ms/step
Epoch 6/200
60/60 - 10s - loss: 0.2396 - tp: 1084.0000 - fp: 92.0000 - tn: 2278.0000 - fn: 101.0000 - accuracy: 0.9457 - precision: 0.9218 - recall: 0.9148 - auc: 0.9846 - prc: 0.9705 - val_loss: 1.8269 - val_tp: 168.0000 - val_fp: 84.0000 - val_tn: 424.0000 - val_fn: 86.0000 - val_accuracy: 0.7769 - val_precision: 0.6667 - val_recall: 0.6614 - val_auc: 0.8067 - val_prc: 0.6742 - 10s/epoch - 171ms/step
Epoch 7/200
60/60 - 11s - loss: 0.2297 - tp: 1095.0000 - fp: 87.0000 - tn: 2283.0000 - fn: 90.0000 - accuracy: 0.9502 - precision: 0.9264 - recall: 0.9241 - auc: 0.9858 - prc: 0.9736 - val_loss: 1.5435 - val_tp: 169.0000 - val_fp: 83.0000 - val_tn: 425.0000 - val_fn: 85.0000 - val_accuracy: 0.7795 - val_precision: 0.6706 - val_recall: 0.6654 - val_auc: 0.8344 - val_prc: 0.7093 - 11s/epoch - 177ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1692 - tp: 1115.0000 - fp: 65.0000 - tn: 2305.0000 - fn: 70.0000 - accuracy: 0.9620 - precision: 0.9449 - recall: 0.9409 - auc: 0.9907 - prc: 0.9824 - val_loss: 1.7795 - val_tp: 169.0000 - val_fp: 82.0000 - val_tn: 426.0000 - val_fn: 85.0000 - val_accuracy: 0.7808 - val_precision: 0.6733 - val_recall: 0.6654 - val_auc: 0.8385 - val_prc: 0.7213 - 10s/epoch - 161ms/step
Epoch 8: early stopping
8/8 [==============================] - 0s 39ms/step
13/13 [==============================] - 1s 43ms/step - loss: 1.2738 - tp: 181.0000 - fp: 71.0000 - tn: 439.0000 - fn: 74.0000 - accuracy: 0.8105 - precision: 0.7183 - recall: 0.7098 - auc: 0.8676 - prc: 0.7922

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.69      0.75      0.72        97
           1       0.74      0.70      0.72        81
           2       0.72      0.68      0.70        77

    accuracy                           0.71       255
   macro avg       0.72      0.71      0.71       255
weighted avg       0.72      0.71      0.71       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       73   11   13     97  0.753  0.113  0.134
1       17   57    7     81  0.210  0.704  0.086
2       16    9   52     77  0.208  0.117  0.675
Total  106   77   72    255  0.416  0.302  0.282

>>>>>> LAP 8

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 442(37.3%)
Label 1: 387(32.66%)
Label 2: 356(30.04%)
Data validation:
Label 0: 95(37.4%)
Label 1: 81(31.89%)
Label 2: 78(30.71%)
Data test:
Label 1: 92(36.08%)
Label 2: 85(33.33%)
Label 0: 78(30.59%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:8
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.11642145487618054, -0.01646373417173553, -0.09995769634948728]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.7632 - tp: 803.0000 - fp: 579.0000 - tn: 2301.0000 - fn: 637.0000 - accuracy: 0.7185 - precision: 0.5810 - recall: 0.5576 - auc: 0.7539 - prc: 0.6114 - val_loss: 1.3350 - val_tp: 158.0000 - val_fp: 87.0000 - val_tn: 421.0000 - val_fn: 96.0000 - val_accuracy: 0.7598 - val_precision: 0.6449 - val_recall: 0.6220 - val_auc: 0.8026 - val_prc: 0.6791 - 12s/epoch - 197ms/step
Epoch 2/200
60/60 - 10s - loss: 0.8089 - tp: 912.0000 - fp: 254.0000 - tn: 2116.0000 - fn: 273.0000 - accuracy: 0.8518 - precision: 0.7822 - recall: 0.7696 - auc: 0.8989 - prc: 0.8216 - val_loss: 1.4354 - val_tp: 167.0000 - val_fp: 80.0000 - val_tn: 428.0000 - val_fn: 87.0000 - val_accuracy: 0.7808 - val_precision: 0.6761 - val_recall: 0.6575 - val_auc: 0.8122 - val_prc: 0.6756 - 10s/epoch - 161ms/step
Epoch 3/200
60/60 - 10s - loss: 0.4588 - tp: 1012.0000 - fp: 159.0000 - tn: 2211.0000 - fn: 173.0000 - accuracy: 0.9066 - precision: 0.8642 - recall: 0.8540 - auc: 0.9562 - prc: 0.9231 - val_loss: 1.0999 - val_tp: 182.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 72.0000 - val_accuracy: 0.8189 - val_precision: 0.7339 - val_recall: 0.7165 - val_auc: 0.8614 - val_prc: 0.7532 - 10s/epoch - 162ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3165 - tp: 1054.0000 - fp: 125.0000 - tn: 2245.0000 - fn: 131.0000 - accuracy: 0.9280 - precision: 0.8940 - recall: 0.8895 - auc: 0.9752 - prc: 0.9543 - val_loss: 1.1019 - val_tp: 182.0000 - val_fp: 64.0000 - val_tn: 444.0000 - val_fn: 72.0000 - val_accuracy: 0.8215 - val_precision: 0.7398 - val_recall: 0.7165 - val_auc: 0.8768 - val_prc: 0.7860 - 10s/epoch - 160ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2654 - tp: 1094.0000 - fp: 88.0000 - tn: 2282.0000 - fn: 91.0000 - accuracy: 0.9496 - precision: 0.9255 - recall: 0.9232 - auc: 0.9790 - prc: 0.9601 - val_loss: 1.3779 - val_tp: 182.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 72.0000 - val_accuracy: 0.8150 - val_precision: 0.7251 - val_recall: 0.7165 - val_auc: 0.8572 - val_prc: 0.7452 - 10s/epoch - 159ms/step
Epoch 6/200
60/60 - 10s - loss: 0.2532 - tp: 1075.0000 - fp: 104.0000 - tn: 2266.0000 - fn: 110.0000 - accuracy: 0.9398 - precision: 0.9118 - recall: 0.9072 - auc: 0.9832 - prc: 0.9694 - val_loss: 1.2601 - val_tp: 189.0000 - val_fp: 62.0000 - val_tn: 446.0000 - val_fn: 65.0000 - val_accuracy: 0.8333 - val_precision: 0.7530 - val_recall: 0.7441 - val_auc: 0.8660 - val_prc: 0.7729 - 10s/epoch - 163ms/step
Epoch 7/200
60/60 - 10s - loss: 0.1478 - tp: 1113.0000 - fp: 66.0000 - tn: 2304.0000 - fn: 72.0000 - accuracy: 0.9612 - precision: 0.9440 - recall: 0.9392 - auc: 0.9932 - prc: 0.9875 - val_loss: 1.4651 - val_tp: 185.0000 - val_fp: 67.0000 - val_tn: 441.0000 - val_fn: 69.0000 - val_accuracy: 0.8215 - val_precision: 0.7341 - val_recall: 0.7283 - val_auc: 0.8476 - val_prc: 0.7375 - 10s/epoch - 159ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1133 - tp: 1141.0000 - fp: 41.0000 - tn: 2329.0000 - fn: 44.0000 - accuracy: 0.9761 - precision: 0.9653 - recall: 0.9629 - auc: 0.9947 - prc: 0.9914 - val_loss: 1.3829 - val_tp: 190.0000 - val_fp: 61.0000 - val_tn: 447.0000 - val_fn: 64.0000 - val_accuracy: 0.8360 - val_precision: 0.7570 - val_recall: 0.7480 - val_auc: 0.8681 - val_prc: 0.7757 - 10s/epoch - 161ms/step
Epoch 8: early stopping
8/8 [==============================] - 0s 43ms/step
13/13 [==============================] - 1s 37ms/step - loss: 1.3822 - tp: 182.0000 - fp: 71.0000 - tn: 439.0000 - fn: 73.0000 - accuracy: 0.8118 - precision: 0.7194 - recall: 0.7137 - auc: 0.8591 - prc: 0.7644

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.64      0.74      0.69        78
           1       0.78      0.64      0.70        92
           2       0.75      0.78      0.76        85

    accuracy                           0.72       255
   macro avg       0.72      0.72      0.72       255
weighted avg       0.73      0.72      0.72       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       58    7   13     78  0.744  0.090  0.167
1       24   59    9     92  0.261  0.641  0.098
2        9   10   66     85  0.106  0.118  0.776
Total   91   76   88    255  0.357  0.298  0.345

>>>>>> LAP 9

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 448(37.81%)
Label 1: 373(31.48%)
Label 2: 364(30.72%)
Data validation:
Label 1: 92(36.22%)
Label 0: 81(31.89%)
Label 2: 81(31.89%)
Data test:
Label 1: 95(37.25%)
Label 0: 86(33.73%)
Label 2: 74(29.02%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:9
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.13028471106918305, -0.05293010170198655, -0.0773546537090614]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.6469 - tp: 792.0000 - fp: 599.0000 - tn: 2281.0000 - fn: 648.0000 - accuracy: 0.7113 - precision: 0.5694 - recall: 0.5500 - auc: 0.7502 - prc: 0.6060 - val_loss: 1.1583 - val_tp: 166.0000 - val_fp: 78.0000 - val_tn: 430.0000 - val_fn: 88.0000 - val_accuracy: 0.7822 - val_precision: 0.6803 - val_recall: 0.6535 - val_auc: 0.8267 - val_prc: 0.7015 - 12s/epoch - 195ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7859 - tp: 904.0000 - fp: 257.0000 - tn: 2113.0000 - fn: 281.0000 - accuracy: 0.8487 - precision: 0.7786 - recall: 0.7629 - auc: 0.9046 - prc: 0.8386 - val_loss: 1.0133 - val_tp: 177.0000 - val_fp: 68.0000 - val_tn: 440.0000 - val_fn: 77.0000 - val_accuracy: 0.8097 - val_precision: 0.7224 - val_recall: 0.6969 - val_auc: 0.8625 - val_prc: 0.7609 - 10s/epoch - 161ms/step
Epoch 3/200
60/60 - 10s - loss: 0.5512 - tp: 980.0000 - fp: 184.0000 - tn: 2186.0000 - fn: 205.0000 - accuracy: 0.8906 - precision: 0.8419 - recall: 0.8270 - auc: 0.9416 - prc: 0.8980 - val_loss: 0.9576 - val_tp: 183.0000 - val_fp: 66.0000 - val_tn: 442.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.7349 - val_recall: 0.7205 - val_auc: 0.8719 - val_prc: 0.7870 - 10s/epoch - 159ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3541 - tp: 1043.0000 - fp: 118.0000 - tn: 2252.0000 - fn: 142.0000 - accuracy: 0.9269 - precision: 0.8984 - recall: 0.8802 - auc: 0.9700 - prc: 0.9465 - val_loss: 1.2034 - val_tp: 181.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 73.0000 - val_accuracy: 0.8136 - val_precision: 0.7240 - val_recall: 0.7126 - val_auc: 0.8560 - val_prc: 0.7513 - 10s/epoch - 162ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2813 - tp: 1075.0000 - fp: 100.0000 - tn: 2270.0000 - fn: 110.0000 - accuracy: 0.9409 - precision: 0.9149 - recall: 0.9072 - auc: 0.9801 - prc: 0.9622 - val_loss: 1.2308 - val_tp: 177.0000 - val_fp: 74.0000 - val_tn: 434.0000 - val_fn: 77.0000 - val_accuracy: 0.8018 - val_precision: 0.7052 - val_recall: 0.6969 - val_auc: 0.8547 - val_prc: 0.7464 - 10s/epoch - 160ms/step
Epoch 6/200
60/60 - 10s - loss: 0.2373 - tp: 1082.0000 - fp: 97.0000 - tn: 2273.0000 - fn: 103.0000 - accuracy: 0.9437 - precision: 0.9177 - recall: 0.9131 - auc: 0.9848 - prc: 0.9718 - val_loss: 1.1916 - val_tp: 177.0000 - val_fp: 73.0000 - val_tn: 435.0000 - val_fn: 77.0000 - val_accuracy: 0.8031 - val_precision: 0.7080 - val_recall: 0.6969 - val_auc: 0.8635 - val_prc: 0.7571 - 10s/epoch - 161ms/step
Epoch 7/200
60/60 - 10s - loss: 0.2084 - tp: 1113.0000 - fp: 66.0000 - tn: 2304.0000 - fn: 72.0000 - accuracy: 0.9612 - precision: 0.9440 - recall: 0.9392 - auc: 0.9857 - prc: 0.9745 - val_loss: 0.9174 - val_tp: 198.0000 - val_fp: 55.0000 - val_tn: 453.0000 - val_fn: 56.0000 - val_accuracy: 0.8543 - val_precision: 0.7826 - val_recall: 0.7795 - val_auc: 0.8946 - val_prc: 0.8206 - 10s/epoch - 159ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1601 - tp: 1122.0000 - fp: 55.0000 - tn: 2315.0000 - fn: 63.0000 - accuracy: 0.9668 - precision: 0.9533 - recall: 0.9468 - auc: 0.9916 - prc: 0.9839 - val_loss: 0.9853 - val_tp: 185.0000 - val_fp: 63.0000 - val_tn: 445.0000 - val_fn: 69.0000 - val_accuracy: 0.8268 - val_precision: 0.7460 - val_recall: 0.7283 - val_auc: 0.8892 - val_prc: 0.8222 - 10s/epoch - 159ms/step
Epoch 9/200
60/60 - 10s - loss: 0.1253 - tp: 1135.0000 - fp: 47.0000 - tn: 2323.0000 - fn: 50.0000 - accuracy: 0.9727 - precision: 0.9602 - recall: 0.9578 - auc: 0.9934 - prc: 0.9874 - val_loss: 0.9639 - val_tp: 195.0000 - val_fp: 58.0000 - val_tn: 450.0000 - val_fn: 59.0000 - val_accuracy: 0.8465 - val_precision: 0.7708 - val_recall: 0.7677 - val_auc: 0.8961 - val_prc: 0.8237 - 10s/epoch - 165ms/step
Epoch 10/200
60/60 - 10s - loss: 0.1090 - tp: 1142.0000 - fp: 42.0000 - tn: 2328.0000 - fn: 43.0000 - accuracy: 0.9761 - precision: 0.9645 - recall: 0.9637 - auc: 0.9959 - prc: 0.9918 - val_loss: 1.1000 - val_tp: 184.0000 - val_fp: 69.0000 - val_tn: 439.0000 - val_fn: 70.0000 - val_accuracy: 0.8176 - val_precision: 0.7273 - val_recall: 0.7244 - val_auc: 0.8867 - val_prc: 0.8041 - 10s/epoch - 159ms/step
Epoch 11/200
60/60 - 10s - loss: 0.0608 - tp: 1161.0000 - fp: 23.0000 - tn: 2347.0000 - fn: 24.0000 - accuracy: 0.9868 - precision: 0.9806 - recall: 0.9797 - auc: 0.9989 - prc: 0.9978 - val_loss: 1.0306 - val_tp: 187.0000 - val_fp: 61.0000 - val_tn: 447.0000 - val_fn: 67.0000 - val_accuracy: 0.8320 - val_precision: 0.7540 - val_recall: 0.7362 - val_auc: 0.8935 - val_prc: 0.8108 - 10s/epoch - 159ms/step
Epoch 12/200
60/60 - 10s - loss: 0.0819 - tp: 1162.0000 - fp: 23.0000 - tn: 2347.0000 - fn: 23.0000 - accuracy: 0.9871 - precision: 0.9806 - recall: 0.9806 - auc: 0.9967 - prc: 0.9949 - val_loss: 1.0590 - val_tp: 199.0000 - val_fp: 54.0000 - val_tn: 454.0000 - val_fn: 55.0000 - val_accuracy: 0.8570 - val_precision: 0.7866 - val_recall: 0.7835 - val_auc: 0.8824 - val_prc: 0.7932 - 10s/epoch - 159ms/step
Epoch 12: early stopping
8/8 [==============================] - 0s 47ms/step
13/13 [==============================] - 1s 37ms/step - loss: 1.2964 - tp: 180.0000 - fp: 74.0000 - tn: 436.0000 - fn: 75.0000 - accuracy: 0.8052 - precision: 0.7087 - recall: 0.7059 - auc: 0.8578 - prc: 0.7667

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.62      0.70      0.66        86
           1       0.85      0.69      0.76        95
           2       0.67      0.73      0.70        74

    accuracy                           0.71       255
   macro avg       0.71      0.71      0.71       255
weighted avg       0.72      0.71      0.71       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       60    9   17     86  0.698  0.105  0.198
1       19   66   10     95  0.200  0.695  0.105
2       17    3   54     74  0.230  0.041  0.730
Total   96   78   81    255  0.376  0.306  0.318

>>>>>> LAP 10

Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1185, Validation: 254, Test: 255
Data train:
Label 0: 447(37.72%)
Label 1: 389(32.83%)
Label 2: 349(29.45%)
Data validation:
Label 1: 88(34.65%)
Label 0: 84(33.07%)
Label 2: 82(32.28%)
Data test:
Label 2: 88(34.51%)
Label 0: 84(32.94%)
Label 1: 83(32.55%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:120
random_state:10
is_shuffle:True
y_to_categorical:True
rebalance:None
hu:2500
output_bias:[0.12882197257477418, -0.010157278420348526, -0.1186646998363674]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:20
Epoch 1/200
60/60 - 12s - loss: 1.8000 - tp: 796.0000 - fp: 589.0000 - tn: 2291.0000 - fn: 644.0000 - accuracy: 0.7146 - precision: 0.5747 - recall: 0.5528 - auc: 0.7438 - prc: 0.5935 - val_loss: 1.0680 - val_tp: 177.0000 - val_fp: 67.0000 - val_tn: 441.0000 - val_fn: 77.0000 - val_accuracy: 0.8110 - val_precision: 0.7254 - val_recall: 0.6969 - val_auc: 0.8421 - val_prc: 0.7272 - 12s/epoch - 194ms/step
Epoch 2/200
60/60 - 10s - loss: 0.7938 - tp: 909.0000 - fp: 255.0000 - tn: 2115.0000 - fn: 276.0000 - accuracy: 0.8506 - precision: 0.7809 - recall: 0.7671 - auc: 0.9030 - prc: 0.8326 - val_loss: 1.0487 - val_tp: 183.0000 - val_fp: 68.0000 - val_tn: 440.0000 - val_fn: 71.0000 - val_accuracy: 0.8176 - val_precision: 0.7291 - val_recall: 0.7205 - val_auc: 0.8611 - val_prc: 0.7522 - 10s/epoch - 159ms/step
Epoch 3/200
60/60 - 10s - loss: 0.4946 - tp: 986.0000 - fp: 182.0000 - tn: 2188.0000 - fn: 199.0000 - accuracy: 0.8928 - precision: 0.8442 - recall: 0.8321 - auc: 0.9498 - prc: 0.9112 - val_loss: 0.8058 - val_tp: 197.0000 - val_fp: 51.0000 - val_tn: 457.0000 - val_fn: 57.0000 - val_accuracy: 0.8583 - val_precision: 0.7944 - val_recall: 0.7756 - val_auc: 0.9016 - val_prc: 0.8218 - 10s/epoch - 158ms/step
Epoch 4/200
60/60 - 10s - loss: 0.3301 - tp: 1057.0000 - fp: 115.0000 - tn: 2255.0000 - fn: 128.0000 - accuracy: 0.9316 - precision: 0.9019 - recall: 0.8920 - auc: 0.9729 - prc: 0.9524 - val_loss: 0.7493 - val_tp: 196.0000 - val_fp: 54.0000 - val_tn: 454.0000 - val_fn: 58.0000 - val_accuracy: 0.8530 - val_precision: 0.7840 - val_recall: 0.7717 - val_auc: 0.9105 - val_prc: 0.8441 - 10s/epoch - 159ms/step
Epoch 5/200
60/60 - 10s - loss: 0.2311 - tp: 1091.0000 - fp: 84.0000 - tn: 2286.0000 - fn: 94.0000 - accuracy: 0.9499 - precision: 0.9285 - recall: 0.9207 - auc: 0.9841 - prc: 0.9722 - val_loss: 0.8917 - val_tp: 195.0000 - val_fp: 56.0000 - val_tn: 452.0000 - val_fn: 59.0000 - val_accuracy: 0.8491 - val_precision: 0.7769 - val_recall: 0.7677 - val_auc: 0.8998 - val_prc: 0.8218 - 10s/epoch - 160ms/step
Epoch 6/200
60/60 - 10s - loss: 0.2373 - tp: 1081.0000 - fp: 96.0000 - tn: 2274.0000 - fn: 104.0000 - accuracy: 0.9437 - precision: 0.9184 - recall: 0.9122 - auc: 0.9847 - prc: 0.9739 - val_loss: 0.9274 - val_tp: 202.0000 - val_fp: 51.0000 - val_tn: 457.0000 - val_fn: 52.0000 - val_accuracy: 0.8648 - val_precision: 0.7984 - val_recall: 0.7953 - val_auc: 0.9002 - val_prc: 0.8163 - 10s/epoch - 158ms/step
Epoch 7/200
60/60 - 10s - loss: 0.1680 - tp: 1117.0000 - fp: 64.0000 - tn: 2306.0000 - fn: 68.0000 - accuracy: 0.9629 - precision: 0.9458 - recall: 0.9426 - auc: 0.9913 - prc: 0.9843 - val_loss: 1.0003 - val_tp: 195.0000 - val_fp: 59.0000 - val_tn: 449.0000 - val_fn: 59.0000 - val_accuracy: 0.8451 - val_precision: 0.7677 - val_recall: 0.7677 - val_auc: 0.8984 - val_prc: 0.8237 - 10s/epoch - 161ms/step
Epoch 8/200
60/60 - 10s - loss: 0.1260 - tp: 1131.0000 - fp: 51.0000 - tn: 2319.0000 - fn: 54.0000 - accuracy: 0.9705 - precision: 0.9569 - recall: 0.9544 - auc: 0.9942 - prc: 0.9885 - val_loss: 0.8738 - val_tp: 200.0000 - val_fp: 52.0000 - val_tn: 456.0000 - val_fn: 54.0000 - val_accuracy: 0.8609 - val_precision: 0.7937 - val_recall: 0.7874 - val_auc: 0.9017 - val_prc: 0.8263 - 10s/epoch - 162ms/step
Epoch 9/200
60/60 - 10s - loss: 0.2076 - tp: 1112.0000 - fp: 64.0000 - tn: 2306.0000 - fn: 73.0000 - accuracy: 0.9615 - precision: 0.9456 - recall: 0.9384 - auc: 0.9876 - prc: 0.9772 - val_loss: 0.8743 - val_tp: 194.0000 - val_fp: 57.0000 - val_tn: 451.0000 - val_fn: 60.0000 - val_accuracy: 0.8465 - val_precision: 0.7729 - val_recall: 0.7638 - val_auc: 0.9119 - val_prc: 0.8550 - 10s/epoch - 159ms/step
Epoch 9: early stopping
8/8 [==============================] - 0s 39ms/step
13/13 [==============================] - 1s 44ms/step - loss: 1.2866 - tp: 190.0000 - fp: 63.0000 - tn: 447.0000 - fn: 65.0000 - accuracy: 0.8327 - precision: 0.7510 - recall: 0.7451 - auc: 0.8609 - prc: 0.7641

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.67      0.76      0.71        84
           1       0.74      0.76      0.75        83
           2       0.86      0.73      0.79        88

    accuracy                           0.75       255
   macro avg       0.76      0.75      0.75       255
weighted avg       0.76      0.75      0.75       255


=============
CONFUSION MATRIX:
       P-0  P-1  P-2  Total   RP-0   RP-1   RP-2
0       64   13    7     84  0.762  0.155  0.083
1       17   63    3     83  0.205  0.759  0.036
2       15    9   64     88  0.170  0.102  0.727
Total   96   85   74    255  0.376  0.333  0.290

=============
TEST SUMMARY REPORT:
Loss mean: 1.312336027622223, std: 0.07968085939490432
Accuracy mean: 0.8207843244075775, std: 0.014771240949630737
Precision mean: 0.7339577853679657, std: 0.021641959820882368
Recall mean: 0.72509805560112, std: 0.024139156830233096


