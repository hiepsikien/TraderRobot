
=============
FEATURES (show 1 for each):
returns_lag_1, dir_lag_1, hashrate_lag_1, fed_rate_lag_1, gold_lag_1, nasdaq_lag_1, sp500_lag_1, google_trend_lag_1, sma_lag_1, boll_lag_1, min_lag_1, max_lag_1, mom_lag_1, vol_lag_1, obv_lag_1, mfi14_lag_1, rsi14_lag_1, adx14_lag_1, roc_lag_1, atr14_lag_1, bop_lag_1, ad_lag_1, adosc_lag_1, trange_lag_1, ado_lag_1, willr14_lag_1, dx14_lag_1, trix_lag_1, ultosc_lag_1, high_lag_1, low_lag_1, 


=============
DATA PREPARATION PARAMS:
trade_timeframe:1d
take_profit_rate:0.05
stop_loss_rate:0.05
max_duration:3
lags:90
fold_number:1
train_size:0.7
val_size:0.15
categorical_label:True
rebalance:None



============
DATA:
Total rows: 1724
Label 0: 656(38.05%)
Label 1: 540(31.32%)
Label 2: 528(30.63%)

>>>>>> FOLD 1


DATA IN FOLD
Train: 1206, Validation: 258, Test: 260

Train:
Label 0: 449(37.23%)
Label 1: 392(32.5%)
Label 2: 365(30.27%)

Validation:
Label 0: 86(33.33%)
Label 1: 85(32.95%)
Label 2: 87(33.72%)

Test:
Label 0: 121(46.54%)
Label 1: 63(24.23%)
Label 2: 76(29.23%)

=============
CLASSIFIER PARAMS:
hu:2700
output_bias:[0.11429552274617595, -0.02146552520561582, -0.0928300114135868]
loss:categorical_crossentropy
dropout:True
dropout_rate:0.3
learning_rate:0.0001
gpu:False
set_class_weight:True
save_check_point:False
early_stopping:True
patience:5
epochs:200
shuffle_when_train:True
batch_size:48
class_weight:{0: 0.8953229398663697, 1: 1.0255102040816326, 2: 1.1013698630136985}



=============
CLASSIFICATION REPORT:

              precision    recall  f1-score   support

           0       0.72      0.24      0.36       121
           1       0.27      0.90      0.41        63
           2       0.50      0.04      0.07        76

    accuracy                           0.34       260
   macro avg       0.50      0.39      0.28       260
weighted avg       0.55      0.34      0.29       260


=============
CONFUSION MATRIX:
       P0   P1  P2  Total    RP0    RP1    RP2
0      29   89   3    121  0.240  0.736  0.025
1       6   57   0     63  0.095  0.905  0.000
2       5   68   3     76  0.066  0.895  0.039
Total  40  214   6    260  0.154  0.823  0.023

>>>>>>
EVALUATION SUMMARY:

       loss  accuracy  precision  recall  precision-0.65  recall-0.65  \
1     2.006     0.342      0.331   0.315           0.319        0.231   
mean  2.006     0.342      0.331   0.315           0.319        0.231   
std     NaN       NaN        NaN     NaN             NaN          NaN   
min   2.006     0.342      0.331   0.315           0.319        0.231   
max   2.006     0.342      0.331   0.315           0.319        0.231   

      precision-0.80  recall-0.80  precision-0.95  recall-0.95  
1              0.358        0.185           0.417        0.077  
mean           0.358        0.185           0.417        0.077  
std              NaN          NaN             NaN          NaN  
min            0.358        0.185           0.417        0.077  
max            0.358        0.185           0.417        0.077  
