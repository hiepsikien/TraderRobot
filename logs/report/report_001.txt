======= Lap 1 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 418(34.66%)
Label 1: 409(33.91%)
Label 2: 379(31.43%)
Data validation label:
Label 0: 104(40.31%)
Label 1: 89(34.5%)
Label 2: 65(25.19%)
Data test label:
Label 0: 97(37.31%)
Label 2: 87(33.46%)
Label 1: 76(29.23%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:1
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.039903826239926485, 0.01813754975797201, -0.058041401202403496]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200

121/121 - 13s - loss: 0.4549 - tp: 1037.0000 - fp: 150.0000 - tn: 2262.0000 - fn: 169.0000 - accuracy: 0.9118 - precision: 0.8736 - recall: 0.8599 - auc: 0.9608 - prc: 0.9259 - val_loss: 1.5265 - val_tp: 175.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 83.0000 - val_accuracy: 0.7920 - val_precision: 0.6917 - val_recall: 0.6783 - val_auc: 0.8238 - val_prc: 0.6975 - 13s/epoch - 108ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2721 - tp: 1103.0000 - fp: 99.0000 - tn: 2313.0000 - fn: 103.0000 - accuracy: 0.9442 - precision: 0.9176 - recall: 0.9146 - auc: 0.9802 - prc: 0.9623 - val_loss: 1.9169 - val_tp: 165.0000 - val_fp: 90.0000 - val_tn: 426.0000 - val_fn: 93.0000 - val_accuracy: 0.7636 - val_precision: 0.6471 - val_recall: 0.6395 - val_auc: 0.7926 - val_prc: 0.6599 - 13s/epoch - 108ms/step
Epoch 2/200
2023-01-20 20:32:27.243023: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3564000000 exceeds 10% of free system memory.
121/121 - 13s - loss: 0.7925 - tp: 901.0000 - fp: 272.0000 - tn: 2140.0000 - fn: 305.0000 - accuracy: 0.8405 - precision: 0.7681 - recall: 0.7471 - auc: 0.8985 - prc: 0.8208 - val_loss: 1.4866 - val_tp: 164.0000 - val_fp: 93.0000 - val_tn: 423.0000 - val_fn: 94.0000 - val_accuracy: 0.7584 - val_precision: 0.6381 - val_recall: 0.6357 - val_auc: 0.7969 - val_prc: 0.6927 - 13s/epoch - 108ms/step
Epoch 3/200
2023-01-20 20:32:40.339797: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3564000000 exceeds 10% of free system memory.
121/121 - 13s - loss: 0.6245 - tp: 985.0000 - fp: 201.0000 - tn: 2211.0000 - fn: 221.0000 - accuracy: 0.8834 - precision: 0.8305 - recall: 0.8167 - auc: 0.9326 - prc: 0.8803 - val_loss: 1.3273 - val_tp: 178.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 80.0000 - val_accuracy: 0.8023 - val_precision: 0.7092 - val_recall: 0.6899 - val_auc: 0.8257 - val_prc: 0.7135 - 13s/epoch - 109ms/step
Epoch 4/200
2023-01-20 20:32:53.484616: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3564000000 exceeds 10% of free system memory.
121/121 - 13s - loss: 0.4842 - tp: 1029.0000 - fp: 165.0000 - tn: 2247.0000 - fn: 177.0000 - accuracy: 0.9055 - precision: 0.8618 - recall: 0.8532 - auc: 0.9529 - prc: 0.9123 - val_loss: 1.5354 - val_tp: 171.0000 - val_fp: 82.0000 - val_tn: 434.0000 - val_fn: 87.0000 - val_accuracy: 0.7817 - val_precision: 0.6759 - val_recall: 0.6628 - val_auc: 0.8152 - val_prc: 0.7046 - 13s/epoch - 108ms/step
Epoch 5/200
2023-01-20 20:33:06.593564: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3564000000 exceeds 10% of free system memory.
Epoch 6: early stopping
9/9 [==============================] - 0s 33ms/step
26/26 [==============================] - 1s 19ms/step - loss: 1.6751 - tp: 182.0000 - fp: 76.0000 - tn: 444.0000 - fn: 78.0000 - accuracy: 0.8026 - precision: 0.7054 - recall: 0.7000 - auc: 0.8487 - prc: 0.7548

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.73      0.67      0.70        97
           1       0.67      0.68      0.68        76
           2       0.71      0.76      0.73        87

    accuracy                           0.70       260
   macro avg       0.70      0.70      0.70       260
weighted avg       0.70      0.70      0.70       260




=============
CONFUSION MATRIX:
[[65 15 17]
 [14 52 10]
 [10 11 66]]



======= Lap 2 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 447(37.06%)
Label 1: 387(32.09%)
Label 2: 372(30.85%)
Data validation label:
Label 1: 92(35.66%)
Label 0: 86(33.33%)
Label 2: 80(31.01%)
Data test label:
Label 1: 95(36.54%)
Label 0: 86(33.08%)
Label 2: 79(30.38%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:2
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.10926621052533671, -0.03486769105844862, -0.0743985298150877]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 15s - loss: 1.8402 - tp: 782.0000 - fp: 627.0000 - tn: 2305.0000 - fn: 684.0000 - accuracy: 0.7019 - precision: 0.5550 - recall: 0.5334 - auc: 0.7295 - prc: 0.5801 - val_loss: 1.3662 - val_tp: 166.0000 - val_fp: 79.0000 - val_tn: 437.0000 - val_fn: 92.0000 - val_accuracy: 0.7791 - val_precision: 0.6776 - val_recall: 0.6434 - val_auc: 0.8022 - val_prc: 0.6595 - 15s/epoch - 124ms/step
Epoch 2/200
121/121 - 13s - loss: 0.9042 - tp: 898.0000 - fp: 284.0000 - tn: 2128.0000 - fn: 308.0000 - accuracy: 0.8364 - precision: 0.7597 - recall: 0.7446 - auc: 0.8885 - prc: 0.8063 - val_loss: 1.6121 - val_tp: 168.0000 - val_fp: 84.0000 - val_tn: 432.0000 - val_fn: 90.0000 - val_accuracy: 0.7752 - val_precision: 0.6667 - val_recall: 0.6512 - val_auc: 0.8098 - val_prc: 0.6729 - 13s/epoch - 106ms/step
Epoch 3/200
121/121 - 13s - loss: 0.5871 - tp: 984.0000 - fp: 205.0000 - tn: 2207.0000 - fn: 222.0000 - accuracy: 0.8820 - precision: 0.8276 - recall: 0.8159 - auc: 0.9383 - prc: 0.8917 - val_loss: 1.4221 - val_tp: 178.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 80.0000 - val_accuracy: 0.8049 - val_precision: 0.7149 - val_recall: 0.6899 - val_auc: 0.8393 - val_prc: 0.7199 - 13s/epoch - 106ms/step
Epoch 4/200
121/121 - 13s - loss: 0.4100 - tp: 1044.0000 - fp: 151.0000 - tn: 2261.0000 - fn: 162.0000 - accuracy: 0.9135 - precision: 0.8736 - recall: 0.8657 - auc: 0.9638 - prc: 0.9346 - val_loss: 1.4748 - val_tp: 182.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 76.0000 - val_accuracy: 0.8062 - val_precision: 0.7109 - val_recall: 0.7054 - val_auc: 0.8421 - val_prc: 0.7332 - 13s/epoch - 106ms/step
Epoch 5/200
121/121 - 12s - loss: 0.5801 - tp: 1026.0000 - fp: 174.0000 - tn: 2238.0000 - fn: 180.0000 - accuracy: 0.9022 - precision: 0.8550 - recall: 0.8507 - auc: 0.9506 - prc: 0.9121 - val_loss: 1.7715 - val_tp: 171.0000 - val_fp: 84.0000 - val_tn: 432.0000 - val_fn: 87.0000 - val_accuracy: 0.7791 - val_precision: 0.6706 - val_recall: 0.6628 - val_auc: 0.8151 - val_prc: 0.6951 - 12s/epoch - 102ms/step
Epoch 6/200
121/121 - 12s - loss: 0.3216 - tp: 1096.0000 - fp: 104.0000 - tn: 2308.0000 - fn: 110.0000 - accuracy: 0.9409 - precision: 0.9133 - recall: 0.9088 - auc: 0.9757 - prc: 0.9536 - val_loss: 1.1976 - val_tp: 189.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 69.0000 - val_accuracy: 0.8243 - val_precision: 0.7383 - val_recall: 0.7326 - val_auc: 0.8793 - val_prc: 0.7972 - 12s/epoch - 103ms/step
Epoch 7/200
121/121 - 13s - loss: 0.3033 - tp: 1097.0000 - fp: 103.0000 - tn: 2309.0000 - fn: 109.0000 - accuracy: 0.9414 - precision: 0.9142 - recall: 0.9096 - auc: 0.9769 - prc: 0.9567 - val_loss: 1.5689 - val_tp: 180.0000 - val_fp: 75.0000 - val_tn: 441.0000 - val_fn: 78.0000 - val_accuracy: 0.8023 - val_precision: 0.7059 - val_recall: 0.6977 - val_auc: 0.8347 - val_prc: 0.7273 - 13s/epoch - 105ms/step
Epoch 8/200
121/121 - 12s - loss: 0.2756 - tp: 1114.0000 - fp: 88.0000 - tn: 2324.0000 - fn: 92.0000 - accuracy: 0.9502 - precision: 0.9268 - recall: 0.9237 - auc: 0.9799 - prc: 0.9612 - val_loss: 1.3872 - val_tp: 182.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 76.0000 - val_accuracy: 0.8088 - val_precision: 0.7165 - val_recall: 0.7054 - val_auc: 0.8559 - val_prc: 0.7452 - 12s/epoch - 102ms/step
Epoch 9/200
121/121 - 12s - loss: 0.2880 - tp: 1116.0000 - fp: 87.0000 - tn: 2325.0000 - fn: 90.0000 - accuracy: 0.9511 - precision: 0.9277 - recall: 0.9254 - auc: 0.9794 - prc: 0.9640 - val_loss: 1.5330 - val_tp: 187.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 71.0000 - val_accuracy: 0.8191 - val_precision: 0.7305 - val_recall: 0.7248 - val_auc: 0.8587 - val_prc: 0.7575 - 12s/epoch - 103ms/step
Epoch 10/200
121/121 - 12s - loss: 0.1834 - tp: 1131.0000 - fp: 70.0000 - tn: 2342.0000 - fn: 75.0000 - accuracy: 0.9599 - precision: 0.9417 - recall: 0.9378 - auc: 0.9903 - prc: 0.9822 - val_loss: 1.2298 - val_tp: 190.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 68.0000 - val_accuracy: 0.8282 - val_precision: 0.7451 - val_recall: 0.7364 - val_auc: 0.8654 - val_prc: 0.7673 - 12s/epoch - 102ms/step
Epoch 11/200
121/121 - 12s - loss: 0.2190 - tp: 1129.0000 - fp: 71.0000 - tn: 2341.0000 - fn: 77.0000 - accuracy: 0.9591 - precision: 0.9408 - recall: 0.9362 - auc: 0.9861 - prc: 0.9746 - val_loss: 1.5184 - val_tp: 186.0000 - val_fp: 70.0000 - val_tn: 446.0000 - val_fn: 72.0000 - val_accuracy: 0.8165 - val_precision: 0.7266 - val_recall: 0.7209 - val_auc: 0.8569 - val_prc: 0.7484 - 12s/epoch - 102ms/step
Epoch 11: early stopping
9/9 [==============================] - 0s 36ms/step
26/26 [==============================] - 1s 20ms/step - loss: 1.6316 - tp: 175.0000 - fp: 83.0000 - tn: 437.0000 - fn: 85.0000 - accuracy: 0.7846 - precision: 0.6783 - recall: 0.6731 - auc: 0.8258 - prc: 0.7017

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.64      0.63      0.64        86
           1       0.72      0.67      0.70        95
           2       0.68      0.75      0.71        79

    accuracy                           0.68       260
   macro avg       0.68      0.68      0.68       260
weighted avg       0.68      0.68      0.68       260




=============
CONFUSION MATRIX:
[[54 17 15]
 [18 64 13]
 [12  8 59]]



======= Lap 3 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 427(35.41%)
Label 1: 408(33.83%)
Label 2: 371(30.76%)
Data validation label:
Label 0: 91(35.27%)
Label 2: 84(32.56%)
Label 1: 83(32.17%)
Data test label:
Label 0: 101(38.85%)
Label 1: 83(31.92%)
Label 2: 76(29.23%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:3
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.06203292028968094, 0.016516081465218123, -0.0785490303315086]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 15s - loss: 1.8086 - tp: 820.0000 - fp: 592.0000 - tn: 2340.0000 - fn: 646.0000 - accuracy: 0.7185 - precision: 0.5807 - recall: 0.5593 - auc: 0.7407 - prc: 0.5865 - val_loss: 1.4849 - val_tp: 156.0000 - val_fp: 96.0000 - val_tn: 420.0000 - val_fn: 102.0000 - val_accuracy: 0.7442 - val_precision: 0.6190 - val_recall: 0.6047 - val_auc: 0.7617 - val_prc: 0.6399 - 15s/epoch - 120ms/step
Epoch 2/200
121/121 - 13s - loss: 0.8331 - tp: 919.0000 - fp: 254.0000 - tn: 2158.0000 - fn: 287.0000 - accuracy: 0.8505 - precision: 0.7835 - recall: 0.7620 - auc: 0.8948 - prc: 0.8183 - val_loss: 1.4402 - val_tp: 164.0000 - val_fp: 86.0000 - val_tn: 430.0000 - val_fn: 94.0000 - val_accuracy: 0.7674 - val_precision: 0.6560 - val_recall: 0.6357 - val_auc: 0.7957 - val_prc: 0.6751 - 13s/epoch - 104ms/step
Epoch 3/200
121/121 - 13s - loss: 0.6895 - tp: 971.0000 - fp: 217.0000 - tn: 2195.0000 - fn: 235.0000 - accuracy: 0.8751 - precision: 0.8173 - recall: 0.8051 - auc: 0.9250 - prc: 0.8686 - val_loss: 1.3506 - val_tp: 176.0000 - val_fp: 79.0000 - val_tn: 437.0000 - val_fn: 82.0000 - val_accuracy: 0.7920 - val_precision: 0.6902 - val_recall: 0.6822 - val_auc: 0.8274 - val_prc: 0.7087 - 13s/epoch - 104ms/step
Epoch 4/200
121/121 - 13s - loss: 0.4936 - tp: 1024.0000 - fp: 164.0000 - tn: 2248.0000 - fn: 182.0000 - accuracy: 0.9044 - precision: 0.8620 - recall: 0.8491 - auc: 0.9540 - prc: 0.9219 - val_loss: 1.2851 - val_tp: 181.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 77.0000 - val_accuracy: 0.8075 - val_precision: 0.7154 - val_recall: 0.7016 - val_auc: 0.8451 - val_prc: 0.7440 - 13s/epoch - 104ms/step
Epoch 5/200
121/121 - 13s - loss: 0.3271 - tp: 1073.0000 - fp: 125.0000 - tn: 2287.0000 - fn: 133.0000 - accuracy: 0.9287 - precision: 0.8957 - recall: 0.8897 - auc: 0.9758 - prc: 0.9584 - val_loss: 1.1936 - val_tp: 185.0000 - val_fp: 70.0000 - val_tn: 446.0000 - val_fn: 73.0000 - val_accuracy: 0.8152 - val_precision: 0.7255 - val_recall: 0.7171 - val_auc: 0.8705 - val_prc: 0.7813 - 13s/epoch - 104ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2174 - tp: 1123.0000 - fp: 76.0000 - tn: 2336.0000 - fn: 83.0000 - accuracy: 0.9561 - precision: 0.9366 - recall: 0.9312 - auc: 0.9856 - prc: 0.9736 - val_loss: 1.6015 - val_tp: 171.0000 - val_fp: 86.0000 - val_tn: 430.0000 - val_fn: 87.0000 - val_accuracy: 0.7765 - val_precision: 0.6654 - val_recall: 0.6628 - val_auc: 0.8254 - val_prc: 0.7140 - 13s/epoch - 104ms/step
Epoch 7/200
121/121 - 13s - loss: 0.2450 - tp: 1100.0000 - fp: 95.0000 - tn: 2317.0000 - fn: 106.0000 - accuracy: 0.9444 - precision: 0.9205 - recall: 0.9121 - auc: 0.9842 - prc: 0.9708 - val_loss: 1.3695 - val_tp: 178.0000 - val_fp: 72.0000 - val_tn: 444.0000 - val_fn: 80.0000 - val_accuracy: 0.8036 - val_precision: 0.7120 - val_recall: 0.6899 - val_auc: 0.8495 - val_prc: 0.7460 - 13s/epoch - 106ms/step
Epoch 8/200
121/121 - 13s - loss: 0.2052 - tp: 1131.0000 - fp: 68.0000 - tn: 2344.0000 - fn: 75.0000 - accuracy: 0.9605 - precision: 0.9433 - recall: 0.9378 - auc: 0.9873 - prc: 0.9756 - val_loss: 1.3795 - val_tp: 186.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 72.0000 - val_accuracy: 0.8152 - val_precision: 0.7237 - val_recall: 0.7209 - val_auc: 0.8554 - val_prc: 0.7609 - 13s/epoch - 106ms/step
Epoch 9/200
121/121 - 13s - loss: 0.1937 - tp: 1137.0000 - fp: 66.0000 - tn: 2346.0000 - fn: 69.0000 - accuracy: 0.9627 - precision: 0.9451 - recall: 0.9428 - auc: 0.9877 - prc: 0.9772 - val_loss: 1.5202 - val_tp: 181.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 77.0000 - val_accuracy: 0.8062 - val_precision: 0.7126 - val_recall: 0.7016 - val_auc: 0.8556 - val_prc: 0.7462 - 13s/epoch - 106ms/step
Epoch 10/200
121/121 - 13s - loss: 0.2830 - tp: 1106.0000 - fp: 96.0000 - tn: 2316.0000 - fn: 100.0000 - accuracy: 0.9458 - precision: 0.9201 - recall: 0.9171 - auc: 0.9801 - prc: 0.9621 - val_loss: 1.7633 - val_tp: 186.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 72.0000 - val_accuracy: 0.8191 - val_precision: 0.7323 - val_recall: 0.7209 - val_auc: 0.8453 - val_prc: 0.7408 - 13s/epoch - 106ms/step
Epoch 10: early stopping
9/9 [==============================] - 0s 32ms/step
26/26 [==============================] - 1s 21ms/step - loss: 2.0432 - tp: 165.0000 - fp: 92.0000 - tn: 428.0000 - fn: 95.0000 - accuracy: 0.7603 - precision: 0.6420 - recall: 0.6346 - auc: 0.7974 - prc: 0.6573

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.64      0.62      0.63       101
           1       0.65      0.65      0.65        83
           2       0.65      0.67      0.66        76

    accuracy                           0.65       260
   macro avg       0.65      0.65      0.65       260
weighted avg       0.65      0.65      0.65       260




=============
CONFUSION MATRIX:
[[63 18 20]
 [21 54  8]
 [14 11 51]]



======= Lap 4 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 425(35.24%)
Label 1: 413(34.25%)
Label 2: 368(30.51%)
Data validation label:
Label 0: 105(40.7%)
Label 1: 83(32.17%)
Label 2: 70(27.13%)
Data test label:
Label 2: 93(35.77%)
Label 0: 89(34.23%)
Label 1: 78(30.0%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:4
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.05754927293885754, 0.028907696975473404, -0.08645695781662842]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 15s - loss: 1.9937 - tp: 776.0000 - fp: 641.0000 - tn: 2291.0000 - fn: 690.0000 - accuracy: 0.6974 - precision: 0.5476 - recall: 0.5293 - auc: 0.7087 - prc: 0.5468 - val_loss: 1.7284 - val_tp: 159.0000 - val_fp: 94.0000 - val_tn: 422.0000 - val_fn: 99.0000 - val_accuracy: 0.7506 - val_precision: 0.6285 - val_recall: 0.6163 - val_auc: 0.7885 - val_prc: 0.6435 - 15s/epoch - 122ms/step
Epoch 2/200
121/121 - 13s - loss: 0.8835 - tp: 908.0000 - fp: 277.0000 - tn: 2135.0000 - fn: 298.0000 - accuracy: 0.8411 - precision: 0.7662 - recall: 0.7529 - auc: 0.8928 - prc: 0.8142 - val_loss: 1.6733 - val_tp: 155.0000 - val_fp: 96.0000 - val_tn: 420.0000 - val_fn: 103.0000 - val_accuracy: 0.7429 - val_precision: 0.6175 - val_recall: 0.6008 - val_auc: 0.7732 - val_prc: 0.6430 - 13s/epoch - 105ms/step
Epoch 3/200
121/121 - 13s - loss: 0.6573 - tp: 972.0000 - fp: 215.0000 - tn: 2197.0000 - fn: 234.0000 - accuracy: 0.8759 - precision: 0.8189 - recall: 0.8060 - auc: 0.9277 - prc: 0.8723 - val_loss: 1.7017 - val_tp: 169.0000 - val_fp: 79.0000 - val_tn: 437.0000 - val_fn: 89.0000 - val_accuracy: 0.7829 - val_precision: 0.6815 - val_recall: 0.6550 - val_auc: 0.8016 - val_prc: 0.6747 - 13s/epoch - 105ms/step
Epoch 4/200
121/121 - 13s - loss: 0.4857 - tp: 1027.0000 - fp: 168.0000 - tn: 2244.0000 - fn: 179.0000 - accuracy: 0.9041 - precision: 0.8594 - recall: 0.8516 - auc: 0.9539 - prc: 0.9182 - val_loss: 1.5335 - val_tp: 170.0000 - val_fp: 86.0000 - val_tn: 430.0000 - val_fn: 88.0000 - val_accuracy: 0.7752 - val_precision: 0.6641 - val_recall: 0.6589 - val_auc: 0.8234 - val_prc: 0.7054 - 13s/epoch - 104ms/step
Epoch 5/200
121/121 - 13s - loss: 0.3359 - tp: 1073.0000 - fp: 123.0000 - tn: 2289.0000 - fn: 133.0000 - accuracy: 0.9292 - precision: 0.8972 - recall: 0.8897 - auc: 0.9728 - prc: 0.9510 - val_loss: 1.2334 - val_tp: 183.0000 - val_fp: 70.0000 - val_tn: 446.0000 - val_fn: 75.0000 - val_accuracy: 0.8127 - val_precision: 0.7233 - val_recall: 0.7093 - val_auc: 0.8511 - val_prc: 0.7498 - 13s/epoch - 105ms/step
Epoch 6/200
121/121 - 13s - loss: 0.3251 - tp: 1071.0000 - fp: 125.0000 - tn: 2287.0000 - fn: 135.0000 - accuracy: 0.9281 - precision: 0.8955 - recall: 0.8881 - auc: 0.9740 - prc: 0.9511 - val_loss: 1.6189 - val_tp: 179.0000 - val_fp: 75.0000 - val_tn: 441.0000 - val_fn: 79.0000 - val_accuracy: 0.8010 - val_precision: 0.7047 - val_recall: 0.6938 - val_auc: 0.8318 - val_prc: 0.7123 - 13s/epoch - 110ms/step
Epoch 7/200
121/121 - 15s - loss: 0.3125 - tp: 1086.0000 - fp: 114.0000 - tn: 2298.0000 - fn: 120.0000 - accuracy: 0.9353 - precision: 0.9050 - recall: 0.9005 - auc: 0.9753 - prc: 0.9525 - val_loss: 1.3616 - val_tp: 178.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 80.0000 - val_accuracy: 0.7959 - val_precision: 0.6953 - val_recall: 0.6899 - val_auc: 0.8523 - val_prc: 0.7490 - 15s/epoch - 125ms/step
Epoch 8/200
121/121 - 13s - loss: 0.1971 - tp: 1123.0000 - fp: 78.0000 - tn: 2334.0000 - fn: 83.0000 - accuracy: 0.9555 - precision: 0.9351 - recall: 0.9312 - auc: 0.9883 - prc: 0.9777 - val_loss: 1.2754 - val_tp: 189.0000 - val_fp: 67.0000 - val_tn: 449.0000 - val_fn: 69.0000 - val_accuracy: 0.8243 - val_precision: 0.7383 - val_recall: 0.7326 - val_auc: 0.8620 - val_prc: 0.7797 - 13s/epoch - 110ms/step
Epoch 9/200
121/121 - 13s - loss: 0.2079 - tp: 1125.0000 - fp: 74.0000 - tn: 2338.0000 - fn: 81.0000 - accuracy: 0.9572 - precision: 0.9383 - recall: 0.9328 - auc: 0.9866 - prc: 0.9737 - val_loss: 1.5102 - val_tp: 181.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 77.0000 - val_accuracy: 0.8062 - val_precision: 0.7126 - val_recall: 0.7016 - val_auc: 0.8494 - val_prc: 0.7462 - 13s/epoch - 111ms/step
Epoch 10/200
121/121 - 13s - loss: 0.1945 - tp: 1133.0000 - fp: 70.0000 - tn: 2342.0000 - fn: 73.0000 - accuracy: 0.9605 - precision: 0.9418 - recall: 0.9395 - auc: 0.9894 - prc: 0.9805 - val_loss: 1.6139 - val_tp: 182.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 76.0000 - val_accuracy: 0.8062 - val_precision: 0.7109 - val_recall: 0.7054 - val_auc: 0.8463 - val_prc: 0.7411 - 13s/epoch - 111ms/step
Epoch 10: early stopping
9/9 [==============================] - 0s 32ms/step
26/26 [==============================] - 1s 20ms/step - loss: 1.3569 - tp: 180.0000 - fp: 76.0000 - tn: 444.0000 - fn: 80.0000 - accuracy: 0.8000 - precision: 0.7031 - recall: 0.6923 - auc: 0.8577 - prc: 0.7579

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.69      0.72      0.70        89
           1       0.68      0.72      0.70        78
           2       0.74      0.68      0.71        93

    accuracy                           0.70       260
   macro avg       0.70      0.70      0.70       260
weighted avg       0.71      0.70      0.70       260




=============
CONFUSION MATRIX:
[[64 13 12]
 [12 56 10]
 [17 13 63]]



======= Lap 5 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 436(36.15%)
Label 1: 402(33.33%)
Label 2: 368(30.51%)
Data validation label:
Label 1: 88(34.11%)
Label 2: 86(33.33%)
Label 0: 84(32.56%)
Data test label:
Label 0: 99(38.08%)
Label 1: 84(32.31%)
Label 2: 77(29.62%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:5
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.08358315680864217, 0.002393002078628901, -0.08597614837146135]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 16s - loss: 1.9519 - tp: 814.0000 - fp: 604.0000 - tn: 2328.0000 - fn: 652.0000 - accuracy: 0.7144 - precision: 0.5740 - recall: 0.5553 - auc: 0.7322 - prc: 0.5823 - val_loss: 1.6574 - val_tp: 153.0000 - val_fp: 94.0000 - val_tn: 422.0000 - val_fn: 105.0000 - val_accuracy: 0.7429 - val_precision: 0.6194 - val_recall: 0.5930 - val_auc: 0.7671 - val_prc: 0.6123 - 16s/epoch - 129ms/step
Epoch 2/200
121/121 - 13s - loss: 0.8828 - tp: 893.0000 - fp: 293.0000 - tn: 2119.0000 - fn: 313.0000 - accuracy: 0.8325 - precision: 0.7530 - recall: 0.7405 - auc: 0.8890 - prc: 0.8072 - val_loss: 1.3265 - val_tp: 176.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 82.0000 - val_accuracy: 0.7984 - val_precision: 0.7040 - val_recall: 0.6822 - val_auc: 0.8357 - val_prc: 0.7355 - 13s/epoch - 109ms/step
Epoch 3/200
121/121 - 13s - loss: 0.5618 - tp: 991.0000 - fp: 204.0000 - tn: 2208.0000 - fn: 215.0000 - accuracy: 0.8842 - precision: 0.8293 - recall: 0.8217 - auc: 0.9410 - prc: 0.8962 - val_loss: 1.4320 - val_tp: 167.0000 - val_fp: 82.0000 - val_tn: 434.0000 - val_fn: 91.0000 - val_accuracy: 0.7765 - val_precision: 0.6707 - val_recall: 0.6473 - val_auc: 0.8021 - val_prc: 0.6995 - 13s/epoch - 110ms/step
Epoch 4/200
121/121 - 13s - loss: 0.4571 - tp: 1038.0000 - fp: 154.0000 - tn: 2258.0000 - fn: 168.0000 - accuracy: 0.9110 - precision: 0.8708 - recall: 0.8607 - auc: 0.9550 - prc: 0.9191 - val_loss: 1.4434 - val_tp: 167.0000 - val_fp: 85.0000 - val_tn: 431.0000 - val_fn: 91.0000 - val_accuracy: 0.7726 - val_precision: 0.6627 - val_recall: 0.6473 - val_auc: 0.8226 - val_prc: 0.7037 - 13s/epoch - 109ms/step
Epoch 5/200
121/121 - 13s - loss: 0.4160 - tp: 1046.0000 - fp: 145.0000 - tn: 2267.0000 - fn: 160.0000 - accuracy: 0.9157 - precision: 0.8783 - recall: 0.8673 - auc: 0.9645 - prc: 0.9343 - val_loss: 1.5408 - val_tp: 174.0000 - val_fp: 80.0000 - val_tn: 436.0000 - val_fn: 84.0000 - val_accuracy: 0.7881 - val_precision: 0.6850 - val_recall: 0.6744 - val_auc: 0.8216 - val_prc: 0.6888 - 13s/epoch - 110ms/step
Epoch 6/200
121/121 - 13s - loss: 0.3460 - tp: 1087.0000 - fp: 111.0000 - tn: 2301.0000 - fn: 119.0000 - accuracy: 0.9364 - precision: 0.9073 - recall: 0.9013 - auc: 0.9710 - prc: 0.9457 - val_loss: 1.6226 - val_tp: 182.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 76.0000 - val_accuracy: 0.8062 - val_precision: 0.7109 - val_recall: 0.7054 - val_auc: 0.8398 - val_prc: 0.7267 - 13s/epoch - 110ms/step
Epoch 7/200
121/121 - 13s - loss: 0.2605 - tp: 1111.0000 - fp: 93.0000 - tn: 2319.0000 - fn: 95.0000 - accuracy: 0.9480 - precision: 0.9228 - recall: 0.9212 - auc: 0.9824 - prc: 0.9663 - val_loss: 1.5360 - val_tp: 179.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 79.0000 - val_accuracy: 0.8036 - val_precision: 0.7103 - val_recall: 0.6938 - val_auc: 0.8423 - val_prc: 0.7299 - 13s/epoch - 110ms/step
Epoch 7: early stopping
9/9 [==============================] - 0s 31ms/step
26/26 [==============================] - 1s 22ms/step - loss: 1.4545 - tp: 190.0000 - fp: 67.0000 - tn: 453.0000 - fn: 70.0000 - accuracy: 0.8244 - precision: 0.7393 - recall: 0.7308 - auc: 0.8475 - prc: 0.7457

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.76      0.63      0.69        99
           1       0.67      0.81      0.74        84
           2       0.79      0.79      0.79        77

    accuracy                           0.73       260
   macro avg       0.74      0.74      0.74       260
weighted avg       0.74      0.73      0.73       260




=============
CONFUSION MATRIX:
[[62 26 11]
 [11 68  5]
 [ 9  7 61]]



======= Lap 6 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 435(36.07%)
Label 1: 399(33.08%)
Label 2: 372(30.85%)
Data validation label:
Label 0: 95(36.82%)
Label 1: 88(34.11%)
Label 2: 75(29.07%)
Data test label:
Label 0: 89(34.23%)
Label 1: 87(33.46%)
Label 2: 84(32.31%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:6
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.08094559047542678, -0.005439023723393909, -0.07550658634011088]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 16s - loss: 1.8367 - tp: 820.0000 - fp: 601.0000 - tn: 2331.0000 - fn: 646.0000 - accuracy: 0.7165 - precision: 0.5771 - recall: 0.5593 - auc: 0.7391 - prc: 0.5933 - val_loss: 1.7407 - val_tp: 154.0000 - val_fp: 102.0000 - val_tn: 414.0000 - val_fn: 104.0000 - val_accuracy: 0.7339 - val_precision: 0.6016 - val_recall: 0.5969 - val_auc: 0.7593 - val_prc: 0.6001 - 16s/epoch - 131ms/step
Epoch 2/200
121/121 - 13s - loss: 0.9154 - tp: 885.0000 - fp: 307.0000 - tn: 2105.0000 - fn: 321.0000 - accuracy: 0.8264 - precision: 0.7424 - recall: 0.7338 - auc: 0.8838 - prc: 0.7978 - val_loss: 1.4698 - val_tp: 158.0000 - val_fp: 87.0000 - val_tn: 429.0000 - val_fn: 100.0000 - val_accuracy: 0.7584 - val_precision: 0.6449 - val_recall: 0.6124 - val_auc: 0.7955 - val_prc: 0.6679 - 13s/epoch - 111ms/step
Epoch 3/200
121/121 - 13s - loss: 0.7076 - tp: 955.0000 - fp: 240.0000 - tn: 2172.0000 - fn: 251.0000 - accuracy: 0.8643 - precision: 0.7992 - recall: 0.7919 - auc: 0.9220 - prc: 0.8608 - val_loss: 1.2634 - val_tp: 172.0000 - val_fp: 80.0000 - val_tn: 436.0000 - val_fn: 86.0000 - val_accuracy: 0.7855 - val_precision: 0.6825 - val_recall: 0.6667 - val_auc: 0.8285 - val_prc: 0.7161 - 13s/epoch - 109ms/step
Epoch 4/200
121/121 - 13s - loss: 0.5858 - tp: 1013.0000 - fp: 178.0000 - tn: 2234.0000 - fn: 193.0000 - accuracy: 0.8975 - precision: 0.8505 - recall: 0.8400 - auc: 0.9427 - prc: 0.8960 - val_loss: 1.3026 - val_tp: 174.0000 - val_fp: 80.0000 - val_tn: 436.0000 - val_fn: 84.0000 - val_accuracy: 0.7881 - val_precision: 0.6850 - val_recall: 0.6744 - val_auc: 0.8444 - val_prc: 0.7383 - 13s/epoch - 110ms/step
Epoch 5/200
121/121 - 13s - loss: 0.3951 - tp: 1063.0000 - fp: 128.0000 - tn: 2284.0000 - fn: 143.0000 - accuracy: 0.9251 - precision: 0.8925 - recall: 0.8814 - auc: 0.9655 - prc: 0.9368 - val_loss: 1.5739 - val_tp: 174.0000 - val_fp: 80.0000 - val_tn: 436.0000 - val_fn: 84.0000 - val_accuracy: 0.7881 - val_precision: 0.6850 - val_recall: 0.6744 - val_auc: 0.8208 - val_prc: 0.7141 - 13s/epoch - 111ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2757 - tp: 1096.0000 - fp: 102.0000 - tn: 2310.0000 - fn: 110.0000 - accuracy: 0.9414 - precision: 0.9149 - recall: 0.9088 - auc: 0.9802 - prc: 0.9620 - val_loss: 1.3254 - val_tp: 186.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 72.0000 - val_accuracy: 0.8217 - val_precision: 0.7381 - val_recall: 0.7209 - val_auc: 0.8465 - val_prc: 0.7370 - 13s/epoch - 110ms/step
Epoch 7/200
121/121 - 13s - loss: 0.2545 - tp: 1109.0000 - fp: 91.0000 - tn: 2321.0000 - fn: 97.0000 - accuracy: 0.9480 - precision: 0.9242 - recall: 0.9196 - auc: 0.9810 - prc: 0.9633 - val_loss: 1.4007 - val_tp: 187.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 71.0000 - val_accuracy: 0.8230 - val_precision: 0.7391 - val_recall: 0.7248 - val_auc: 0.8613 - val_prc: 0.7672 - 13s/epoch - 111ms/step
Epoch 8/200
121/121 - 14s - loss: 0.3041 - tp: 1100.0000 - fp: 101.0000 - tn: 2311.0000 - fn: 106.0000 - accuracy: 0.9428 - precision: 0.9159 - recall: 0.9121 - auc: 0.9757 - prc: 0.9533 - val_loss: 1.5805 - val_tp: 180.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 78.0000 - val_accuracy: 0.8049 - val_precision: 0.7115 - val_recall: 0.6977 - val_auc: 0.8441 - val_prc: 0.7301 - 14s/epoch - 113ms/step
Epoch 8: early stopping
9/9 [==============================] - 0s 41ms/step
26/26 [==============================] - 1s 22ms/step - loss: 1.8008 - tp: 190.0000 - fp: 68.0000 - tn: 452.0000 - fn: 70.0000 - accuracy: 0.8231 - precision: 0.7364 - recall: 0.7308 - auc: 0.8365 - prc: 0.7328

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.73      0.61      0.66        89
           1       0.71      0.80      0.76        87
           2       0.75      0.79      0.77        84

    accuracy                           0.73       260
   macro avg       0.73      0.73      0.73       260
weighted avg       0.73      0.73      0.73       260




=============
CONFUSION MATRIX:
[[54 22 13]
 [ 8 70  9]
 [12  6 66]]



======= Lap 7 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 439(36.4%)
Label 1: 388(32.17%)
Label 2: 379(31.43%)
Data validation label:
Label 0: 105(40.7%)
Label 1: 86(33.33%)
Label 2: 67(25.97%)
Data test label:
Label 1: 100(38.46%)
Label 2: 85(32.69%)
Label 0: 75(28.85%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:7
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.09015242551668473, -0.033341647935213374, -0.0568107824760604]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 16s - loss: 1.8485 - tp: 804.0000 - fp: 615.0000 - tn: 2317.0000 - fn: 662.0000 - accuracy: 0.7096 - precision: 0.5666 - recall: 0.5484 - auc: 0.7289 - prc: 0.5788 - val_loss: 1.6269 - val_tp: 162.0000 - val_fp: 86.0000 - val_tn: 430.0000 - val_fn: 96.0000 - val_accuracy: 0.7649 - val_precision: 0.6532 - val_recall: 0.6279 - val_auc: 0.7847 - val_prc: 0.6321 - 16s/epoch - 136ms/step
Epoch 2/200
121/121 - 14s - loss: 0.7572 - tp: 912.0000 - fp: 272.0000 - tn: 2140.0000 - fn: 294.0000 - accuracy: 0.8436 - precision: 0.7703 - recall: 0.7562 - auc: 0.9047 - prc: 0.8368 - val_loss: 1.3719 - val_tp: 163.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 95.0000 - val_accuracy: 0.7700 - val_precision: 0.6626 - val_recall: 0.6318 - val_auc: 0.8028 - val_prc: 0.6536 - 14s/epoch - 116ms/step
Epoch 3/200
121/121 - 14s - loss: 0.5971 - tp: 984.0000 - fp: 204.0000 - tn: 2208.0000 - fn: 222.0000 - accuracy: 0.8823 - precision: 0.8283 - recall: 0.8159 - auc: 0.9362 - prc: 0.8852 - val_loss: 1.5180 - val_tp: 177.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 81.0000 - val_accuracy: 0.7997 - val_precision: 0.7052 - val_recall: 0.6860 - val_auc: 0.8139 - val_prc: 0.6775 - 14s/epoch - 115ms/step
Epoch 4/200
121/121 - 13s - loss: 0.3718 - tp: 1060.0000 - fp: 134.0000 - tn: 2278.0000 - fn: 146.0000 - accuracy: 0.9226 - precision: 0.8878 - recall: 0.8789 - auc: 0.9656 - prc: 0.9360 - val_loss: 1.3338 - val_tp: 170.0000 - val_fp: 82.0000 - val_tn: 434.0000 - val_fn: 88.0000 - val_accuracy: 0.7804 - val_precision: 0.6746 - val_recall: 0.6589 - val_auc: 0.8385 - val_prc: 0.7349 - 13s/epoch - 111ms/step
Epoch 5/200
121/121 - 13s - loss: 0.2955 - tp: 1090.0000 - fp: 108.0000 - tn: 2304.0000 - fn: 116.0000 - accuracy: 0.9381 - precision: 0.9098 - recall: 0.9038 - auc: 0.9776 - prc: 0.9573 - val_loss: 1.5683 - val_tp: 175.0000 - val_fp: 79.0000 - val_tn: 437.0000 - val_fn: 83.0000 - val_accuracy: 0.7907 - val_precision: 0.6890 - val_recall: 0.6783 - val_auc: 0.8256 - val_prc: 0.7109 - 13s/epoch - 108ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2808 - tp: 1091.0000 - fp: 107.0000 - tn: 2305.0000 - fn: 115.0000 - accuracy: 0.9386 - precision: 0.9107 - recall: 0.9046 - auc: 0.9805 - prc: 0.9654 - val_loss: 1.8652 - val_tp: 161.0000 - val_fp: 93.0000 - val_tn: 423.0000 - val_fn: 97.0000 - val_accuracy: 0.7545 - val_precision: 0.6339 - val_recall: 0.6240 - val_auc: 0.8184 - val_prc: 0.6931 - 13s/epoch - 107ms/step
Epoch 7/200
121/121 - 13s - loss: 0.3242 - tp: 1083.0000 - fp: 114.0000 - tn: 2298.0000 - fn: 123.0000 - accuracy: 0.9345 - precision: 0.9048 - recall: 0.8980 - auc: 0.9740 - prc: 0.9510 - val_loss: 1.2962 - val_tp: 178.0000 - val_fp: 77.0000 - val_tn: 439.0000 - val_fn: 80.0000 - val_accuracy: 0.7972 - val_precision: 0.6980 - val_recall: 0.6899 - val_auc: 0.8527 - val_prc: 0.7376 - 13s/epoch - 108ms/step
Epoch 8/200
121/121 - 13s - loss: 0.2090 - tp: 1128.0000 - fp: 75.0000 - tn: 2337.0000 - fn: 78.0000 - accuracy: 0.9577 - precision: 0.9377 - recall: 0.9353 - auc: 0.9869 - prc: 0.9759 - val_loss: 1.4498 - val_tp: 189.0000 - val_fp: 62.0000 - val_tn: 454.0000 - val_fn: 69.0000 - val_accuracy: 0.8307 - val_precision: 0.7530 - val_recall: 0.7326 - val_auc: 0.8590 - val_prc: 0.7479 - 13s/epoch - 104ms/step
Epoch 9/200
121/121 - 13s - loss: 0.2117 - tp: 1140.0000 - fp: 61.0000 - tn: 2351.0000 - fn: 66.0000 - accuracy: 0.9649 - precision: 0.9492 - recall: 0.9453 - auc: 0.9862 - prc: 0.9741 - val_loss: 1.5593 - val_tp: 186.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 72.0000 - val_accuracy: 0.8152 - val_precision: 0.7237 - val_recall: 0.7209 - val_auc: 0.8535 - val_prc: 0.7418 - 13s/epoch - 105ms/step
Epoch 10/200
121/121 - 13s - loss: 0.1394 - tp: 1147.0000 - fp: 56.0000 - tn: 2356.0000 - fn: 59.0000 - accuracy: 0.9682 - precision: 0.9534 - recall: 0.9511 - auc: 0.9926 - prc: 0.9876 - val_loss: 1.6690 - val_tp: 179.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 79.0000 - val_accuracy: 0.7972 - val_precision: 0.6965 - val_recall: 0.6938 - val_auc: 0.8371 - val_prc: 0.7168 - 13s/epoch - 105ms/step
Epoch 11/200
121/121 - 13s - loss: 0.1450 - tp: 1150.0000 - fp: 52.0000 - tn: 2360.0000 - fn: 56.0000 - accuracy: 0.9701 - precision: 0.9567 - recall: 0.9536 - auc: 0.9928 - prc: 0.9864 - val_loss: 2.1185 - val_tp: 169.0000 - val_fp: 87.0000 - val_tn: 429.0000 - val_fn: 89.0000 - val_accuracy: 0.7726 - val_precision: 0.6602 - val_recall: 0.6550 - val_auc: 0.8142 - val_prc: 0.6725 - 13s/epoch - 105ms/step
Epoch 12/200
121/121 - 13s - loss: 0.1998 - tp: 1128.0000 - fp: 74.0000 - tn: 2338.0000 - fn: 78.0000 - accuracy: 0.9580 - precision: 0.9384 - recall: 0.9353 - auc: 0.9892 - prc: 0.9797 - val_loss: 1.9583 - val_tp: 177.0000 - val_fp: 78.0000 - val_tn: 438.0000 - val_fn: 81.0000 - val_accuracy: 0.7946 - val_precision: 0.6941 - val_recall: 0.6860 - val_auc: 0.8184 - val_prc: 0.6810 - 13s/epoch - 105ms/step
Epoch 12: early stopping
9/9 [==============================] - 0s 32ms/step
26/26 [==============================] - 1s 21ms/step - loss: 1.8871 - tp: 178.0000 - fp: 79.0000 - tn: 441.0000 - fn: 82.0000 - accuracy: 0.7936 - precision: 0.6926 - recall: 0.6846 - auc: 0.8281 - prc: 0.7001

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.59      0.77      0.67        75
           1       0.77      0.63      0.69       100
           2       0.71      0.67      0.69        85

    accuracy                           0.68       260
   macro avg       0.69      0.69      0.68       260
weighted avg       0.70      0.68      0.69       260




=============
CONFUSION MATRIX:
[[58  8  9]
 [23 63 14]
 [17 11 57]]



======= Lap 8 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 450(37.31%)
Label 1: 394(32.67%)
Label 2: 362(30.02%)
Data validation label:
Label 0: 90(34.88%)
Label 2: 84(32.56%)
Label 1: 84(32.56%)
Data test label:
Label 1: 96(36.92%)
Label 2: 85(32.69%)
Label 0: 79(30.38%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:8
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.11683335982459347, -0.016063313641838037, -0.10077001111400082]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 15s - loss: 1.9790 - tp: 775.0000 - fp: 641.0000 - tn: 2291.0000 - fn: 691.0000 - accuracy: 0.6971 - precision: 0.5473 - recall: 0.5286 - auc: 0.7147 - prc: 0.5634 - val_loss: 1.4084 - val_tp: 163.0000 - val_fp: 87.0000 - val_tn: 429.0000 - val_fn: 95.0000 - val_accuracy: 0.7649 - val_precision: 0.6520 - val_recall: 0.6318 - val_auc: 0.7969 - val_prc: 0.6601 - 15s/epoch - 125ms/step
Epoch 2/200
121/121 - 13s - loss: 0.9599 - tp: 877.0000 - fp: 302.0000 - tn: 2110.0000 - fn: 329.0000 - accuracy: 0.8256 - precision: 0.7439 - recall: 0.7272 - auc: 0.8803 - prc: 0.7955 - val_loss: 1.2300 - val_tp: 163.0000 - val_fp: 83.0000 - val_tn: 433.0000 - val_fn: 95.0000 - val_accuracy: 0.7700 - val_precision: 0.6626 - val_recall: 0.6318 - val_auc: 0.8108 - val_prc: 0.6873 - 13s/epoch - 107ms/step
Epoch 3/200
121/121 - 13s - loss: 0.6563 - tp: 985.0000 - fp: 207.0000 - tn: 2205.0000 - fn: 221.0000 - accuracy: 0.8817 - precision: 0.8263 - recall: 0.8167 - auc: 0.9319 - prc: 0.8756 - val_loss: 1.5333 - val_tp: 164.0000 - val_fp: 88.0000 - val_tn: 428.0000 - val_fn: 94.0000 - val_accuracy: 0.7649 - val_precision: 0.6508 - val_recall: 0.6357 - val_auc: 0.8090 - val_prc: 0.6924 - 13s/epoch - 108ms/step
Epoch 4/200
121/121 - 13s - loss: 0.5218 - tp: 1021.0000 - fp: 175.0000 - tn: 2237.0000 - fn: 185.0000 - accuracy: 0.9005 - precision: 0.8537 - recall: 0.8466 - auc: 0.9498 - prc: 0.9113 - val_loss: 1.3986 - val_tp: 180.0000 - val_fp: 75.0000 - val_tn: 441.0000 - val_fn: 78.0000 - val_accuracy: 0.8023 - val_precision: 0.7059 - val_recall: 0.6977 - val_auc: 0.8380 - val_prc: 0.7177 - 13s/epoch - 109ms/step
Epoch 5/200
121/121 - 13s - loss: 0.3610 - tp: 1069.0000 - fp: 131.0000 - tn: 2281.0000 - fn: 137.0000 - accuracy: 0.9259 - precision: 0.8908 - recall: 0.8864 - auc: 0.9694 - prc: 0.9419 - val_loss: 1.4880 - val_tp: 167.0000 - val_fp: 85.0000 - val_tn: 431.0000 - val_fn: 91.0000 - val_accuracy: 0.7726 - val_precision: 0.6627 - val_recall: 0.6473 - val_auc: 0.8063 - val_prc: 0.6667 - 13s/epoch - 110ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2967 - tp: 1097.0000 - fp: 99.0000 - tn: 2313.0000 - fn: 109.0000 - accuracy: 0.9425 - precision: 0.9172 - recall: 0.9096 - auc: 0.9782 - prc: 0.9584 - val_loss: 1.3455 - val_tp: 171.0000 - val_fp: 82.0000 - val_tn: 434.0000 - val_fn: 87.0000 - val_accuracy: 0.7817 - val_precision: 0.6759 - val_recall: 0.6628 - val_auc: 0.8396 - val_prc: 0.7240 - 13s/epoch - 110ms/step
Epoch 7/200
121/121 - 13s - loss: 0.2177 - tp: 1113.0000 - fp: 83.0000 - tn: 2329.0000 - fn: 93.0000 - accuracy: 0.9514 - precision: 0.9306 - recall: 0.9229 - auc: 0.9865 - prc: 0.9770 - val_loss: 1.3340 - val_tp: 179.0000 - val_fp: 76.0000 - val_tn: 440.0000 - val_fn: 79.0000 - val_accuracy: 0.7997 - val_precision: 0.7020 - val_recall: 0.6938 - val_auc: 0.8448 - val_prc: 0.7308 - 13s/epoch - 110ms/step
Epoch 7: early stopping
9/9 [==============================] - 0s 40ms/step
26/26 [==============================] - 1s 19ms/step - loss: 1.5545 - tp: 173.0000 - fp: 79.0000 - tn: 441.0000 - fn: 87.0000 - accuracy: 0.7872 - precision: 0.6865 - recall: 0.6654 - auc: 0.8313 - prc: 0.7184

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.58      0.57      0.57        79
           1       0.70      0.76      0.73        96
           2       0.78      0.71      0.74        85

    accuracy                           0.68       260
   macro avg       0.68      0.68      0.68       260
weighted avg       0.69      0.68      0.68       260




=============
CONFUSION MATRIX:
[[45 23 11]
 [17 73  6]
 [16  9 60]]



======= Lap 9 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 433(35.9%)
Label 1: 389(32.26%)
Label 2: 384(31.84%)
Data validation label:
Label 0: 94(36.43%)
Label 1: 94(36.43%)
Label 2: 70(27.13%)
Data test label:
Label 0: 92(35.38%)
Label 1: 91(35.0%)
Label 2: 77(29.62%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:9
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.07575118765407839, -0.03140719672996517, -0.044343987760684614]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 16s - loss: 2.0381 - tp: 760.0000 - fp: 655.0000 - tn: 2277.0000 - fn: 706.0000 - accuracy: 0.6905 - precision: 0.5371 - recall: 0.5184 - auc: 0.7120 - prc: 0.5510 - val_loss: 1.6449 - val_tp: 151.0000 - val_fp: 105.0000 - val_tn: 411.0000 - val_fn: 107.0000 - val_accuracy: 0.7261 - val_precision: 0.5898 - val_recall: 0.5853 - val_auc: 0.7915 - val_prc: 0.6604 - 16s/epoch - 128ms/step
Epoch 2/200
121/121 - 13s - loss: 0.8592 - tp: 884.0000 - fp: 291.0000 - tn: 2121.0000 - fn: 322.0000 - accuracy: 0.8306 - precision: 0.7523 - recall: 0.7330 - auc: 0.8914 - prc: 0.8122 - val_loss: 1.3675 - val_tp: 175.0000 - val_fp: 81.0000 - val_tn: 435.0000 - val_fn: 83.0000 - val_accuracy: 0.7881 - val_precision: 0.6836 - val_recall: 0.6783 - val_auc: 0.8240 - val_prc: 0.7173 - 13s/epoch - 109ms/step
Epoch 3/200
121/121 - 13s - loss: 0.5967 - tp: 980.0000 - fp: 211.0000 - tn: 2201.0000 - fn: 226.0000 - accuracy: 0.8792 - precision: 0.8228 - recall: 0.8126 - auc: 0.9387 - prc: 0.8886 - val_loss: 1.3572 - val_tp: 187.0000 - val_fp: 70.0000 - val_tn: 446.0000 - val_fn: 71.0000 - val_accuracy: 0.8178 - val_precision: 0.7276 - val_recall: 0.7248 - val_auc: 0.8646 - val_prc: 0.7563 - 13s/epoch - 109ms/step
Epoch 4/200
121/121 - 13s - loss: 0.4628 - tp: 1019.0000 - fp: 172.0000 - tn: 2240.0000 - fn: 187.0000 - accuracy: 0.9008 - precision: 0.8556 - recall: 0.8449 - auc: 0.9566 - prc: 0.9252 - val_loss: 1.3218 - val_tp: 185.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 73.0000 - val_accuracy: 0.8178 - val_precision: 0.7312 - val_recall: 0.7171 - val_auc: 0.8545 - val_prc: 0.7484 - 13s/epoch - 108ms/step
Epoch 5/200
121/121 - 13s - loss: 0.3055 - tp: 1078.0000 - fp: 108.0000 - tn: 2304.0000 - fn: 128.0000 - accuracy: 0.9348 - precision: 0.9089 - recall: 0.8939 - auc: 0.9765 - prc: 0.9572 - val_loss: 1.1956 - val_tp: 192.0000 - val_fp: 61.0000 - val_tn: 455.0000 - val_fn: 66.0000 - val_accuracy: 0.8359 - val_precision: 0.7589 - val_recall: 0.7442 - val_auc: 0.8717 - val_prc: 0.7817 - 13s/epoch - 108ms/step
Epoch 6/200
121/121 - 13s - loss: 0.2247 - tp: 1120.0000 - fp: 79.0000 - tn: 2333.0000 - fn: 86.0000 - accuracy: 0.9544 - precision: 0.9341 - recall: 0.9287 - auc: 0.9862 - prc: 0.9746 - val_loss: 1.1564 - val_tp: 191.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 67.0000 - val_accuracy: 0.8295 - val_precision: 0.7461 - val_recall: 0.7403 - val_auc: 0.8764 - val_prc: 0.7837 - 13s/epoch - 109ms/step
Epoch 7/200
121/121 - 14s - loss: 0.2054 - tp: 1122.0000 - fp: 81.0000 - tn: 2331.0000 - fn: 84.0000 - accuracy: 0.9544 - precision: 0.9327 - recall: 0.9303 - auc: 0.9885 - prc: 0.9804 - val_loss: 1.2867 - val_tp: 191.0000 - val_fp: 63.0000 - val_tn: 453.0000 - val_fn: 67.0000 - val_accuracy: 0.8320 - val_precision: 0.7520 - val_recall: 0.7403 - val_auc: 0.8578 - val_prc: 0.7417 - 14s/epoch - 115ms/step
Epoch 8/200
121/121 - 14s - loss: 0.2690 - tp: 1111.0000 - fp: 90.0000 - tn: 2322.0000 - fn: 95.0000 - accuracy: 0.9489 - precision: 0.9251 - recall: 0.9212 - auc: 0.9813 - prc: 0.9632 - val_loss: 1.4762 - val_tp: 184.0000 - val_fp: 73.0000 - val_tn: 443.0000 - val_fn: 74.0000 - val_accuracy: 0.8101 - val_precision: 0.7160 - val_recall: 0.7132 - val_auc: 0.8534 - val_prc: 0.7440 - 14s/epoch - 117ms/step
Epoch 9/200
121/121 - 14s - loss: 0.2052 - tp: 1121.0000 - fp: 82.0000 - tn: 2330.0000 - fn: 85.0000 - accuracy: 0.9538 - precision: 0.9318 - recall: 0.9295 - auc: 0.9875 - prc: 0.9760 - val_loss: 1.5726 - val_tp: 189.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 69.0000 - val_accuracy: 0.8256 - val_precision: 0.7412 - val_recall: 0.7326 - val_auc: 0.8475 - val_prc: 0.7281 - 14s/epoch - 114ms/step
Epoch 10/200
121/121 - 13s - loss: 0.1672 - tp: 1138.0000 - fp: 62.0000 - tn: 2350.0000 - fn: 68.0000 - accuracy: 0.9641 - precision: 0.9483 - recall: 0.9436 - auc: 0.9899 - prc: 0.9820 - val_loss: 1.2742 - val_tp: 192.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 66.0000 - val_accuracy: 0.8320 - val_precision: 0.7500 - val_recall: 0.7442 - val_auc: 0.8847 - val_prc: 0.7976 - 13s/epoch - 105ms/step
Epoch 11/200
121/121 - 13s - loss: 0.1655 - tp: 1151.0000 - fp: 52.0000 - tn: 2360.0000 - fn: 55.0000 - accuracy: 0.9704 - precision: 0.9568 - recall: 0.9544 - auc: 0.9905 - prc: 0.9822 - val_loss: 1.4492 - val_tp: 192.0000 - val_fp: 66.0000 - val_tn: 450.0000 - val_fn: 66.0000 - val_accuracy: 0.8295 - val_precision: 0.7442 - val_recall: 0.7442 - val_auc: 0.8633 - val_prc: 0.7579 - 13s/epoch - 106ms/step
Epoch 11: early stopping
9/9 [==============================] - 0s 33ms/step
26/26 [==============================] - 1s 22ms/step - loss: 1.3870 - tp: 190.0000 - fp: 66.0000 - tn: 454.0000 - fn: 70.0000 - accuracy: 0.8256 - precision: 0.7422 - recall: 0.7308 - auc: 0.8666 - prc: 0.7686

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.74      0.66      0.70        92
           1       0.75      0.77      0.76        91
           2       0.72      0.79      0.75        77

    accuracy                           0.74       260
   macro avg       0.74      0.74      0.74       260
weighted avg       0.74      0.74      0.74       260




=============
CONFUSION MATRIX:
[[61 18 13]
 [10 70 11]
 [11  5 61]]



======= Lap 10 =======
Shuffling the data...
Splitting the data...
Data preparation completed.
==========
INPUT DATA FOR CLASSIFICATION:
Data Train: 1206, Validation: 258, Test: 260
Data train label:
Label 0: 440(36.48%)
Label 1: 399(33.08%)
Label 2: 367(30.43%)
Data validation label:
Label 1: 89(34.5%)
Label 2: 86(33.33%)
Label 0: 83(32.17%)
Data test label:
Label 0: 96(36.92%)
Label 1: 86(33.08%)
Label 2: 78(30.0%)

=============
PARAMS:
timeframe_in_ms:86400000
take_profit_rate:0.1
stop_loss_rate:0.08
max_duration:12
lags:90
random_state:10
is_shuffle:True
y_to_categorical:True
rebalance:None
cat_lentgh:1000
hu:3000
output_bias:[0.09307539768624283, -0.004737912336200705, -0.08833748117149397]
loss:categorical_crossentropy
dropout:True
gpu:False
set_class_weight:False
save_check_point:False
early_stopping:True
patience:5
epochs:200
batch_size:10


Epoch 1/200
121/121 - 15s - loss: 1.8578 - tp: 809.0000 - fp: 606.0000 - tn: 2326.0000 - fn: 657.0000 - accuracy: 0.7128 - precision: 0.5717 - recall: 0.5518 - auc: 0.7410 - prc: 0.5956 - val_loss: 1.3348 - val_tp: 158.0000 - val_fp: 91.0000 - val_tn: 425.0000 - val_fn: 100.0000 - val_accuracy: 0.7532 - val_precision: 0.6345 - val_recall: 0.6124 - val_auc: 0.7961 - val_prc: 0.6666 - 15s/epoch - 123ms/step
Epoch 2/200
121/121 - 13s - loss: 0.9604 - tp: 870.0000 - fp: 311.0000 - tn: 2101.0000 - fn: 336.0000 - accuracy: 0.8212 - precision: 0.7367 - recall: 0.7214 - auc: 0.8820 - prc: 0.8003 - val_loss: 1.2802 - val_tp: 173.0000 - val_fp: 77.0000 - val_tn: 439.0000 - val_fn: 85.0000 - val_accuracy: 0.7907 - val_precision: 0.6920 - val_recall: 0.6705 - val_auc: 0.8261 - val_prc: 0.7199 - 13s/epoch - 106ms/step
Epoch 3/200
121/121 - 13s - loss: 0.6498 - tp: 974.0000 - fp: 208.0000 - tn: 2204.0000 - fn: 232.0000 - accuracy: 0.8784 - precision: 0.8240 - recall: 0.8076 - auc: 0.9318 - prc: 0.8758 - val_loss: 0.9274 - val_tp: 184.0000 - val_fp: 69.0000 - val_tn: 447.0000 - val_fn: 74.0000 - val_accuracy: 0.8152 - val_precision: 0.7273 - val_recall: 0.7132 - val_auc: 0.8779 - val_prc: 0.8017 - 13s/epoch - 109ms/step
Epoch 4/200
121/121 - 13s - loss: 0.5847 - tp: 990.0000 - fp: 202.0000 - tn: 2210.0000 - fn: 216.0000 - accuracy: 0.8845 - precision: 0.8305 - recall: 0.8209 - auc: 0.9414 - prc: 0.8939 - val_loss: 1.5145 - val_tp: 187.0000 - val_fp: 68.0000 - val_tn: 448.0000 - val_fn: 71.0000 - val_accuracy: 0.8204 - val_precision: 0.7333 - val_recall: 0.7248 - val_auc: 0.8421 - val_prc: 0.7466 - 13s/epoch - 110ms/step
Epoch 5/200
121/121 - 13s - loss: 0.4416 - tp: 1048.0000 - fp: 144.0000 - tn: 2268.0000 - fn: 158.0000 - accuracy: 0.9165 - precision: 0.8792 - recall: 0.8690 - auc: 0.9617 - prc: 0.9300 - val_loss: 1.3438 - val_tp: 179.0000 - val_fp: 74.0000 - val_tn: 442.0000 - val_fn: 79.0000 - val_accuracy: 0.8023 - val_precision: 0.7075 - val_recall: 0.6938 - val_auc: 0.8479 - val_prc: 0.7364 - 13s/epoch - 107ms/step
Epoch 6/200
121/121 - 13s - loss: 0.4350 - tp: 1062.0000 - fp: 137.0000 - tn: 2275.0000 - fn: 144.0000 - accuracy: 0.9223 - precision: 0.8857 - recall: 0.8806 - auc: 0.9643 - prc: 0.9328 - val_loss: 1.3761 - val_tp: 191.0000 - val_fp: 65.0000 - val_tn: 451.0000 - val_fn: 67.0000 - val_accuracy: 0.8295 - val_precision: 0.7461 - val_recall: 0.7403 - val_auc: 0.8499 - val_prc: 0.7406 - 13s/epoch - 109ms/step
Epoch 7/200
121/121 - 13s - loss: 0.3643 - tp: 1078.0000 - fp: 118.0000 - tn: 2294.0000 - fn: 128.0000 - accuracy: 0.9320 - precision: 0.9013 - recall: 0.8939 - auc: 0.9739 - prc: 0.9534 - val_loss: 1.2245 - val_tp: 192.0000 - val_fp: 64.0000 - val_tn: 452.0000 - val_fn: 66.0000 - val_accuracy: 0.8320 - val_precision: 0.7500 - val_recall: 0.7442 - val_auc: 0.8694 - val_prc: 0.7750 - 13s/epoch - 108ms/step
Epoch 8/200
121/121 - 13s - loss: 0.2174 - tp: 1124.0000 - fp: 79.0000 - tn: 2333.0000 - fn: 82.0000 - accuracy: 0.9555 - precision: 0.9343 - recall: 0.9320 - auc: 0.9871 - prc: 0.9758 - val_loss: 1.3582 - val_tp: 187.0000 - val_fp: 71.0000 - val_tn: 445.0000 - val_fn: 71.0000 - val_accuracy: 0.8165 - val_precision: 0.7248 - val_recall: 0.7248 - val_auc: 0.8643 - val_prc: 0.7605 - 13s/epoch - 108ms/step
Epoch 8: early stopping
9/9 [==============================] - 0s 37ms/step
26/26 [==============================] - 1s 20ms/step - loss: 1.7481 - tp: 184.0000 - fp: 74.0000 - tn: 446.0000 - fn: 76.0000 - accuracy: 0.8077 - precision: 0.7132 - recall: 0.7077 - auc: 0.8372 - prc: 0.7245

=============
CLASSIFICATION REPORT:
              precision    recall  f1-score   support

           0       0.73      0.67      0.70        96
           1       0.68      0.78      0.73        86
           2       0.73      0.69      0.71        78

    accuracy                           0.71       260
   macro avg       0.71      0.71      0.71       260
weighted avg       0.71      0.71      0.71       260




=============
CONFUSION MATRIX:
[[64 18 14]
 [13 67  6]
 [11 13 54]]



=============
TEST SUMMARY REPORT:
Loss mean: 1.6538801074028016, std: 0.21129478016336292
Accuracy mean: 0.8008974373340607, std: 0.019653892718881072
Precsion mean: 0.7039083659648895, std: 0.02963262263100996
Recall mean: 0.6949999928474426, std: 0.03023820870880127


