{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 23:17:07.696946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-02 23:17:07.697112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-02 23:17:07.697125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-02 23:17:09.296522: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-02 23:17:09.296587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: andy-GA-970A-D3\n",
      "2023-02-02 23:17:09.296601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: andy-GA-970A-D3\n",
      "2023-02-02 23:17:09.296788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 520.61.5\n",
      "2023-02-02 23:17:09.296830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5\n",
      "2023-02-02 23:17:09.296842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 520.61.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import feature_manager as fma\n",
    "import classifier.multi_dnn_classifier as dnn\n",
    "from random import randint\n",
    "from keras import callbacks, losses\n",
    "import visualizer\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import importlib\n",
    "import tr_utils\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"BTCUSDT\"\n",
    "trade_tf = \"1h\"\n",
    "granular_tf = \"1m\"\n",
    "\n",
    "fm = fma.FeatureManager(\n",
    "    target_col=\"trade_signal\"\n",
    ")\n",
    "\n",
    "fm.import_trading_data(\n",
    "    symbol=symbol,\n",
    "    trade_timeframe=trade_tf,\n",
    ")\n",
    "\n",
    "fm.import_granular_data(\n",
    "    symbol=symbol,\n",
    "    granular_timeframe=granular_tf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.df[\"swing\"] = (fm.df[\"High\"]-fm.df[\"Low\"])/fm.df[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.df[\"swing\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0.03\n",
    "sl = 0.03\n",
    "md = 12\n",
    "\n",
    "fm.prepare_trade_forward_data(\n",
    "    take_profit_rate=tp,\n",
    "    stop_loss_rate=sl,\n",
    "    max_duration=md,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.build_features(lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PRINT_METRICS = [\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"precision-0.65\",\n",
    "    \"recall-0.65\",\n",
    "    \"precision-0.80\",\n",
    "    \"recall-0.80\",\n",
    "    \"precision-0.95\",\n",
    "    \"recall-0.95\"\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "results = dnn.evaluate_classifier_k_folds(\n",
    "    hu = 500,\n",
    "    fm = fm,\n",
    "    fold_number = 10,\n",
    "    batch_size = 1024,\n",
    "    set_class_weight = False,\n",
    "    save_check_point = True,\n",
    "    early_stop = True,\n",
    "    rebalance = None,\n",
    "    split_type=\"time_series_split\",\n",
    "    metrics=DEFAULT_PRINT_METRICS,\n",
    "    set_initial_bias = True,\n",
    "    dropout = True,\n",
    "    dropout_rate = 0.3,\n",
    "    shuffle_when_train = True,\n",
    "    gpu = False,\n",
    "    write_to_file = True\n",
    ")\n",
    "results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.df[\"gold_lag_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"precision-0.65\",\n",
    "    \"recall-0.65\",\n",
    "    \"precision-0.80\",\n",
    "    \"recall-0.80\",\n",
    "    \"precision-0.95\",\n",
    "    \"recall-0.95\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "results = dnn.evaluate_classifier(\n",
    "    hu=100,\n",
    "    fm=fm,\n",
    "    laps=1,\n",
    "    batch_size=20,\n",
    "    set_class_weight=False,\n",
    "    save_check_point=False,\n",
    "    early_stopping=True,\n",
    "    shuffle_before_split=False,\n",
    "    dropout=True,\n",
    "    dropout_rate=0.3,\n",
    "    gpu=False,\n",
    "    metrics=metric_list,\n",
    "    write_to_file=True\n",
    ")\n",
    "results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../out/evaluate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dnn.MultiDNNClassifer()\n",
    "\n",
    "filename = \"../logs/report/{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "report_file = open(filename,'w')\n",
    "\n",
    "dataset = classifier.prepare_data(\n",
    "    data = fm.df,\n",
    "    cols = fm.cols,\n",
    "    shuffle_before_split= False,\n",
    "    categorical_label=True,\n",
    "    rebalance=\"over\",\n",
    "    target_col=\"trade_signal\",\n",
    "    file = report_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = tr_utils.init_imbalanced_bias(\n",
    "    y_train=dataset[1]\n",
    ")\n",
    "\n",
    "classifier.configure(\n",
    "    hu = 100, \n",
    "    dropout=True, \n",
    "    dropout_rate = 0.3,\n",
    "    input_dim=len(fm.cols),\n",
    "    output_bias=initial_bias,\n",
    "    class_num=3\n",
    ")\n",
    "\n",
    "test_result = classifier.run(\n",
    "    gpu = False,\n",
    "    dataset = dataset,\n",
    "    epochs = 500,\n",
    "    shuffle_when_train = False,\n",
    "    patience = 5,\n",
    "    early_stop = True,\n",
    "    save_check_point = True,\n",
    "    set_class_weight = False,\n",
    "    batch_size = 128,\n",
    "    file = report_file\n",
    ")\n",
    "\n",
    "var_df = pd.DataFrame(data=classifier.viann_callback.varScores, index = fm.cols)\n",
    "var_df.columns = [\"var\"]\n",
    "var_df.sort_values(by=[\"var\"],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b58b1819899e409cec63cea36e334f732dfc50db3a5ecdff48b63b0a8eb4970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
