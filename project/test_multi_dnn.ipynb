{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 14:37:37.120722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-29 14:37:37.120890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-29 14:37:37.120903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-29 14:37:38.747999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-29 14:37:38.748059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: andy-GA-970A-D3\n",
      "2023-01-29 14:37:38.748074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: andy-GA-970A-D3\n",
      "2023-01-29 14:37:38.748256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 520.61.5\n",
      "2023-01-29 14:37:38.748301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5\n",
      "2023-01-29 14:37:38.748315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 520.61.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import feature_manager as fma\n",
    "import classifier.multi_dnn_classifier as dnn\n",
    "from random import randint\n",
    "from keras import callbacks, losses\n",
    "import visualizer\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import importlib\n",
    "import tr_utils\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported ../data/BTCUSDT-1h.csv with 46982 rows\n",
      "Imported ../nocommit/BTCUSDT-1m.csv with 2817999 rows\n"
     ]
    }
   ],
   "source": [
    "symbol = \"BTCUSDT\"\n",
    "trade_tf = \"1h\"\n",
    "granular_tf = \"1m\"\n",
    "\n",
    "fm = fma.FeatureManager(\n",
    "    target_col=\"trade_signal\"\n",
    ")\n",
    "\n",
    "fm.import_trading_data(\n",
    "    symbol=symbol,\n",
    "    trade_timeframe=trade_tf,\n",
    ")\n",
    "\n",
    "fm.import_granular_data(\n",
    "    symbol=symbol,\n",
    "    granular_timeframe=granular_tf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.df[\"swing\"] = (fm.df[\"High\"]-fm.df[\"Low\"])/fm.df[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46982.000000\n",
       "mean         0.011602\n",
       "std          0.011129\n",
       "min          0.000000\n",
       "25%          0.005332\n",
       "50%          0.008498\n",
       "75%          0.013971\n",
       "max          0.308296\n",
       "Name: swing, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.df[\"swing\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 12 future timeframes to build trade signal: \n",
      "1  2  3  4  5  6  7  8  9  10  11  12  \n",
      "Label producing completed. \n",
      " Value counts:\n",
      "0    28558\n",
      "2     9560\n",
      "1     8864\n",
      "Name: trade_signal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tp = 0.03\n",
    "sl = 0.03\n",
    "md = 12\n",
    "\n",
    "fm.prepare_trade_forward_data(\n",
    "    take_profit_rate=tp,\n",
    "    stop_loss_rate=sl,\n",
    "    max_duration=md,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical features...\n",
      "\n",
      "Adding features with lags 12: returns, dir, hashrate, fed_rate, gold, nasdaq, sp500, google_trend, sma, boll, boll7, boll14, boll21, min, min7, min14, min21, max, max7, max14, max21, mom, mom7, mom14, mom21, vol, vol7, vol14, vol21, obv, mfi7, mfi14, mfi21, rsi7, rsi14, rsi21, adx7, adx14, adx21, roc, roc7, roc14, roc21, atr7, atr14, atr21, bop, ad, adosc, trange, ado, willr7, willr14, willr21, dx7, dx14, dx21, trix, ultosc, high, low, \n",
      "\n",
      "Normalizing features with MaxAbs: returns_lag_1, returns_lag_2, returns_lag_3, returns_lag_4, returns_lag_5, returns_lag_6, returns_lag_7, returns_lag_8, returns_lag_9, returns_lag_10, returns_lag_11, returns_lag_12, dir_lag_1, dir_lag_2, dir_lag_3, dir_lag_4, dir_lag_5, dir_lag_6, dir_lag_7, dir_lag_8, dir_lag_9, dir_lag_10, dir_lag_11, dir_lag_12, hashrate_lag_1, hashrate_lag_2, hashrate_lag_3, hashrate_lag_4, hashrate_lag_5, hashrate_lag_6, hashrate_lag_7, hashrate_lag_8, hashrate_lag_9, hashrate_lag_10, hashrate_lag_11, hashrate_lag_12, fed_rate_lag_1, fed_rate_lag_2, fed_rate_lag_3, fed_rate_lag_4, fed_rate_lag_5, fed_rate_lag_6, fed_rate_lag_7, fed_rate_lag_8, fed_rate_lag_9, fed_rate_lag_10, fed_rate_lag_11, fed_rate_lag_12, gold_lag_1, gold_lag_2, gold_lag_3, gold_lag_4, gold_lag_5, gold_lag_6, gold_lag_7, gold_lag_8, gold_lag_9, gold_lag_10, gold_lag_11, gold_lag_12, nasdaq_lag_1, nasdaq_lag_2, nasdaq_lag_3, nasdaq_lag_4, nasdaq_lag_5, nasdaq_lag_6, nasdaq_lag_7, nasdaq_lag_8, nasdaq_lag_9, nasdaq_lag_10, nasdaq_lag_11, nasdaq_lag_12, sp500_lag_1, sp500_lag_2, sp500_lag_3, sp500_lag_4, sp500_lag_5, sp500_lag_6, sp500_lag_7, sp500_lag_8, sp500_lag_9, sp500_lag_10, sp500_lag_11, sp500_lag_12, google_trend_lag_1, google_trend_lag_2, google_trend_lag_3, google_trend_lag_4, google_trend_lag_5, google_trend_lag_6, google_trend_lag_7, google_trend_lag_8, google_trend_lag_9, google_trend_lag_10, google_trend_lag_11, google_trend_lag_12, sma_lag_1, sma_lag_2, sma_lag_3, sma_lag_4, sma_lag_5, sma_lag_6, sma_lag_7, sma_lag_8, sma_lag_9, sma_lag_10, sma_lag_11, sma_lag_12, boll_lag_1, boll_lag_2, boll_lag_3, boll_lag_4, boll_lag_5, boll_lag_6, boll_lag_7, boll_lag_8, boll_lag_9, boll_lag_10, boll_lag_11, boll_lag_12, boll7_lag_1, boll7_lag_2, boll7_lag_3, boll7_lag_4, boll7_lag_5, boll7_lag_6, boll7_lag_7, boll7_lag_8, boll7_lag_9, boll7_lag_10, boll7_lag_11, boll7_lag_12, boll14_lag_1, boll14_lag_2, boll14_lag_3, boll14_lag_4, boll14_lag_5, boll14_lag_6, boll14_lag_7, boll14_lag_8, boll14_lag_9, boll14_lag_10, boll14_lag_11, boll14_lag_12, boll21_lag_1, boll21_lag_2, boll21_lag_3, boll21_lag_4, boll21_lag_5, boll21_lag_6, boll21_lag_7, boll21_lag_8, boll21_lag_9, boll21_lag_10, boll21_lag_11, boll21_lag_12, min_lag_1, min_lag_2, min_lag_3, min_lag_4, min_lag_5, min_lag_6, min_lag_7, min_lag_8, min_lag_9, min_lag_10, min_lag_11, min_lag_12, min7_lag_1, min7_lag_2, min7_lag_3, min7_lag_4, min7_lag_5, min7_lag_6, min7_lag_7, min7_lag_8, min7_lag_9, min7_lag_10, min7_lag_11, min7_lag_12, min14_lag_1, min14_lag_2, min14_lag_3, min14_lag_4, min14_lag_5, min14_lag_6, min14_lag_7, min14_lag_8, min14_lag_9, min14_lag_10, min14_lag_11, min14_lag_12, min21_lag_1, min21_lag_2, min21_lag_3, min21_lag_4, min21_lag_5, min21_lag_6, min21_lag_7, min21_lag_8, min21_lag_9, min21_lag_10, min21_lag_11, min21_lag_12, max_lag_1, max_lag_2, max_lag_3, max_lag_4, max_lag_5, max_lag_6, max_lag_7, max_lag_8, max_lag_9, max_lag_10, max_lag_11, max_lag_12, max7_lag_1, max7_lag_2, max7_lag_3, max7_lag_4, max7_lag_5, max7_lag_6, max7_lag_7, max7_lag_8, max7_lag_9, max7_lag_10, max7_lag_11, max7_lag_12, max14_lag_1, max14_lag_2, max14_lag_3, max14_lag_4, max14_lag_5, max14_lag_6, max14_lag_7, max14_lag_8, max14_lag_9, max14_lag_10, max14_lag_11, max14_lag_12, max21_lag_1, max21_lag_2, max21_lag_3, max21_lag_4, max21_lag_5, max21_lag_6, max21_lag_7, max21_lag_8, max21_lag_9, max21_lag_10, max21_lag_11, max21_lag_12, mom_lag_1, mom_lag_2, mom_lag_3, mom_lag_4, mom_lag_5, mom_lag_6, mom_lag_7, mom_lag_8, mom_lag_9, mom_lag_10, mom_lag_11, mom_lag_12, mom7_lag_1, mom7_lag_2, mom7_lag_3, mom7_lag_4, mom7_lag_5, mom7_lag_6, mom7_lag_7, mom7_lag_8, mom7_lag_9, mom7_lag_10, mom7_lag_11, mom7_lag_12, mom14_lag_1, mom14_lag_2, mom14_lag_3, mom14_lag_4, mom14_lag_5, mom14_lag_6, mom14_lag_7, mom14_lag_8, mom14_lag_9, mom14_lag_10, mom14_lag_11, mom14_lag_12, mom21_lag_1, mom21_lag_2, mom21_lag_3, mom21_lag_4, mom21_lag_5, mom21_lag_6, mom21_lag_7, mom21_lag_8, mom21_lag_9, mom21_lag_10, mom21_lag_11, mom21_lag_12, vol_lag_1, vol_lag_2, vol_lag_3, vol_lag_4, vol_lag_5, vol_lag_6, vol_lag_7, vol_lag_8, vol_lag_9, vol_lag_10, vol_lag_11, vol_lag_12, vol7_lag_1, vol7_lag_2, vol7_lag_3, vol7_lag_4, vol7_lag_5, vol7_lag_6, vol7_lag_7, vol7_lag_8, vol7_lag_9, vol7_lag_10, vol7_lag_11, vol7_lag_12, vol14_lag_1, vol14_lag_2, vol14_lag_3, vol14_lag_4, vol14_lag_5, vol14_lag_6, vol14_lag_7, vol14_lag_8, vol14_lag_9, vol14_lag_10, vol14_lag_11, vol14_lag_12, vol21_lag_1, vol21_lag_2, vol21_lag_3, vol21_lag_4, vol21_lag_5, vol21_lag_6, vol21_lag_7, vol21_lag_8, vol21_lag_9, vol21_lag_10, vol21_lag_11, vol21_lag_12, obv_lag_1, obv_lag_2, obv_lag_3, obv_lag_4, obv_lag_5, obv_lag_6, obv_lag_7, obv_lag_8, obv_lag_9, obv_lag_10, obv_lag_11, obv_lag_12, mfi7_lag_1, mfi7_lag_2, mfi7_lag_3, mfi7_lag_4, mfi7_lag_5, mfi7_lag_6, mfi7_lag_7, mfi7_lag_8, mfi7_lag_9, mfi7_lag_10, mfi7_lag_11, mfi7_lag_12, mfi14_lag_1, mfi14_lag_2, mfi14_lag_3, mfi14_lag_4, mfi14_lag_5, mfi14_lag_6, mfi14_lag_7, mfi14_lag_8, mfi14_lag_9, mfi14_lag_10, mfi14_lag_11, mfi14_lag_12, mfi21_lag_1, mfi21_lag_2, mfi21_lag_3, mfi21_lag_4, mfi21_lag_5, mfi21_lag_6, mfi21_lag_7, mfi21_lag_8, mfi21_lag_9, mfi21_lag_10, mfi21_lag_11, mfi21_lag_12, rsi7_lag_1, rsi7_lag_2, rsi7_lag_3, rsi7_lag_4, rsi7_lag_5, rsi7_lag_6, rsi7_lag_7, rsi7_lag_8, rsi7_lag_9, rsi7_lag_10, rsi7_lag_11, rsi7_lag_12, rsi14_lag_1, rsi14_lag_2, rsi14_lag_3, rsi14_lag_4, rsi14_lag_5, rsi14_lag_6, rsi14_lag_7, rsi14_lag_8, rsi14_lag_9, rsi14_lag_10, rsi14_lag_11, rsi14_lag_12, rsi21_lag_1, rsi21_lag_2, rsi21_lag_3, rsi21_lag_4, rsi21_lag_5, rsi21_lag_6, rsi21_lag_7, rsi21_lag_8, rsi21_lag_9, rsi21_lag_10, rsi21_lag_11, rsi21_lag_12, adx7_lag_1, adx7_lag_2, adx7_lag_3, adx7_lag_4, adx7_lag_5, adx7_lag_6, adx7_lag_7, adx7_lag_8, adx7_lag_9, adx7_lag_10, adx7_lag_11, adx7_lag_12, adx14_lag_1, adx14_lag_2, adx14_lag_3, adx14_lag_4, adx14_lag_5, adx14_lag_6, adx14_lag_7, adx14_lag_8, adx14_lag_9, adx14_lag_10, adx14_lag_11, adx14_lag_12, adx21_lag_1, adx21_lag_2, adx21_lag_3, adx21_lag_4, adx21_lag_5, adx21_lag_6, adx21_lag_7, adx21_lag_8, adx21_lag_9, adx21_lag_10, adx21_lag_11, adx21_lag_12, roc_lag_1, roc_lag_2, roc_lag_3, roc_lag_4, roc_lag_5, roc_lag_6, roc_lag_7, roc_lag_8, roc_lag_9, roc_lag_10, roc_lag_11, roc_lag_12, roc7_lag_1, roc7_lag_2, roc7_lag_3, roc7_lag_4, roc7_lag_5, roc7_lag_6, roc7_lag_7, roc7_lag_8, roc7_lag_9, roc7_lag_10, roc7_lag_11, roc7_lag_12, roc14_lag_1, roc14_lag_2, roc14_lag_3, roc14_lag_4, roc14_lag_5, roc14_lag_6, roc14_lag_7, roc14_lag_8, roc14_lag_9, roc14_lag_10, roc14_lag_11, roc14_lag_12, roc21_lag_1, roc21_lag_2, roc21_lag_3, roc21_lag_4, roc21_lag_5, roc21_lag_6, roc21_lag_7, roc21_lag_8, roc21_lag_9, roc21_lag_10, roc21_lag_11, roc21_lag_12, atr7_lag_1, atr7_lag_2, atr7_lag_3, atr7_lag_4, atr7_lag_5, atr7_lag_6, atr7_lag_7, atr7_lag_8, atr7_lag_9, atr7_lag_10, atr7_lag_11, atr7_lag_12, atr14_lag_1, atr14_lag_2, atr14_lag_3, atr14_lag_4, atr14_lag_5, atr14_lag_6, atr14_lag_7, atr14_lag_8, atr14_lag_9, atr14_lag_10, atr14_lag_11, atr14_lag_12, atr21_lag_1, atr21_lag_2, atr21_lag_3, atr21_lag_4, atr21_lag_5, atr21_lag_6, atr21_lag_7, atr21_lag_8, atr21_lag_9, atr21_lag_10, atr21_lag_11, atr21_lag_12, bop_lag_1, bop_lag_2, bop_lag_3, bop_lag_4, bop_lag_5, bop_lag_6, bop_lag_7, bop_lag_8, bop_lag_9, bop_lag_10, bop_lag_11, bop_lag_12, ad_lag_1, ad_lag_2, ad_lag_3, ad_lag_4, ad_lag_5, ad_lag_6, ad_lag_7, ad_lag_8, ad_lag_9, ad_lag_10, ad_lag_11, ad_lag_12, adosc_lag_1, adosc_lag_2, adosc_lag_3, adosc_lag_4, adosc_lag_5, adosc_lag_6, adosc_lag_7, adosc_lag_8, adosc_lag_9, adosc_lag_10, adosc_lag_11, adosc_lag_12, trange_lag_1, trange_lag_2, trange_lag_3, trange_lag_4, trange_lag_5, trange_lag_6, trange_lag_7, trange_lag_8, trange_lag_9, trange_lag_10, trange_lag_11, trange_lag_12, ado_lag_1, ado_lag_2, ado_lag_3, ado_lag_4, ado_lag_5, ado_lag_6, ado_lag_7, ado_lag_8, ado_lag_9, ado_lag_10, ado_lag_11, ado_lag_12, willr7_lag_1, willr7_lag_2, willr7_lag_3, willr7_lag_4, willr7_lag_5, willr7_lag_6, willr7_lag_7, willr7_lag_8, willr7_lag_9, willr7_lag_10, willr7_lag_11, willr7_lag_12, willr14_lag_1, willr14_lag_2, willr14_lag_3, willr14_lag_4, willr14_lag_5, willr14_lag_6, willr14_lag_7, willr14_lag_8, willr14_lag_9, willr14_lag_10, willr14_lag_11, willr14_lag_12, willr21_lag_1, willr21_lag_2, willr21_lag_3, willr21_lag_4, willr21_lag_5, willr21_lag_6, willr21_lag_7, willr21_lag_8, willr21_lag_9, willr21_lag_10, willr21_lag_11, willr21_lag_12, dx7_lag_1, dx7_lag_2, dx7_lag_3, dx7_lag_4, dx7_lag_5, dx7_lag_6, dx7_lag_7, dx7_lag_8, dx7_lag_9, dx7_lag_10, dx7_lag_11, dx7_lag_12, dx14_lag_1, dx14_lag_2, dx14_lag_3, dx14_lag_4, dx14_lag_5, dx14_lag_6, dx14_lag_7, dx14_lag_8, dx14_lag_9, dx14_lag_10, dx14_lag_11, dx14_lag_12, dx21_lag_1, dx21_lag_2, dx21_lag_3, dx21_lag_4, dx21_lag_5, dx21_lag_6, dx21_lag_7, dx21_lag_8, dx21_lag_9, dx21_lag_10, dx21_lag_11, dx21_lag_12, trix_lag_1, trix_lag_2, trix_lag_3, trix_lag_4, trix_lag_5, trix_lag_6, trix_lag_7, trix_lag_8, trix_lag_9, trix_lag_10, trix_lag_11, trix_lag_12, ultosc_lag_1, ultosc_lag_2, ultosc_lag_3, ultosc_lag_4, ultosc_lag_5, ultosc_lag_6, ultosc_lag_7, ultosc_lag_8, ultosc_lag_9, ultosc_lag_10, ultosc_lag_11, ultosc_lag_12, high_lag_1, high_lag_2, high_lag_3, high_lag_4, high_lag_5, high_lag_6, high_lag_7, high_lag_8, high_lag_9, high_lag_10, high_lag_11, high_lag_12, low_lag_1, low_lag_2, low_lag_3, low_lag_4, low_lag_5, low_lag_6, low_lag_7, low_lag_8, low_lag_9, low_lag_10, low_lag_11, low_lag_12, \n",
      "Total 732 features added.\n"
     ]
    }
   ],
   "source": [
    "fm.build_features(lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'classifier.multi_dnn_classifier' from '/home/andy/CryptoTradingPlatform/TraderRobot/project/classifier/multi_dnn_classifier.py'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "DATA PREPARATION PARAMS:\n",
      "trade_timeframe:1h\n",
      "take_profit_rate:0.03\n",
      "stop_loss_rate:0.03\n",
      "max_duration:12\n",
      "lags:12\n",
      "fold_number:10\n",
      "train_size:0.7\n",
      "val_size:0.15\n",
      "categorical_label:True\n",
      "rebalance:None\n",
      "split_type:time_series_split\n",
      "\n",
      "\n",
      "\n",
      "============\n",
      "DATA:\n",
      "Total rows: 46821\n",
      "Label 0: 28524(60.92%)\n",
      "Label 1: 8820(18.84%)\n",
      "Label 2: 9477(20.24%)\n",
      "Splitting the data...\n",
      "\n",
      ">>>>>> FOLD 1\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 3901, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 1000(25.63%)\n",
      "Label 1: 1497(38.37%)\n",
      "Label 2: 1404(35.99%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 1937(49.65%)\n",
      "Label 1: 893(22.89%)\n",
      "Label 2: 1071(27.45%)\n",
      "\n",
      "Test:\n",
      "Label 0: 2694(69.06%)\n",
      "Label 1: 503(12.89%)\n",
      "Label 2: 704(18.05%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[-0.2475961228030686, 0.15586698263442275, 0.09172918280055087]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1341 - tp: 706.0000 - fp: 1110.0000 - tn: 6692.0000 - fn: 3195.0000 - accuracy: 0.3889 - precision: 0.3888 - precision-0.55: 0.3914 - precision-0.60: 0.4264 - precision-0.65: 0.4498 - precision-0.70: 0.5000 - precision-0.75: 0.5263 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1810 - recall-0.55: 0.1072 - recall-0.60: 0.0587 - recall-0.65: 0.0264 - recall-0.70: 0.0092 - recall-0.75: 0.0026 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.21972, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 5s 691ms/step - loss: 1.1341 - tp: 706.0000 - fp: 1110.0000 - tn: 6692.0000 - fn: 3195.0000 - accuracy: 0.3889 - precision: 0.3888 - precision-0.55: 0.3914 - precision-0.60: 0.4264 - precision-0.65: 0.4498 - precision-0.70: 0.5000 - precision-0.75: 0.5263 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1810 - recall-0.55: 0.1072 - recall-0.60: 0.0587 - recall-0.65: 0.0264 - recall-0.70: 0.0092 - recall-0.75: 0.0026 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.2197 - val_tp: 108.0000 - val_fp: 158.0000 - val_tn: 7644.0000 - val_fn: 3793.0000 - val_accuracy: 0.2766 - val_precision: 0.4060 - val_precision-0.55: 0.3200 - val_precision-0.60: 0.0000e+00 - val_precision-0.65: 0.0000e+00 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0277 - val_recall-0.55: 0.0021 - val_recall-0.60: 0.0000e+00 - val_recall-0.65: 0.0000e+00 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0870 - tp: 283.0000 - fp: 320.0000 - tn: 5824.0000 - fn: 2789.0000 - accuracy: 0.3880 - precision: 0.4693 - precision-0.55: 0.5081 - precision-0.60: 0.5854 - precision-0.65: 0.8077 - precision-0.70: 0.8000 - precision-0.75: 0.5000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0921 - recall-0.55: 0.0407 - recall-0.60: 0.0156 - recall-0.65: 0.0068 - recall-0.70: 0.0013 - recall-0.75: 3.2552e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00          \n",
      "Epoch 2: val_loss improved from 1.21972 to 1.14835, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 148ms/step - loss: 1.0871 - tp: 365.0000 - fp: 393.0000 - tn: 7409.0000 - fn: 3536.0000 - accuracy: 0.3873 - precision: 0.4815 - precision-0.55: 0.5200 - precision-0.60: 0.5726 - precision-0.65: 0.8000 - precision-0.70: 0.8333 - precision-0.75: 0.5000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0936 - recall-0.55: 0.0433 - recall-0.60: 0.0172 - recall-0.65: 0.0072 - recall-0.70: 0.0013 - recall-0.75: 2.5634e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1483 - val_tp: 239.0000 - val_fp: 355.0000 - val_tn: 7447.0000 - val_fn: 3662.0000 - val_accuracy: 0.2974 - val_precision: 0.4024 - val_precision-0.55: 0.4589 - val_precision-0.60: 0.4615 - val_precision-0.65: 0.0000e+00 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0613 - val_recall-0.55: 0.0244 - val_recall-0.60: 0.0031 - val_recall-0.65: 0.0000e+00 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0741 - tp: 264.0000 - fp: 279.0000 - tn: 5865.0000 - fn: 2808.0000 - accuracy: 0.4023 - precision: 0.4862 - precision-0.55: 0.5305 - precision-0.60: 0.5271 - precision-0.65: 0.6111 - precision-0.70: 0.7500 - precision-0.75: 0.6667 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0859 - recall-0.55: 0.0482 - recall-0.60: 0.0221 - recall-0.65: 0.0107 - recall-0.70: 0.0039 - recall-0.75: 6.5104e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 \n",
      "Epoch 3: val_loss did not improve from 1.14835\n",
      "4/4 [==============================] - 0s 143ms/step - loss: 1.0689 - tp: 351.0000 - fp: 353.0000 - tn: 7449.0000 - fn: 3550.0000 - accuracy: 0.4048 - precision: 0.4986 - precision-0.55: 0.5361 - precision-0.60: 0.5439 - precision-0.65: 0.6250 - precision-0.70: 0.7826 - precision-0.75: 0.6000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0900 - recall-0.55: 0.0495 - recall-0.60: 0.0238 - recall-0.65: 0.0115 - recall-0.70: 0.0046 - recall-0.75: 7.6903e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1593 - val_tp: 233.0000 - val_fp: 321.0000 - val_tn: 7481.0000 - val_fn: 3668.0000 - val_accuracy: 0.2707 - val_precision: 0.4206 - val_precision-0.55: 0.4629 - val_precision-0.60: 0.4419 - val_precision-0.65: 0.6667 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0597 - val_recall-0.55: 0.0272 - val_recall-0.60: 0.0049 - val_recall-0.65: 5.1269e-04 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0415 - tp: 385.0000 - fp: 396.0000 - tn: 5748.0000 - fn: 2687.0000 - accuracy: 0.4274 - precision: 0.4930 - precision-0.55: 0.5237 - precision-0.60: 0.5549 - precision-0.65: 0.6500 - precision-0.70: 0.6190 - precision-0.75: 0.7500 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1253 - recall-0.55: 0.0648 - recall-0.60: 0.0296 - recall-0.65: 0.0127 - recall-0.70: 0.0042 - recall-0.75: 9.7656e-04 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00        \n",
      "Epoch 4: val_loss did not improve from 1.14835\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 1.0423 - tp: 509.0000 - fp: 521.0000 - tn: 7281.0000 - fn: 3392.0000 - accuracy: 0.4260 - precision: 0.4942 - precision-0.55: 0.5319 - precision-0.60: 0.5674 - precision-0.65: 0.6420 - precision-0.70: 0.7241 - precision-0.75: 0.7500 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1305 - recall-0.55: 0.0684 - recall-0.60: 0.0313 - recall-0.65: 0.0133 - recall-0.70: 0.0054 - recall-0.75: 7.6903e-04 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1994 - val_tp: 317.0000 - val_fp: 413.0000 - val_tn: 7389.0000 - val_fn: 3584.0000 - val_accuracy: 0.2604 - val_precision: 0.4342 - val_precision-0.55: 0.4876 - val_precision-0.60: 0.4722 - val_precision-0.65: 0.5000 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0813 - val_recall-0.55: 0.0354 - val_recall-0.60: 0.0087 - val_recall-0.65: 5.1269e-04 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0313 - tp: 539.0000 - fp: 550.0000 - tn: 5594.0000 - fn: 2533.0000 - accuracy: 0.4294 - precision: 0.4949 - precision-0.55: 0.5528 - precision-0.60: 0.5993 - precision-0.65: 0.5789 - precision-0.70: 0.5122 - precision-0.75: 0.5714 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1755 - recall-0.55: 0.1022 - recall-0.60: 0.0540 - recall-0.65: 0.0215 - recall-0.70: 0.0068 - recall-0.75: 0.0013 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00       \n",
      "Epoch 5: val_loss did not improve from 1.14835\n",
      "4/4 [==============================] - 0s 148ms/step - loss: 1.0298 - tp: 697.0000 - fp: 689.0000 - tn: 7113.0000 - fn: 3204.0000 - accuracy: 0.4309 - precision: 0.5029 - precision-0.55: 0.5592 - precision-0.60: 0.5833 - precision-0.65: 0.5621 - precision-0.70: 0.5472 - precision-0.75: 0.5000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1787 - recall-0.55: 0.1054 - recall-0.60: 0.0538 - recall-0.65: 0.0220 - recall-0.70: 0.0074 - recall-0.75: 0.0015 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.2086 - val_tp: 356.0000 - val_fp: 519.0000 - val_tn: 7283.0000 - val_fn: 3545.0000 - val_accuracy: 0.2599 - val_precision: 0.4069 - val_precision-0.55: 0.4372 - val_precision-0.60: 0.4647 - val_precision-0.65: 0.3462 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0913 - val_recall-0.55: 0.0500 - val_recall-0.60: 0.0203 - val_recall-0.65: 0.0023 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0218 - tp: 540.0000 - fp: 474.0000 - tn: 5670.0000 - fn: 2532.0000 - accuracy: 0.4326 - precision: 0.5325 - precision-0.55: 0.5368 - precision-0.60: 0.5596 - precision-0.65: 0.5912 - precision-0.70: 0.6429 - precision-0.75: 0.7059 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1758 - recall-0.55: 0.0996 - recall-0.60: 0.0550 - recall-0.65: 0.0264 - recall-0.70: 0.0117 - recall-0.75: 0.0039 - recall-0.80: 9.7656e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from 1.14835\n",
      "4/4 [==============================] - 0s 141ms/step - loss: 1.0194 - tp: 679.0000 - fp: 593.0000 - tn: 7209.0000 - fn: 3222.0000 - accuracy: 0.4312 - precision: 0.5338 - precision-0.55: 0.5514 - precision-0.60: 0.5722 - precision-0.65: 0.6230 - precision-0.70: 0.6575 - precision-0.75: 0.6800 - precision-0.80: 0.6250 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1741 - recall-0.55: 0.1031 - recall-0.60: 0.0579 - recall-0.65: 0.0292 - recall-0.70: 0.0123 - recall-0.75: 0.0044 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1723 - val_tp: 344.0000 - val_fp: 545.0000 - val_tn: 7257.0000 - val_fn: 3557.0000 - val_accuracy: 0.2866 - val_precision: 0.3870 - val_precision-0.55: 0.4309 - val_precision-0.60: 0.4414 - val_precision-0.65: 0.4375 - val_precision-0.70: 0.4000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0882 - val_recall-0.55: 0.0600 - val_recall-0.60: 0.0290 - val_recall-0.65: 0.0072 - val_recall-0.70: 5.1269e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0022 - tp: 536.0000 - fp: 441.0000 - tn: 5703.0000 - fn: 2536.0000 - accuracy: 0.4613 - precision: 0.5486 - precision-0.55: 0.6047 - precision-0.60: 0.6113 - precision-0.65: 0.6333 - precision-0.70: 0.6719 - precision-0.75: 0.5789 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1745 - recall-0.55: 0.1081 - recall-0.60: 0.0563 - recall-0.65: 0.0309 - recall-0.70: 0.0140 - recall-0.75: 0.0036 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 7: val_loss improved from 1.14835 to 1.14090, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 145ms/step - loss: 1.0060 - tp: 672.0000 - fp: 565.0000 - tn: 7237.0000 - fn: 3229.0000 - accuracy: 0.4565 - precision: 0.5432 - precision-0.55: 0.5852 - precision-0.60: 0.5979 - precision-0.65: 0.6270 - precision-0.70: 0.6707 - precision-0.75: 0.6250 - precision-0.80: 0.8333 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1723 - recall-0.55: 0.1056 - recall-0.60: 0.0572 - recall-0.65: 0.0297 - recall-0.70: 0.0141 - recall-0.75: 0.0038 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1409 - val_tp: 323.0000 - val_fp: 490.0000 - val_tn: 7312.0000 - val_fn: 3578.0000 - val_accuracy: 0.3448 - val_precision: 0.3973 - val_precision-0.55: 0.4374 - val_precision-0.60: 0.4425 - val_precision-0.65: 0.4074 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0828 - val_recall-0.55: 0.0546 - val_recall-0.60: 0.0256 - val_recall-0.65: 0.0056 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9934 - tp: 527.0000 - fp: 394.0000 - tn: 5750.0000 - fn: 2545.0000 - accuracy: 0.4688 - precision: 0.5722 - precision-0.55: 0.5853 - precision-0.60: 0.5775 - precision-0.65: 0.5882 - precision-0.70: 0.5918 - precision-0.75: 0.4667 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1715 - recall-0.55: 0.0960 - recall-0.60: 0.0485 - recall-0.65: 0.0228 - recall-0.70: 0.0094 - recall-0.75: 0.0023 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 8: val_loss improved from 1.14090 to 1.13064, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 144ms/step - loss: 0.9960 - tp: 670.0000 - fp: 509.0000 - tn: 7293.0000 - fn: 3231.0000 - accuracy: 0.4653 - precision: 0.5683 - precision-0.55: 0.5899 - precision-0.60: 0.5816 - precision-0.65: 0.5833 - precision-0.70: 0.5606 - precision-0.75: 0.4500 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1718 - recall-0.55: 0.0984 - recall-0.60: 0.0502 - recall-0.65: 0.0233 - recall-0.70: 0.0095 - recall-0.75: 0.0023 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1306 - val_tp: 300.0000 - val_fp: 410.0000 - val_tn: 7392.0000 - val_fn: 3601.0000 - val_accuracy: 0.3497 - val_precision: 0.4225 - val_precision-0.55: 0.4524 - val_precision-0.60: 0.4173 - val_precision-0.65: 0.2500 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0769 - val_recall-0.55: 0.0438 - val_recall-0.60: 0.0149 - val_recall-0.65: 0.0013 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9928 - tp: 526.0000 - fp: 440.0000 - tn: 5704.0000 - fn: 2546.0000 - accuracy: 0.4704 - precision: 0.5445 - precision-0.55: 0.5706 - precision-0.60: 0.5771 - precision-0.65: 0.6239 - precision-0.70: 0.5556 - precision-0.75: 0.4000 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1712 - recall-0.55: 0.0973 - recall-0.60: 0.0475 - recall-0.65: 0.0221 - recall-0.70: 0.0065 - recall-0.75: 0.0020 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00       \n",
      "Epoch 9: val_loss did not improve from 1.13064\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9930 - tp: 682.0000 - fp: 545.0000 - tn: 7257.0000 - fn: 3219.0000 - accuracy: 0.4678 - precision: 0.5558 - precision-0.55: 0.5778 - precision-0.60: 0.5831 - precision-0.65: 0.6214 - precision-0.70: 0.5490 - precision-0.75: 0.4211 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1748 - recall-0.55: 0.1000 - recall-0.60: 0.0477 - recall-0.65: 0.0223 - recall-0.70: 0.0072 - recall-0.75: 0.0021 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1334 - val_tp: 311.0000 - val_fp: 415.0000 - val_tn: 7387.0000 - val_fn: 3590.0000 - val_accuracy: 0.3422 - val_precision: 0.4284 - val_precision-0.55: 0.4444 - val_precision-0.60: 0.3858 - val_precision-0.65: 0.2000 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0797 - val_recall-0.55: 0.0420 - val_recall-0.60: 0.0126 - val_recall-0.65: 0.0010 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9829 - tp: 575.0000 - fp: 458.0000 - tn: 5686.0000 - fn: 2497.0000 - accuracy: 0.4616 - precision: 0.5566 - precision-0.55: 0.5758 - precision-0.60: 0.5864 - precision-0.65: 0.6357 - precision-0.70: 0.5417 - precision-0.75: 0.5385 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1872 - recall-0.55: 0.1100 - recall-0.60: 0.0563 - recall-0.65: 0.0290 - recall-0.70: 0.0085 - recall-0.75: 0.0023 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 10: val_loss did not improve from 1.13064\n",
      "4/4 [==============================] - 0s 145ms/step - loss: 0.9842 - tp: 730.0000 - fp: 576.0000 - tn: 7226.0000 - fn: 3171.0000 - accuracy: 0.4604 - precision: 0.5590 - precision-0.55: 0.5804 - precision-0.60: 0.5958 - precision-0.65: 0.6229 - precision-0.70: 0.5333 - precision-0.75: 0.4375 - precision-0.80: 0.3333 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1871 - recall-0.55: 0.1110 - recall-0.60: 0.0582 - recall-0.65: 0.0279 - recall-0.70: 0.0082 - recall-0.75: 0.0018 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1435 - val_tp: 338.0000 - val_fp: 476.0000 - val_tn: 7326.0000 - val_fn: 3563.0000 - val_accuracy: 0.3274 - val_precision: 0.4152 - val_precision-0.55: 0.4409 - val_precision-0.60: 0.4242 - val_precision-0.65: 0.1842 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0866 - val_recall-0.55: 0.0526 - val_recall-0.60: 0.0215 - val_recall-0.65: 0.0018 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9815 - tp: 597.0000 - fp: 499.0000 - tn: 5645.0000 - fn: 2475.0000 - accuracy: 0.4730 - precision: 0.5447 - precision-0.55: 0.5696 - precision-0.60: 0.5952 - precision-0.65: 0.6014 - precision-0.70: 0.6290 - precision-0.75: 0.5714 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1943 - recall-0.55: 0.1146 - recall-0.60: 0.0641 - recall-0.65: 0.0280 - recall-0.70: 0.0127 - recall-0.75: 0.0026 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00       \n",
      "Epoch 11: val_loss improved from 1.13064 to 1.12753, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 145ms/step - loss: 0.9810 - tp: 767.0000 - fp: 631.0000 - tn: 7171.0000 - fn: 3134.0000 - accuracy: 0.4717 - precision: 0.5486 - precision-0.55: 0.5698 - precision-0.60: 0.5741 - precision-0.65: 0.5751 - precision-0.70: 0.5783 - precision-0.75: 0.5263 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1966 - recall-0.55: 0.1171 - recall-0.60: 0.0625 - recall-0.65: 0.0285 - recall-0.70: 0.0123 - recall-0.75: 0.0026 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1275 - val_tp: 350.0000 - val_fp: 504.0000 - val_tn: 7298.0000 - val_fn: 3551.0000 - val_accuracy: 0.3535 - val_precision: 0.4098 - val_precision-0.55: 0.4398 - val_precision-0.60: 0.4274 - val_precision-0.65: 0.2830 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0897 - val_recall-0.55: 0.0561 - val_recall-0.60: 0.0256 - val_recall-0.65: 0.0038 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 12/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9753 - tp: 669.0000 - fp: 484.0000 - tn: 5660.0000 - fn: 2403.0000 - accuracy: 0.4795 - precision: 0.5802 - precision-0.55: 0.6021 - precision-0.60: 0.6399 - precision-0.65: 0.6258 - precision-0.70: 0.6154 - precision-0.75: 0.5000 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2178 - recall-0.55: 0.1286 - recall-0.60: 0.0752 - recall-0.65: 0.0332 - recall-0.70: 0.0130 - recall-0.75: 0.0039 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 12: val_loss improved from 1.12753 to 1.11019, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 145ms/step - loss: 0.9744 - tp: 849.0000 - fp: 621.0000 - tn: 7181.0000 - fn: 3052.0000 - accuracy: 0.4794 - precision: 0.5776 - precision-0.55: 0.5993 - precision-0.60: 0.6149 - precision-0.65: 0.6055 - precision-0.70: 0.6098 - precision-0.75: 0.5000 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2176 - recall-0.55: 0.1300 - recall-0.60: 0.0720 - recall-0.65: 0.0338 - recall-0.70: 0.0128 - recall-0.75: 0.0041 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1102 - val_tp: 358.0000 - val_fp: 497.0000 - val_tn: 7305.0000 - val_fn: 3543.0000 - val_accuracy: 0.3796 - val_precision: 0.4187 - val_precision-0.55: 0.4375 - val_precision-0.60: 0.4304 - val_precision-0.65: 0.2903 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0918 - val_recall-0.55: 0.0556 - val_recall-0.60: 0.0261 - val_recall-0.65: 0.0046 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 13/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9739 - tp: 643.0000 - fp: 540.0000 - tn: 5604.0000 - fn: 2429.0000 - accuracy: 0.4645 - precision: 0.5435 - precision-0.55: 0.5727 - precision-0.60: 0.6067 - precision-0.65: 0.6505 - precision-0.70: 0.6875 - precision-0.75: 0.5625 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2093 - recall-0.55: 0.1257 - recall-0.60: 0.0703 - recall-0.65: 0.0394 - recall-0.70: 0.0143 - recall-0.75: 0.0029 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 13: val_loss improved from 1.11019 to 1.10562, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.9727 - tp: 819.0000 - fp: 669.0000 - tn: 7133.0000 - fn: 3082.0000 - accuracy: 0.4714 - precision: 0.5504 - precision-0.55: 0.5807 - precision-0.60: 0.6081 - precision-0.65: 0.6356 - precision-0.70: 0.6444 - precision-0.75: 0.5500 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2099 - recall-0.55: 0.1282 - recall-0.60: 0.0692 - recall-0.65: 0.0385 - recall-0.70: 0.0149 - recall-0.75: 0.0028 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1056 - val_tp: 359.0000 - val_fp: 494.0000 - val_tn: 7308.0000 - val_fn: 3542.0000 - val_accuracy: 0.3850 - val_precision: 0.4209 - val_precision-0.55: 0.4371 - val_precision-0.60: 0.4372 - val_precision-0.65: 0.2698 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0920 - val_recall-0.55: 0.0543 - val_recall-0.60: 0.0259 - val_recall-0.65: 0.0044 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 14/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9677 - tp: 666.0000 - fp: 531.0000 - tn: 5613.0000 - fn: 2406.0000 - accuracy: 0.4795 - precision: 0.5564 - precision-0.55: 0.5886 - precision-0.60: 0.6291 - precision-0.65: 0.6506 - precision-0.70: 0.6604 - precision-0.75: 0.6875 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2168 - recall-0.55: 0.1309 - recall-0.60: 0.0745 - recall-0.65: 0.0352 - recall-0.70: 0.0114 - recall-0.75: 0.0036 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 14: val_loss did not improve from 1.10562\n",
      "4/4 [==============================] - 0s 141ms/step - loss: 0.9692 - tp: 848.0000 - fp: 681.0000 - tn: 7121.0000 - fn: 3053.0000 - accuracy: 0.4835 - precision: 0.5546 - precision-0.55: 0.5803 - precision-0.60: 0.6218 - precision-0.65: 0.6380 - precision-0.70: 0.6667 - precision-0.75: 0.6818 - precision-0.80: 0.6667 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2174 - recall-0.55: 0.1297 - recall-0.60: 0.0746 - recall-0.65: 0.0361 - recall-0.70: 0.0123 - recall-0.75: 0.0038 - recall-0.80: 0.0010 - recall-0.85: 2.5634e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1060 - val_tp: 377.0000 - val_fp: 511.0000 - val_tn: 7291.0000 - val_fn: 3524.0000 - val_accuracy: 0.3814 - val_precision: 0.4245 - val_precision-0.55: 0.4429 - val_precision-0.60: 0.4280 - val_precision-0.65: 0.2727 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0966 - val_recall-0.55: 0.0567 - val_recall-0.60: 0.0259 - val_recall-0.65: 0.0046 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 15/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9749 - tp: 682.0000 - fp: 575.0000 - tn: 5569.0000 - fn: 2390.0000 - accuracy: 0.4880 - precision: 0.5426 - precision-0.55: 0.5735 - precision-0.60: 0.6050 - precision-0.65: 0.6094 - precision-0.70: 0.5972 - precision-0.75: 0.5926 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2220 - recall-0.55: 0.1383 - recall-0.60: 0.0788 - recall-0.65: 0.0381 - recall-0.70: 0.0140 - recall-0.75: 0.0052 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 15: val_loss improved from 1.10562 to 1.10294, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9660 - tp: 890.0000 - fp: 698.0000 - tn: 7104.0000 - fn: 3011.0000 - accuracy: 0.4922 - precision: 0.5605 - precision-0.55: 0.5957 - precision-0.60: 0.6339 - precision-0.65: 0.6502 - precision-0.70: 0.6559 - precision-0.75: 0.6452 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2281 - recall-0.55: 0.1428 - recall-0.60: 0.0825 - recall-0.65: 0.0405 - recall-0.70: 0.0156 - recall-0.75: 0.0051 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1029 - val_tp: 397.0000 - val_fp: 545.0000 - val_tn: 7257.0000 - val_fn: 3504.0000 - val_accuracy: 0.3922 - val_precision: 0.4214 - val_precision-0.55: 0.4354 - val_precision-0.60: 0.4366 - val_precision-0.65: 0.2892 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1018 - val_recall-0.55: 0.0587 - val_recall-0.60: 0.0300 - val_recall-0.65: 0.0062 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 16/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9563 - tp: 771.0000 - fp: 561.0000 - tn: 5583.0000 - fn: 2301.0000 - accuracy: 0.4906 - precision: 0.5788 - precision-0.55: 0.5974 - precision-0.60: 0.6345 - precision-0.65: 0.6816 - precision-0.70: 0.6866 - precision-0.75: 0.6471 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2510 - recall-0.55: 0.1478 - recall-0.60: 0.0814 - recall-0.65: 0.0397 - recall-0.70: 0.0150 - recall-0.75: 0.0036 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00           \n",
      "Epoch 16: val_loss improved from 1.10294 to 1.09730, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9612 - tp: 954.0000 - fp: 717.0000 - tn: 7085.0000 - fn: 2947.0000 - accuracy: 0.4863 - precision: 0.5709 - precision-0.55: 0.5892 - precision-0.60: 0.6275 - precision-0.65: 0.6667 - precision-0.70: 0.6813 - precision-0.75: 0.6538 - precision-0.80: 0.6000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2446 - recall-0.55: 0.1456 - recall-0.60: 0.0807 - recall-0.65: 0.0395 - recall-0.70: 0.0159 - recall-0.75: 0.0044 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0973 - val_tp: 427.0000 - val_fp: 574.0000 - val_tn: 7228.0000 - val_fn: 3474.0000 - val_accuracy: 0.4091 - val_precision: 0.4266 - val_precision-0.55: 0.4478 - val_precision-0.60: 0.4321 - val_precision-0.65: 0.2762 - val_precision-0.70: 0.0476 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1095 - val_recall-0.55: 0.0638 - val_recall-0.60: 0.0318 - val_recall-0.65: 0.0074 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 17/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9574 - tp: 760.0000 - fp: 558.0000 - tn: 5586.0000 - fn: 2312.0000 - accuracy: 0.4967 - precision: 0.5766 - precision-0.55: 0.6291 - precision-0.60: 0.6464 - precision-0.65: 0.6406 - precision-0.70: 0.6341 - precision-0.75: 0.4762 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2474 - recall-0.55: 0.1579 - recall-0.60: 0.0898 - recall-0.65: 0.0400 - recall-0.70: 0.0169 - recall-0.75: 0.0033 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 17: val_loss did not improve from 1.09730\n",
      "4/4 [==============================] - 0s 144ms/step - loss: 0.9552 - tp: 964.0000 - fp: 710.0000 - tn: 7092.0000 - fn: 2937.0000 - accuracy: 0.4958 - precision: 0.5759 - precision-0.55: 0.6290 - precision-0.60: 0.6519 - precision-0.65: 0.6494 - precision-0.70: 0.6609 - precision-0.75: 0.5000 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2471 - recall-0.55: 0.1569 - recall-0.60: 0.0902 - recall-0.65: 0.0418 - recall-0.70: 0.0195 - recall-0.75: 0.0036 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1002 - val_tp: 457.0000 - val_fp: 613.0000 - val_tn: 7189.0000 - val_fn: 3444.0000 - val_accuracy: 0.4058 - val_precision: 0.4271 - val_precision-0.55: 0.4253 - val_precision-0.60: 0.4162 - val_precision-0.65: 0.3431 - val_precision-0.70: 0.0345 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1171 - val_recall-0.55: 0.0672 - val_recall-0.60: 0.0356 - val_recall-0.65: 0.0120 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 18/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9494 - tp: 781.0000 - fp: 579.0000 - tn: 5565.0000 - fn: 2291.0000 - accuracy: 0.5016 - precision: 0.5743 - precision-0.55: 0.6093 - precision-0.60: 0.6410 - precision-0.65: 0.6875 - precision-0.70: 0.6582 - precision-0.75: 0.7500 - precision-0.80: 0.8571 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2542 - recall-0.55: 0.1660 - recall-0.60: 0.0977 - recall-0.65: 0.0501 - recall-0.70: 0.0169 - recall-0.75: 0.0049 - recall-0.80: 0.0020 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 18: val_loss did not improve from 1.09730\n",
      "4/4 [==============================] - 0s 141ms/step - loss: 0.9540 - tp: 1003.0000 - fp: 759.0000 - tn: 7043.0000 - fn: 2898.0000 - accuracy: 0.4976 - precision: 0.5692 - precision-0.55: 0.6017 - precision-0.60: 0.6364 - precision-0.65: 0.6679 - precision-0.70: 0.6373 - precision-0.75: 0.7500 - precision-0.80: 0.8000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2571 - recall-0.55: 0.1646 - recall-0.60: 0.0969 - recall-0.65: 0.0479 - recall-0.70: 0.0167 - recall-0.75: 0.0054 - recall-0.80: 0.0021 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0996 - val_tp: 472.0000 - val_fp: 633.0000 - val_tn: 7169.0000 - val_fn: 3429.0000 - val_accuracy: 0.4060 - val_precision: 0.4271 - val_precision-0.55: 0.4330 - val_precision-0.60: 0.4207 - val_precision-0.65: 0.3284 - val_precision-0.70: 0.0357 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1210 - val_recall-0.55: 0.0687 - val_recall-0.60: 0.0354 - val_recall-0.65: 0.0113 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 19/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9535 - tp: 784.0000 - fp: 593.0000 - tn: 5551.0000 - fn: 2288.0000 - accuracy: 0.4919 - precision: 0.5694 - precision-0.55: 0.6088 - precision-0.60: 0.6570 - precision-0.65: 0.6695 - precision-0.70: 0.7551 - precision-0.75: 0.9130 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2552 - recall-0.55: 0.1621 - recall-0.60: 0.0954 - recall-0.65: 0.0508 - recall-0.70: 0.0241 - recall-0.75: 0.0068 - recall-0.80: 3.2552e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 19: val_loss did not improve from 1.09730\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9502 - tp: 1022.0000 - fp: 753.0000 - tn: 7049.0000 - fn: 2879.0000 - accuracy: 0.4973 - precision: 0.5758 - precision-0.55: 0.6101 - precision-0.60: 0.6557 - precision-0.65: 0.6777 - precision-0.70: 0.7540 - precision-0.75: 0.8438 - precision-0.80: 0.3333 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2620 - recall-0.55: 0.1648 - recall-0.60: 0.0972 - recall-0.65: 0.0523 - recall-0.70: 0.0244 - recall-0.75: 0.0069 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0973 - val_tp: 501.0000 - val_fp: 663.0000 - val_tn: 7139.0000 - val_fn: 3400.0000 - val_accuracy: 0.4166 - val_precision: 0.4304 - val_precision-0.55: 0.4207 - val_precision-0.60: 0.4180 - val_precision-0.65: 0.3294 - val_precision-0.70: 0.0811 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1284 - val_recall-0.55: 0.0720 - val_recall-0.60: 0.0392 - val_recall-0.65: 0.0144 - val_recall-0.70: 7.6903e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9506 - tp: 1031.0000 - fp: 768.0000 - tn: 7034.0000 - fn: 2870.0000 - accuracy: 0.5027 - precision: 0.5731 - precision-0.55: 0.6136 - precision-0.60: 0.6329 - precision-0.65: 0.6264 - precision-0.70: 0.6296 - precision-0.75: 0.6774 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2643 - recall-0.55: 0.1689 - recall-0.60: 0.0928 - recall-0.65: 0.0438 - recall-0.70: 0.0174 - recall-0.75: 0.0054 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 20: val_loss improved from 1.09730 to 1.09347, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.9506 - tp: 1031.0000 - fp: 768.0000 - tn: 7034.0000 - fn: 2870.0000 - accuracy: 0.5027 - precision: 0.5731 - precision-0.55: 0.6136 - precision-0.60: 0.6329 - precision-0.65: 0.6264 - precision-0.70: 0.6296 - precision-0.75: 0.6774 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2643 - recall-0.55: 0.1689 - recall-0.60: 0.0928 - recall-0.65: 0.0438 - recall-0.70: 0.0174 - recall-0.75: 0.0054 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0935 - val_tp: 526.0000 - val_fp: 674.0000 - val_tn: 7128.0000 - val_fn: 3375.0000 - val_accuracy: 0.4235 - val_precision: 0.4383 - val_precision-0.55: 0.4247 - val_precision-0.60: 0.4173 - val_precision-0.65: 0.3174 - val_precision-0.70: 0.0789 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1348 - val_recall-0.55: 0.0731 - val_recall-0.60: 0.0395 - val_recall-0.65: 0.0136 - val_recall-0.70: 7.6903e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 21/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9439 - tp: 826.0000 - fp: 603.0000 - tn: 5541.0000 - fn: 2246.0000 - accuracy: 0.5075 - precision: 0.5780 - precision-0.55: 0.6211 - precision-0.60: 0.6439 - precision-0.65: 0.6763 - precision-0.70: 0.6471 - precision-0.75: 0.8889 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2689 - recall-0.55: 0.1761 - recall-0.60: 0.0983 - recall-0.65: 0.0531 - recall-0.70: 0.0179 - recall-0.75: 0.0052 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 21: val_loss did not improve from 1.09347\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.9437 - tp: 1055.0000 - fp: 775.0000 - tn: 7027.0000 - fn: 2846.0000 - accuracy: 0.5086 - precision: 0.5765 - precision-0.55: 0.6210 - precision-0.60: 0.6487 - precision-0.65: 0.6678 - precision-0.70: 0.6275 - precision-0.75: 0.7826 - precision-0.80: 0.4000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2704 - recall-0.55: 0.1743 - recall-0.60: 0.0989 - recall-0.65: 0.0515 - recall-0.70: 0.0164 - recall-0.75: 0.0046 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0945 - val_tp: 535.0000 - val_fp: 690.0000 - val_tn: 7112.0000 - val_fn: 3366.0000 - val_accuracy: 0.4214 - val_precision: 0.4367 - val_precision-0.55: 0.4281 - val_precision-0.60: 0.4183 - val_precision-0.65: 0.3292 - val_precision-0.70: 0.0286 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1371 - val_recall-0.55: 0.0725 - val_recall-0.60: 0.0387 - val_recall-0.65: 0.0136 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 22/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9462 - tp: 847.0000 - fp: 613.0000 - tn: 5531.0000 - fn: 2225.0000 - accuracy: 0.5039 - precision: 0.5801 - precision-0.55: 0.6247 - precision-0.60: 0.6424 - precision-0.65: 0.6468 - precision-0.70: 0.6629 - precision-0.75: 0.7727 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2757 - recall-0.55: 0.1794 - recall-0.60: 0.0977 - recall-0.65: 0.0495 - recall-0.70: 0.0192 - recall-0.75: 0.0055 - recall-0.80: 9.7656e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 22: val_loss did not improve from 1.09347\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9459 - tp: 1080.0000 - fp: 799.0000 - tn: 7003.0000 - fn: 2821.0000 - accuracy: 0.5035 - precision: 0.5748 - precision-0.55: 0.6137 - precision-0.60: 0.6503 - precision-0.65: 0.6633 - precision-0.70: 0.6875 - precision-0.75: 0.8333 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2769 - recall-0.55: 0.1792 - recall-0.60: 0.0987 - recall-0.65: 0.0505 - recall-0.70: 0.0197 - recall-0.75: 0.0064 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0994 - val_tp: 532.0000 - val_fp: 727.0000 - val_tn: 7075.0000 - val_fn: 3369.0000 - val_accuracy: 0.4168 - val_precision: 0.4226 - val_precision-0.55: 0.4210 - val_precision-0.60: 0.4179 - val_precision-0.65: 0.3942 - val_precision-0.70: 0.1695 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1364 - val_recall-0.55: 0.0772 - val_recall-0.60: 0.0443 - val_recall-0.65: 0.0210 - val_recall-0.70: 0.0026 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 23/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9343 - tp: 862.0000 - fp: 621.0000 - tn: 5523.0000 - fn: 2210.0000 - accuracy: 0.5215 - precision: 0.5813 - precision-0.55: 0.6192 - precision-0.60: 0.6799 - precision-0.65: 0.7125 - precision-0.70: 0.7284 - precision-0.75: 0.6364 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2806 - recall-0.55: 0.1852 - recall-0.60: 0.1058 - recall-0.65: 0.0557 - recall-0.70: 0.0192 - recall-0.75: 0.0046 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 23: val_loss did not improve from 1.09347\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9344 - tp: 1118.0000 - fp: 791.0000 - tn: 7011.0000 - fn: 2783.0000 - accuracy: 0.5232 - precision: 0.5856 - precision-0.55: 0.6252 - precision-0.60: 0.6862 - precision-0.65: 0.7070 - precision-0.70: 0.7117 - precision-0.75: 0.5938 - precision-0.80: 0.6000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2866 - recall-0.55: 0.1907 - recall-0.60: 0.1110 - recall-0.65: 0.0569 - recall-0.70: 0.0203 - recall-0.75: 0.0049 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1007 - val_tp: 557.0000 - val_fp: 762.0000 - val_tn: 7040.0000 - val_fn: 3344.0000 - val_accuracy: 0.4160 - val_precision: 0.4223 - val_precision-0.55: 0.4167 - val_precision-0.60: 0.4176 - val_precision-0.65: 0.4183 - val_precision-0.70: 0.2500 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1428 - val_recall-0.55: 0.0846 - val_recall-0.60: 0.0500 - val_recall-0.65: 0.0282 - val_recall-0.70: 0.0056 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 24/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9414 - tp: 844.0000 - fp: 623.0000 - tn: 5521.0000 - fn: 2228.0000 - accuracy: 0.5124 - precision: 0.5753 - precision-0.55: 0.6059 - precision-0.60: 0.6545 - precision-0.65: 0.6768 - precision-0.70: 0.7290 - precision-0.75: 0.6667 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2747 - recall-0.55: 0.1797 - recall-0.60: 0.1110 - recall-0.65: 0.0579 - recall-0.70: 0.0254 - recall-0.75: 0.0072 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 24: val_loss did not improve from 1.09347\n",
      "4/4 [==============================] - 0s 142ms/step - loss: 0.9417 - tp: 1082.0000 - fp: 790.0000 - tn: 7012.0000 - fn: 2819.0000 - accuracy: 0.5112 - precision: 0.5780 - precision-0.55: 0.6022 - precision-0.60: 0.6560 - precision-0.65: 0.6697 - precision-0.70: 0.7176 - precision-0.75: 0.6829 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2774 - recall-0.55: 0.1797 - recall-0.60: 0.1105 - recall-0.65: 0.0572 - recall-0.70: 0.0241 - recall-0.75: 0.0072 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0983 - val_tp: 572.0000 - val_fp: 778.0000 - val_tn: 7024.0000 - val_fn: 3329.0000 - val_accuracy: 0.4219 - val_precision: 0.4237 - val_precision-0.55: 0.4215 - val_precision-0.60: 0.4158 - val_precision-0.65: 0.4202 - val_precision-0.70: 0.2289 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1466 - val_recall-0.55: 0.0846 - val_recall-0.60: 0.0487 - val_recall-0.65: 0.0277 - val_recall-0.70: 0.0049 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 25/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9371 - tp: 891.0000 - fp: 628.0000 - tn: 5516.0000 - fn: 2181.0000 - accuracy: 0.5104 - precision: 0.5866 - precision-0.55: 0.6060 - precision-0.60: 0.6334 - precision-0.65: 0.6654 - precision-0.70: 0.6944 - precision-0.75: 0.7297 - precision-0.80: 1.0000 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2900 - recall-0.55: 0.1833 - recall-0.60: 0.1074 - recall-0.65: 0.0576 - recall-0.70: 0.0244 - recall-0.75: 0.0088 - recall-0.80: 0.0016 - recall-0.85: 3.2552e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00           \n",
      "Epoch 25: val_loss improved from 1.09347 to 1.09215, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 147ms/step - loss: 0.9412 - tp: 1116.0000 - fp: 817.0000 - tn: 6985.0000 - fn: 2785.0000 - accuracy: 0.5081 - precision: 0.5773 - precision-0.55: 0.6101 - precision-0.60: 0.6409 - precision-0.65: 0.6728 - precision-0.70: 0.7154 - precision-0.75: 0.7297 - precision-0.80: 1.0000 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2861 - recall-0.55: 0.1833 - recall-0.60: 0.1084 - recall-0.65: 0.0564 - recall-0.70: 0.0238 - recall-0.75: 0.0069 - recall-0.80: 0.0013 - recall-0.85: 2.5634e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0922 - val_tp: 587.0000 - val_fp: 770.0000 - val_tn: 7032.0000 - val_fn: 3314.0000 - val_accuracy: 0.4299 - val_precision: 0.4326 - val_precision-0.55: 0.4314 - val_precision-0.60: 0.4145 - val_precision-0.65: 0.4009 - val_precision-0.70: 0.1571 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1505 - val_recall-0.55: 0.0838 - val_recall-0.60: 0.0454 - val_recall-0.65: 0.0233 - val_recall-0.70: 0.0028 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 26/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9362 - tp: 885.0000 - fp: 667.0000 - tn: 5477.0000 - fn: 2187.0000 - accuracy: 0.5140 - precision: 0.5702 - precision-0.55: 0.5993 - precision-0.60: 0.6198 - precision-0.65: 0.6147 - precision-0.70: 0.6809 - precision-0.75: 0.7500 - precision-0.80: 0.6000 - precision-0.85: 0.6667 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2881 - recall-0.55: 0.1768 - recall-0.60: 0.0977 - recall-0.65: 0.0436 - recall-0.70: 0.0208 - recall-0.75: 0.0068 - recall-0.80: 9.7656e-04 - recall-0.85: 6.5104e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00       \n",
      "Epoch 26: val_loss did not improve from 1.09215\n",
      "4/4 [==============================] - 0s 145ms/step - loss: 0.9379 - tp: 1135.0000 - fp: 829.0000 - tn: 6973.0000 - fn: 2766.0000 - accuracy: 0.5165 - precision: 0.5779 - precision-0.55: 0.6112 - precision-0.60: 0.6278 - precision-0.65: 0.6477 - precision-0.70: 0.7190 - precision-0.75: 0.7714 - precision-0.80: 0.6667 - precision-0.85: 0.7500 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2910 - recall-0.55: 0.1817 - recall-0.60: 0.1007 - recall-0.65: 0.0467 - recall-0.70: 0.0223 - recall-0.75: 0.0069 - recall-0.80: 0.0010 - recall-0.85: 7.6903e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0951 - val_tp: 594.0000 - val_fp: 799.0000 - val_tn: 7003.0000 - val_fn: 3307.0000 - val_accuracy: 0.4268 - val_precision: 0.4264 - val_precision-0.55: 0.4250 - val_precision-0.60: 0.4030 - val_precision-0.65: 0.4144 - val_precision-0.70: 0.2118 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1523 - val_recall-0.55: 0.0879 - val_recall-0.60: 0.0484 - val_recall-0.65: 0.0279 - val_recall-0.70: 0.0046 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 27/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9333 - tp: 901.0000 - fp: 608.0000 - tn: 5536.0000 - fn: 2171.0000 - accuracy: 0.5218 - precision: 0.5971 - precision-0.55: 0.6251 - precision-0.60: 0.6726 - precision-0.65: 0.6820 - precision-0.70: 0.7349 - precision-0.75: 0.9333 - precision-0.80: 0.8000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2933 - recall-0.55: 0.1862 - recall-0.60: 0.1104 - recall-0.65: 0.0579 - recall-0.70: 0.0199 - recall-0.75: 0.0046 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 \n",
      "Epoch 27: val_loss did not improve from 1.09215\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.9368 - tp: 1145.0000 - fp: 800.0000 - tn: 7002.0000 - fn: 2756.0000 - accuracy: 0.5176 - precision: 0.5887 - precision-0.55: 0.6117 - precision-0.60: 0.6425 - precision-0.65: 0.6426 - precision-0.70: 0.7103 - precision-0.75: 0.8421 - precision-0.80: 0.7143 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2935 - recall-0.55: 0.1846 - recall-0.60: 0.1069 - recall-0.65: 0.0549 - recall-0.70: 0.0195 - recall-0.75: 0.0041 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0943 - val_tp: 617.0000 - val_fp: 834.0000 - val_tn: 6968.0000 - val_fn: 3284.0000 - val_accuracy: 0.4299 - val_precision: 0.4252 - val_precision-0.55: 0.4172 - val_precision-0.60: 0.4056 - val_precision-0.65: 0.4128 - val_precision-0.70: 0.2524 - val_precision-0.75: 0.0370 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1582 - val_recall-0.55: 0.0910 - val_recall-0.60: 0.0518 - val_recall-0.65: 0.0297 - val_recall-0.70: 0.0067 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 28/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9234 - tp: 942.0000 - fp: 598.0000 - tn: 5546.0000 - fn: 2130.0000 - accuracy: 0.5303 - precision: 0.6117 - precision-0.55: 0.6455 - precision-0.60: 0.6680 - precision-0.65: 0.6969 - precision-0.70: 0.7778 - precision-0.75: 0.8889 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3066 - recall-0.55: 0.1986 - recall-0.60: 0.1120 - recall-0.65: 0.0576 - recall-0.70: 0.0228 - recall-0.75: 0.0078 - recall-0.80: 9.7656e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 28: val_loss did not improve from 1.09215\n",
      "4/4 [==============================] - 0s 143ms/step - loss: 0.9284 - tp: 1179.0000 - fp: 780.0000 - tn: 7022.0000 - fn: 2722.0000 - accuracy: 0.5252 - precision: 0.6018 - precision-0.55: 0.6338 - precision-0.60: 0.6574 - precision-0.65: 0.6984 - precision-0.70: 0.7524 - precision-0.75: 0.8387 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3022 - recall-0.55: 0.1961 - recall-0.60: 0.1087 - recall-0.65: 0.0546 - recall-0.70: 0.0203 - recall-0.75: 0.0067 - recall-0.80: 7.6903e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0950 - val_tp: 615.0000 - val_fp: 828.0000 - val_tn: 6974.0000 - val_fn: 3286.0000 - val_accuracy: 0.4276 - val_precision: 0.4262 - val_precision-0.55: 0.4193 - val_precision-0.60: 0.4025 - val_precision-0.65: 0.4143 - val_precision-0.70: 0.2300 - val_precision-0.75: 0.0385 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1577 - val_recall-0.55: 0.0892 - val_recall-0.60: 0.0497 - val_recall-0.65: 0.0297 - val_recall-0.70: 0.0059 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 29/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9289 - tp: 933.0000 - fp: 651.0000 - tn: 5493.0000 - fn: 2139.0000 - accuracy: 0.5192 - precision: 0.5890 - precision-0.55: 0.6276 - precision-0.60: 0.6426 - precision-0.65: 0.6719 - precision-0.70: 0.7248 - precision-0.75: 0.7143 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3037 - recall-0.55: 0.1969 - recall-0.60: 0.1100 - recall-0.65: 0.0553 - recall-0.70: 0.0257 - recall-0.75: 0.0049 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 29: val_loss did not improve from 1.09215\n",
      "4/4 [==============================] - 0s 149ms/step - loss: 0.9316 - tp: 1165.0000 - fp: 824.0000 - tn: 6978.0000 - fn: 2736.0000 - accuracy: 0.5163 - precision: 0.5857 - precision-0.55: 0.6202 - precision-0.60: 0.6476 - precision-0.65: 0.6781 - precision-0.70: 0.7203 - precision-0.75: 0.6897 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2986 - recall-0.55: 0.1917 - recall-0.60: 0.1102 - recall-0.65: 0.0556 - recall-0.70: 0.0264 - recall-0.75: 0.0051 - recall-0.80: 0.0010 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1000 - val_tp: 600.0000 - val_fp: 829.0000 - val_tn: 6973.0000 - val_fn: 3301.0000 - val_accuracy: 0.4227 - val_precision: 0.4199 - val_precision-0.55: 0.4161 - val_precision-0.60: 0.3992 - val_precision-0.65: 0.4214 - val_precision-0.70: 0.2268 - val_precision-0.75: 0.0370 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1538 - val_recall-0.55: 0.0890 - val_recall-0.60: 0.0492 - val_recall-0.65: 0.0302 - val_recall-0.70: 0.0056 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 30/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9331 - tp: 912.0000 - fp: 651.0000 - tn: 5493.0000 - fn: 2160.0000 - accuracy: 0.5179 - precision: 0.5835 - precision-0.55: 0.6289 - precision-0.60: 0.6733 - precision-0.65: 0.7315 - precision-0.70: 0.7524 - precision-0.75: 0.7576 - precision-0.80: 0.8000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2969 - recall-0.55: 0.1914 - recall-0.60: 0.1094 - recall-0.65: 0.0612 - recall-0.70: 0.0257 - recall-0.75: 0.0081 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 30: val_loss improved from 1.09215 to 1.09188, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154443.h5\n",
      "4/4 [==============================] - 0s 144ms/step - loss: 0.9303 - tp: 1182.0000 - fp: 823.0000 - tn: 6979.0000 - fn: 2719.0000 - accuracy: 0.5211 - precision: 0.5895 - precision-0.55: 0.6326 - precision-0.60: 0.6754 - precision-0.65: 0.7292 - precision-0.70: 0.7721 - precision-0.75: 0.8000 - precision-0.80: 0.8333 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3030 - recall-0.55: 0.1951 - recall-0.60: 0.1125 - recall-0.65: 0.0608 - recall-0.70: 0.0269 - recall-0.75: 0.0092 - recall-0.80: 0.0013 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0919 - val_tp: 636.0000 - val_fp: 843.0000 - val_tn: 6959.0000 - val_fn: 3265.0000 - val_accuracy: 0.4312 - val_precision: 0.4300 - val_precision-0.55: 0.4234 - val_precision-0.60: 0.4054 - val_precision-0.65: 0.4205 - val_precision-0.70: 0.2222 - val_precision-0.75: 0.0357 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1630 - val_recall-0.55: 0.0907 - val_recall-0.60: 0.0500 - val_recall-0.65: 0.0305 - val_recall-0.70: 0.0056 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 31/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9258 - tp: 936.0000 - fp: 647.0000 - tn: 5497.0000 - fn: 2136.0000 - accuracy: 0.5195 - precision: 0.5913 - precision-0.55: 0.6431 - precision-0.60: 0.6903 - precision-0.65: 0.7167 - precision-0.70: 0.7157 - precision-0.75: 0.8125 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3047 - recall-0.55: 0.2048 - recall-0.60: 0.1234 - recall-0.65: 0.0544 - recall-0.70: 0.0238 - recall-0.75: 0.0085 - recall-0.80: 9.7656e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 31: val_loss did not improve from 1.09188\n",
      "4/4 [==============================] - 0s 143ms/step - loss: 0.9292 - tp: 1175.0000 - fp: 819.0000 - tn: 6983.0000 - fn: 2726.0000 - accuracy: 0.5181 - precision: 0.5893 - precision-0.55: 0.6431 - precision-0.60: 0.6844 - precision-0.65: 0.7110 - precision-0.70: 0.7132 - precision-0.75: 0.7917 - precision-0.80: 0.8750 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3012 - recall-0.55: 0.2005 - recall-0.60: 0.1189 - recall-0.65: 0.0549 - recall-0.70: 0.0249 - recall-0.75: 0.0097 - recall-0.80: 0.0018 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1055 - val_tp: 612.0000 - val_fp: 908.0000 - val_tn: 6894.0000 - val_fn: 3289.0000 - val_accuracy: 0.4201 - val_precision: 0.4026 - val_precision-0.55: 0.3987 - val_precision-0.60: 0.3959 - val_precision-0.65: 0.3896 - val_precision-0.70: 0.3352 - val_precision-0.75: 0.0385 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1569 - val_recall-0.55: 0.0979 - val_recall-0.60: 0.0590 - val_recall-0.65: 0.0367 - val_recall-0.70: 0.0151 - val_recall-0.75: 5.1269e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 32/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9277 - tp: 904.0000 - fp: 632.0000 - tn: 5512.0000 - fn: 2168.0000 - accuracy: 0.5212 - precision: 0.5885 - precision-0.55: 0.6128 - precision-0.60: 0.6494 - precision-0.65: 0.6906 - precision-0.70: 0.7170 - precision-0.75: 0.6750 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2943 - recall-0.55: 0.1927 - recall-0.60: 0.1146 - recall-0.65: 0.0596 - recall-0.70: 0.0247 - recall-0.75: 0.0088 - recall-0.80: 0.0020 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 32: val_loss did not improve from 1.09188\n",
      "4/4 [==============================] - 0s 140ms/step - loss: 0.9261 - tp: 1172.0000 - fp: 782.0000 - tn: 7020.0000 - fn: 2729.0000 - accuracy: 0.5273 - precision: 0.5998 - precision-0.55: 0.6247 - precision-0.60: 0.6701 - precision-0.65: 0.7173 - precision-0.70: 0.7609 - precision-0.75: 0.7200 - precision-0.80: 0.8000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3004 - recall-0.55: 0.1958 - recall-0.60: 0.1177 - recall-0.65: 0.0618 - recall-0.70: 0.0269 - recall-0.75: 0.0092 - recall-0.80: 0.0021 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.0992 - val_tp: 638.0000 - val_fp: 906.0000 - val_tn: 6896.0000 - val_fn: 3263.0000 - val_accuracy: 0.4248 - val_precision: 0.4132 - val_precision-0.55: 0.4106 - val_precision-0.60: 0.4022 - val_precision-0.65: 0.4029 - val_precision-0.70: 0.3311 - val_precision-0.75: 0.0426 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1635 - val_recall-0.55: 0.0972 - val_recall-0.60: 0.0559 - val_recall-0.65: 0.0356 - val_recall-0.70: 0.0128 - val_recall-0.75: 5.1269e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 33/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9272 - tp: 958.0000 - fp: 638.0000 - tn: 5506.0000 - fn: 2114.0000 - accuracy: 0.5267 - precision: 0.6003 - precision-0.55: 0.6350 - precision-0.60: 0.6825 - precision-0.65: 0.7366 - precision-0.70: 0.7155 - precision-0.75: 0.7742 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3118 - recall-0.55: 0.2021 - recall-0.60: 0.1260 - recall-0.65: 0.0628 - recall-0.70: 0.0270 - recall-0.75: 0.0078 - recall-0.80: 6.5104e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 33: val_loss did not improve from 1.09188\n",
      "4/4 [==============================] - 0s 141ms/step - loss: 0.9263 - tp: 1209.0000 - fp: 815.0000 - tn: 6987.0000 - fn: 2692.0000 - accuracy: 0.5278 - precision: 0.5973 - precision-0.55: 0.6337 - precision-0.60: 0.6866 - precision-0.65: 0.7401 - precision-0.70: 0.7292 - precision-0.75: 0.7838 - precision-0.80: 0.6667 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3099 - recall-0.55: 0.2005 - recall-0.60: 0.1236 - recall-0.65: 0.0620 - recall-0.70: 0.0269 - recall-0.75: 0.0074 - recall-0.80: 5.1269e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1012 - val_tp: 627.0000 - val_fp: 878.0000 - val_tn: 6924.0000 - val_fn: 3274.0000 - val_accuracy: 0.4217 - val_precision: 0.4166 - val_precision-0.55: 0.4212 - val_precision-0.60: 0.4126 - val_precision-0.65: 0.4132 - val_precision-0.70: 0.2824 - val_precision-0.75: 0.0256 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1607 - val_recall-0.55: 0.0946 - val_recall-0.60: 0.0538 - val_recall-0.65: 0.0336 - val_recall-0.70: 0.0095 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9261 - tp: 1224.0000 - fp: 804.0000 - tn: 6998.0000 - fn: 2677.0000 - accuracy: 0.5324 - precision: 0.6036 - precision-0.55: 0.6332 - precision-0.60: 0.6728 - precision-0.65: 0.6906 - precision-0.70: 0.7440 - precision-0.75: 0.7632 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3138 - recall-0.55: 0.1974 - recall-0.60: 0.1123 - recall-0.65: 0.0567 - recall-0.70: 0.0238 - recall-0.75: 0.0074 - recall-0.80: 0.0015 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 34: val_loss did not improve from 1.09188\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.9261 - tp: 1224.0000 - fp: 804.0000 - tn: 6998.0000 - fn: 2677.0000 - accuracy: 0.5324 - precision: 0.6036 - precision-0.55: 0.6332 - precision-0.60: 0.6728 - precision-0.65: 0.6906 - precision-0.70: 0.7440 - precision-0.75: 0.7632 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3138 - recall-0.55: 0.1974 - recall-0.60: 0.1123 - recall-0.65: 0.0567 - recall-0.70: 0.0238 - recall-0.75: 0.0074 - recall-0.80: 0.0015 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1045 - val_tp: 640.0000 - val_fp: 912.0000 - val_tn: 6890.0000 - val_fn: 3261.0000 - val_accuracy: 0.4178 - val_precision: 0.4124 - val_precision-0.55: 0.4051 - val_precision-0.60: 0.4043 - val_precision-0.65: 0.3994 - val_precision-0.70: 0.3313 - val_precision-0.75: 0.0377 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1641 - val_recall-0.55: 0.0979 - val_recall-0.60: 0.0579 - val_recall-0.65: 0.0361 - val_recall-0.70: 0.0141 - val_recall-0.75: 5.1269e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 35/200\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9265 - tp: 949.0000 - fp: 657.0000 - tn: 5487.0000 - fn: 2123.0000 - accuracy: 0.5176 - precision: 0.5909 - precision-0.55: 0.6347 - precision-0.60: 0.6650 - precision-0.65: 0.7021 - precision-0.70: 0.7385 - precision-0.75: 0.7179 - precision-0.80: 0.7500 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3089 - recall-0.55: 0.2087 - recall-0.60: 0.1266 - recall-0.65: 0.0645 - recall-0.70: 0.0312 - recall-0.75: 0.0091 - recall-0.80: 9.7656e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 35: val_loss did not improve from 1.09188\n",
      "4/4 [==============================] - 0s 147ms/step - loss: 0.9243 - tp: 1214.0000 - fp: 853.0000 - tn: 6949.0000 - fn: 2687.0000 - accuracy: 0.5232 - precision: 0.5873 - precision-0.55: 0.6334 - precision-0.60: 0.6626 - precision-0.65: 0.6959 - precision-0.70: 0.7419 - precision-0.75: 0.7347 - precision-0.80: 0.8000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3112 - recall-0.55: 0.2099 - recall-0.60: 0.1248 - recall-0.65: 0.0610 - recall-0.70: 0.0295 - recall-0.75: 0.0092 - recall-0.80: 0.0010 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 1.1018 - val_tp: 664.0000 - val_fp: 963.0000 - val_tn: 6839.0000 - val_fn: 3237.0000 - val_accuracy: 0.4258 - val_precision: 0.4081 - val_precision-0.55: 0.3971 - val_precision-0.60: 0.3961 - val_precision-0.65: 0.3949 - val_precision-0.70: 0.3561 - val_precision-0.75: 0.1045 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1702 - val_recall-0.55: 0.1038 - val_recall-0.60: 0.0631 - val_recall-0.65: 0.0395 - val_recall-0.70: 0.0187 - val_recall-0.75: 0.0018 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [358 575 359 565 567 574 573 572 566 570]\n",
      "Epoch 35: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3891 - tp: 509.0000 - fp: 1607.0000 - tn: 6195.0000 - fn: 3392.0000 - accuracy: 0.2689 - precision: 0.2405 - precision-0.55: 0.2550 - precision-0.60: 0.2674 - precision-0.65: 0.2710 - precision-0.70: 0.2833 - precision-0.75: 0.3107 - precision-0.80: 0.3218 - precision-0.85: 0.3600 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1305 - recall-0.55: 0.1110 - recall-0.60: 0.0954 - recall-0.65: 0.0728 - recall-0.70: 0.0508 - recall-0.75: 0.0351 - recall-0.80: 0.0167 - recall-0.85: 0.0023 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.13      0.22      2694\n",
      "           1       0.20      0.11      0.14       503\n",
      "           2       0.20      0.92      0.33       704\n",
      "\n",
      "    accuracy                           0.27      3901\n",
      "   macro avg       0.44      0.39      0.23      3901\n",
      "weighted avg       0.70      0.27      0.23      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "        P0   P1    P2  Total    RP0    RP1    RP2\n",
      "0      345  183  2166   2694  0.128  0.068  0.804\n",
      "1       18   56   429    503  0.036  0.111  0.853\n",
      "2       13   43   648    704  0.018  0.061  0.920\n",
      "Total  376  282  3243   3901  0.096  0.072  0.831\n",
      "\n",
      ">>>>>> FOLD 2\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 7802, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 2937(37.64%)\n",
      "Label 1: 2390(30.63%)\n",
      "Label 2: 2475(31.72%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 2694(69.06%)\n",
      "Label 1: 503(12.89%)\n",
      "Label 2: 704(18.05%)\n",
      "\n",
      "Test:\n",
      "Label 0: 3015(77.29%)\n",
      "Label 1: 476(12.2%)\n",
      "Label 2: 410(10.51%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.12574786087124826, -0.08034742540181541, -0.045400395324581226]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.1280 - tp: 970.0000 - fp: 2381.0000 - tn: 19757.0000 - fn: 10099.0000 - accuracy: 0.3230 - precision: 0.2895 - precision-0.55: 0.2842 - precision-0.60: 0.2866 - precision-0.65: 0.2748 - precision-0.70: 0.2803 - precision-0.75: 0.3107 - precision-0.80: 0.3218 - precision-0.85: 0.3600 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0876 - recall-0.55: 0.0567 - recall-0.60: 0.0401 - recall-0.65: 0.0270 - recall-0.70: 0.0180 - recall-0.75: 0.0124 - recall-0.80: 0.0059 - recall-0.85: 8.1308e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.95508, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 5s 318ms/step - loss: 1.1250 - tp: 1047.0000 - fp: 2465.0000 - tn: 20941.0000 - fn: 10656.0000 - accuracy: 0.3288 - precision: 0.2981 - precision-0.55: 0.2877 - precision-0.60: 0.2883 - precision-0.65: 0.2750 - precision-0.70: 0.2803 - precision-0.75: 0.3107 - precision-0.80: 0.3218 - precision-0.85: 0.3600 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.0895 - recall-0.55: 0.0560 - recall-0.60: 0.0386 - recall-0.65: 0.0256 - recall-0.70: 0.0170 - recall-0.75: 0.0117 - recall-0.80: 0.0056 - recall-0.85: 7.6903e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.9551 - val_tp: 489.0000 - val_fp: 188.0000 - val_tn: 7614.0000 - val_fn: 3412.0000 - val_accuracy: 0.6237 - val_precision: 0.7223 - val_precision-0.55: 0.5965 - val_precision-0.60: 0.0000e+00 - val_precision-0.65: 0.0000e+00 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1254 - val_recall-0.55: 0.0087 - val_recall-0.60: 0.0000e+00 - val_recall-0.65: 0.0000e+00 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0698 - tp: 982.0000 - fp: 929.0000 - tn: 13407.0000 - fn: 6186.0000 - accuracy: 0.4383 - precision: 0.5139 - precision-0.55: 0.5527 - precision-0.60: 0.5461 - precision-0.65: 0.6111 - precision-0.70: 0.4737 - precision-0.75: 1.0000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1370 - recall-0.55: 0.0629 - recall-0.60: 0.0215 - recall-0.65: 0.0077 - recall-0.70: 0.0013 - recall-0.75: 1.3951e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 2: val_loss did not improve from 0.95508\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.0673 - tp: 1050.0000 - fp: 973.0000 - tn: 14631.0000 - fn: 6752.0000 - accuracy: 0.4423 - precision: 0.5190 - precision-0.55: 0.5522 - precision-0.60: 0.5458 - precision-0.65: 0.6000 - precision-0.70: 0.4545 - precision-0.75: 0.5000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1346 - recall-0.55: 0.0610 - recall-0.60: 0.0206 - recall-0.65: 0.0073 - recall-0.70: 0.0013 - recall-0.75: 1.2817e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.9941 - val_tp: 188.0000 - val_fp: 93.0000 - val_tn: 7709.0000 - val_fn: 3713.0000 - val_accuracy: 0.5988 - val_precision: 0.6690 - val_precision-0.55: 0.6038 - val_precision-0.60: 0.6667 - val_precision-0.65: 0.0000e+00 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.0482 - val_recall-0.55: 0.0082 - val_recall-0.60: 5.1269e-04 - val_recall-0.65: 0.0000e+00 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.0379 - tp: 932.0000 - fp: 758.0000 - tn: 14846.0000 - fn: 6870.0000 - accuracy: 0.4564 - precision: 0.5515 - precision-0.55: 0.5877 - precision-0.60: 0.5785 - precision-0.65: 0.6301 - precision-0.70: 0.6364 - precision-0.75: 0.7500 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1195 - recall-0.55: 0.0528 - recall-0.60: 0.0194 - recall-0.65: 0.0059 - recall-0.70: 0.0018 - recall-0.75: 3.8452e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 0.95508 to 0.93353, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.0379 - tp: 932.0000 - fp: 758.0000 - tn: 14846.0000 - fn: 6870.0000 - accuracy: 0.4564 - precision: 0.5515 - precision-0.55: 0.5877 - precision-0.60: 0.5785 - precision-0.65: 0.6301 - precision-0.70: 0.6364 - precision-0.75: 0.7500 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1195 - recall-0.55: 0.0528 - recall-0.60: 0.0194 - recall-0.65: 0.0059 - recall-0.70: 0.0018 - recall-0.75: 3.8452e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.9335 - val_tp: 874.0000 - val_fp: 206.0000 - val_tn: 7596.0000 - val_fn: 3027.0000 - val_accuracy: 0.6468 - val_precision: 0.8093 - val_precision-0.55: 0.8529 - val_precision-0.60: 0.8421 - val_precision-0.65: 0.0000e+00 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.2240 - val_recall-0.55: 0.0595 - val_recall-0.60: 0.0041 - val_recall-0.65: 0.0000e+00 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.0079 - tp: 1354.0000 - fp: 928.0000 - tn: 13408.0000 - fn: 5814.0000 - accuracy: 0.4954 - precision: 0.5933 - precision-0.55: 0.5956 - precision-0.60: 0.6543 - precision-0.65: 0.6425 - precision-0.70: 0.6111 - precision-0.75: 0.5000 - precision-0.80: 0.0000e+00 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1889 - recall-0.55: 0.0986 - recall-0.60: 0.0467 - recall-0.65: 0.0160 - recall-0.70: 0.0046 - recall-0.75: 8.3705e-04 - recall-0.80: 0.0000e+00 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 0.93353 to 0.86366, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.0076 - tp: 1489.0000 - fp: 1026.0000 - tn: 14578.0000 - fn: 6313.0000 - accuracy: 0.4967 - precision: 0.5920 - precision-0.55: 0.5903 - precision-0.60: 0.6453 - precision-0.65: 0.6244 - precision-0.70: 0.6452 - precision-0.75: 0.6000 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.1908 - recall-0.55: 0.1001 - recall-0.60: 0.0478 - recall-0.65: 0.0164 - recall-0.70: 0.0051 - recall-0.75: 0.0012 - recall-0.80: 1.2817e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.8637 - val_tp: 1769.0000 - val_fp: 448.0000 - val_tn: 7354.0000 - val_fn: 2132.0000 - val_accuracy: 0.6775 - val_precision: 0.7979 - val_precision-0.55: 0.8484 - val_precision-0.60: 0.8807 - val_precision-0.65: 0.9432 - val_precision-0.70: 1.0000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4535 - val_recall-0.55: 0.2927 - val_recall-0.60: 0.1097 - val_recall-0.65: 0.0213 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9877 - tp: 1605.0000 - fp: 1036.0000 - tn: 13300.0000 - fn: 5563.0000 - accuracy: 0.5110 - precision: 0.6077 - precision-0.55: 0.6409 - precision-0.60: 0.6612 - precision-0.65: 0.6985 - precision-0.70: 0.6825 - precision-0.75: 0.7500 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2239 - recall-0.55: 0.1297 - recall-0.60: 0.0621 - recall-0.65: 0.0255 - recall-0.70: 0.0060 - recall-0.75: 0.0013 - recall-0.80: 2.7902e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00  \n",
      "Epoch 5: val_loss improved from 0.86366 to 0.85791, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.9873 - tp: 1732.0000 - fp: 1126.0000 - tn: 14478.0000 - fn: 6070.0000 - accuracy: 0.5106 - precision: 0.6060 - precision-0.55: 0.6403 - precision-0.60: 0.6671 - precision-0.65: 0.6979 - precision-0.70: 0.7183 - precision-0.75: 0.7857 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2220 - recall-0.55: 0.1287 - recall-0.60: 0.0624 - recall-0.65: 0.0258 - recall-0.70: 0.0065 - recall-0.75: 0.0014 - recall-0.80: 2.5634e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.8579 - val_tp: 1775.0000 - val_fp: 401.0000 - val_tn: 7401.0000 - val_fn: 2126.0000 - val_accuracy: 0.6778 - val_precision: 0.8157 - val_precision-0.55: 0.8633 - val_precision-0.60: 0.9007 - val_precision-0.65: 0.9648 - val_precision-0.70: 1.0000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4550 - val_recall-0.55: 0.3109 - val_recall-0.60: 0.1418 - val_recall-0.65: 0.0351 - val_recall-0.70: 0.0033 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.9720 - tp: 1967.0000 - fp: 1261.0000 - tn: 14343.0000 - fn: 5835.0000 - accuracy: 0.5161 - precision: 0.6094 - precision-0.55: 0.6358 - precision-0.60: 0.6698 - precision-0.65: 0.7056 - precision-0.70: 0.7466 - precision-0.75: 0.7600 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2521 - recall-0.55: 0.1602 - recall-0.60: 0.0915 - recall-0.65: 0.0418 - recall-0.70: 0.0140 - recall-0.75: 0.0024 - recall-0.80: 1.2817e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 6: val_loss improved from 0.85791 to 0.81300, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.9720 - tp: 1967.0000 - fp: 1261.0000 - tn: 14343.0000 - fn: 5835.0000 - accuracy: 0.5161 - precision: 0.6094 - precision-0.55: 0.6358 - precision-0.60: 0.6698 - precision-0.65: 0.7056 - precision-0.70: 0.7466 - precision-0.75: 0.7600 - precision-0.80: 1.0000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2521 - recall-0.55: 0.1602 - recall-0.60: 0.0915 - recall-0.65: 0.0418 - recall-0.70: 0.0140 - recall-0.75: 0.0024 - recall-0.80: 1.2817e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.8130 - val_tp: 2125.0000 - val_fp: 544.0000 - val_tn: 7258.0000 - val_fn: 1776.0000 - val_accuracy: 0.6901 - val_precision: 0.7962 - val_precision-0.55: 0.8262 - val_precision-0.60: 0.8686 - val_precision-0.65: 0.8946 - val_precision-0.70: 0.9628 - val_precision-0.75: 0.9792 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5447 - val_recall-0.55: 0.4583 - val_recall-0.60: 0.3356 - val_recall-0.65: 0.1828 - val_recall-0.70: 0.0531 - val_recall-0.75: 0.0120 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9607 - tp: 2073.0000 - fp: 1312.0000 - tn: 13024.0000 - fn: 5095.0000 - accuracy: 0.5266 - precision: 0.6124 - precision-0.55: 0.6374 - precision-0.60: 0.6702 - precision-0.65: 0.6977 - precision-0.70: 0.7023 - precision-0.75: 0.7846 - precision-0.80: 0.8571 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2892 - recall-0.55: 0.1948 - recall-0.60: 0.1242 - recall-0.65: 0.0647 - recall-0.70: 0.0257 - recall-0.75: 0.0071 - recall-0.80: 8.3705e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 7: val_loss improved from 0.81300 to 0.80417, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9611 - tp: 2257.0000 - fp: 1423.0000 - tn: 14181.0000 - fn: 5545.0000 - accuracy: 0.5269 - precision: 0.6133 - precision-0.55: 0.6408 - precision-0.60: 0.6724 - precision-0.65: 0.6949 - precision-0.70: 0.7123 - precision-0.75: 0.7945 - precision-0.80: 0.8750 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2893 - recall-0.55: 0.1960 - recall-0.60: 0.1242 - recall-0.65: 0.0642 - recall-0.70: 0.0260 - recall-0.75: 0.0074 - recall-0.80: 8.9721e-04 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.8042 - val_tp: 2151.0000 - val_fp: 558.0000 - val_tn: 7244.0000 - val_fn: 1750.0000 - val_accuracy: 0.6888 - val_precision: 0.7940 - val_precision-0.55: 0.8293 - val_precision-0.60: 0.8677 - val_precision-0.65: 0.8997 - val_precision-0.70: 0.9375 - val_precision-0.75: 0.9882 - val_precision-0.80: 1.0000 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5514 - val_recall-0.55: 0.4758 - val_recall-0.60: 0.3632 - val_recall-0.65: 0.2276 - val_recall-0.70: 0.0807 - val_recall-0.75: 0.0215 - val_recall-0.80: 2.5634e-04 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9565 - tp: 2121.0000 - fp: 1388.0000 - tn: 12948.0000 - fn: 5047.0000 - accuracy: 0.5297 - precision: 0.6044 - precision-0.55: 0.6281 - precision-0.60: 0.6704 - precision-0.65: 0.7017 - precision-0.70: 0.7287 - precision-0.75: 0.7778 - precision-0.80: 0.7143 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2959 - recall-0.55: 0.2035 - recall-0.60: 0.1336 - recall-0.65: 0.0755 - recall-0.70: 0.0322 - recall-0.75: 0.0107 - recall-0.80: 0.0014 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00  \n",
      "Epoch 8: val_loss improved from 0.80417 to 0.78524, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.9572 - tp: 2312.0000 - fp: 1519.0000 - tn: 14085.0000 - fn: 5490.0000 - accuracy: 0.5290 - precision: 0.6035 - precision-0.55: 0.6275 - precision-0.60: 0.6720 - precision-0.65: 0.7067 - precision-0.70: 0.7291 - precision-0.75: 0.7826 - precision-0.80: 0.7778 - precision-0.85: 0.5000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2963 - recall-0.55: 0.2056 - recall-0.60: 0.1357 - recall-0.65: 0.0769 - recall-0.70: 0.0335 - recall-0.75: 0.0115 - recall-0.80: 0.0018 - recall-0.85: 1.2817e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7852 - val_tp: 2261.0000 - val_fp: 613.0000 - val_tn: 7189.0000 - val_fn: 1640.0000 - val_accuracy: 0.6911 - val_precision: 0.7867 - val_precision-0.55: 0.8156 - val_precision-0.60: 0.8435 - val_precision-0.65: 0.8890 - val_precision-0.70: 0.9157 - val_precision-0.75: 0.9756 - val_precision-0.80: 0.9796 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5796 - val_recall-0.55: 0.5160 - val_recall-0.60: 0.4296 - val_recall-0.65: 0.3181 - val_recall-0.70: 0.1700 - val_recall-0.75: 0.0513 - val_recall-0.80: 0.0123 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9487 - tp: 2313.0000 - fp: 1466.0000 - tn: 12870.0000 - fn: 4855.0000 - accuracy: 0.5294 - precision: 0.6121 - precision-0.55: 0.6488 - precision-0.60: 0.6789 - precision-0.65: 0.7081 - precision-0.70: 0.7785 - precision-0.75: 0.8167 - precision-0.80: 0.8511 - precision-0.85: 0.8750 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3227 - recall-0.55: 0.2354 - recall-0.60: 0.1596 - recall-0.65: 0.1002 - recall-0.70: 0.0515 - recall-0.75: 0.0205 - recall-0.80: 0.0056 - recall-0.85: 9.7656e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 9: val_loss improved from 0.78524 to 0.78013, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9508 - tp: 2517.0000 - fp: 1623.0000 - tn: 13981.0000 - fn: 5285.0000 - accuracy: 0.5272 - precision: 0.6080 - precision-0.55: 0.6403 - precision-0.60: 0.6714 - precision-0.65: 0.7000 - precision-0.70: 0.7707 - precision-0.75: 0.8000 - precision-0.80: 0.8571 - precision-0.85: 0.8889 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3226 - recall-0.55: 0.2337 - recall-0.60: 0.1584 - recall-0.65: 0.0996 - recall-0.70: 0.0513 - recall-0.75: 0.0205 - recall-0.80: 0.0062 - recall-0.85: 0.0010 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7801 - val_tp: 2260.0000 - val_fp: 616.0000 - val_tn: 7186.0000 - val_fn: 1641.0000 - val_accuracy: 0.6932 - val_precision: 0.7858 - val_precision-0.55: 0.8130 - val_precision-0.60: 0.8422 - val_precision-0.65: 0.8877 - val_precision-0.70: 0.9151 - val_precision-0.75: 0.9524 - val_precision-0.80: 0.9859 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5793 - val_recall-0.55: 0.5217 - val_recall-0.60: 0.4419 - val_recall-0.65: 0.3404 - val_recall-0.70: 0.2046 - val_recall-0.75: 0.0718 - val_recall-0.80: 0.0179 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9454 - tp: 2228.0000 - fp: 1468.0000 - tn: 12868.0000 - fn: 4940.0000 - accuracy: 0.5275 - precision: 0.6028 - precision-0.55: 0.6427 - precision-0.60: 0.6671 - precision-0.65: 0.6987 - precision-0.70: 0.7598 - precision-0.75: 0.7811 - precision-0.80: 0.8158 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3108 - recall-0.55: 0.2321 - recall-0.60: 0.1546 - recall-0.65: 0.0932 - recall-0.70: 0.0512 - recall-0.75: 0.0184 - recall-0.80: 0.0043 - recall-0.85: 8.3705e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 10: val_loss improved from 0.78013 to 0.76652, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9454 - tp: 2451.0000 - fp: 1606.0000 - tn: 13998.0000 - fn: 5351.0000 - accuracy: 0.5279 - precision: 0.6041 - precision-0.55: 0.6424 - precision-0.60: 0.6665 - precision-0.65: 0.6976 - precision-0.70: 0.7564 - precision-0.75: 0.7604 - precision-0.80: 0.7708 - precision-0.85: 0.8571 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3142 - recall-0.55: 0.2328 - recall-0.60: 0.1552 - recall-0.65: 0.0943 - recall-0.70: 0.0529 - recall-0.75: 0.0187 - recall-0.80: 0.0047 - recall-0.85: 7.6903e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7665 - val_tp: 2337.0000 - val_fp: 664.0000 - val_tn: 7138.0000 - val_fn: 1564.0000 - val_accuracy: 0.6955 - val_precision: 0.7787 - val_precision-0.55: 0.8036 - val_precision-0.60: 0.8366 - val_precision-0.65: 0.8705 - val_precision-0.70: 0.9052 - val_precision-0.75: 0.9300 - val_precision-0.80: 0.9677 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5991 - val_recall-0.55: 0.5435 - val_recall-0.60: 0.4817 - val_recall-0.65: 0.3927 - val_recall-0.70: 0.2669 - val_recall-0.75: 0.1225 - val_recall-0.80: 0.0308 - val_recall-0.85: 0.0015 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9377 - tp: 2408.0000 - fp: 1490.0000 - tn: 12846.0000 - fn: 4760.0000 - accuracy: 0.5396 - precision: 0.6178 - precision-0.55: 0.6457 - precision-0.60: 0.6738 - precision-0.65: 0.7088 - precision-0.70: 0.7430 - precision-0.75: 0.8084 - precision-0.80: 0.8667 - precision-0.85: 0.8889 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3359 - recall-0.55: 0.2454 - recall-0.60: 0.1709 - recall-0.65: 0.1117 - recall-0.70: 0.0633 - recall-0.75: 0.0294 - recall-0.80: 0.0091 - recall-0.85: 0.0011 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00 \n",
      "Epoch 11: val_loss improved from 0.76652 to 0.75922, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9376 - tp: 2634.0000 - fp: 1612.0000 - tn: 13992.0000 - fn: 5168.0000 - accuracy: 0.5411 - precision: 0.6203 - precision-0.55: 0.6495 - precision-0.60: 0.6782 - precision-0.65: 0.7082 - precision-0.70: 0.7406 - precision-0.75: 0.8070 - precision-0.80: 0.8718 - precision-0.85: 0.8889 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3376 - recall-0.55: 0.2472 - recall-0.60: 0.1726 - recall-0.65: 0.1123 - recall-0.70: 0.0633 - recall-0.75: 0.0295 - recall-0.80: 0.0087 - recall-0.85: 0.0010 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7592 - val_tp: 2378.0000 - val_fp: 699.0000 - val_tn: 7103.0000 - val_fn: 1523.0000 - val_accuracy: 0.6967 - val_precision: 0.7728 - val_precision-0.55: 0.7977 - val_precision-0.60: 0.8240 - val_precision-0.65: 0.8542 - val_precision-0.70: 0.8990 - val_precision-0.75: 0.9265 - val_precision-0.80: 0.9760 - val_precision-0.85: 0.9667 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6096 - val_recall-0.55: 0.5591 - val_recall-0.60: 0.4994 - val_recall-0.65: 0.4250 - val_recall-0.70: 0.3148 - val_recall-0.75: 0.1712 - val_recall-0.80: 0.0520 - val_recall-0.85: 0.0074 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 12/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9377 - tp: 2472.0000 - fp: 1590.0000 - tn: 12746.0000 - fn: 4696.0000 - accuracy: 0.5392 - precision: 0.6086 - precision-0.55: 0.6452 - precision-0.60: 0.6769 - precision-0.65: 0.7060 - precision-0.70: 0.7469 - precision-0.75: 0.7968 - precision-0.80: 0.8614 - precision-0.85: 0.9375 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3449 - recall-0.55: 0.2600 - recall-0.60: 0.1885 - recall-0.65: 0.1236 - recall-0.70: 0.0749 - recall-0.75: 0.0350 - recall-0.80: 0.0121 - recall-0.85: 0.0021 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00     \n",
      "Epoch 12: val_loss improved from 0.75922 to 0.75806, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9376 - tp: 2690.0000 - fp: 1720.0000 - tn: 13884.0000 - fn: 5112.0000 - accuracy: 0.5391 - precision: 0.6100 - precision-0.55: 0.6459 - precision-0.60: 0.6789 - precision-0.65: 0.7085 - precision-0.70: 0.7484 - precision-0.75: 0.7925 - precision-0.80: 0.8673 - precision-0.85: 0.9375 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3448 - recall-0.55: 0.2593 - recall-0.60: 0.1878 - recall-0.65: 0.1237 - recall-0.70: 0.0755 - recall-0.75: 0.0352 - recall-0.80: 0.0126 - recall-0.85: 0.0019 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7581 - val_tp: 2372.0000 - val_fp: 691.0000 - val_tn: 7111.0000 - val_fn: 1529.0000 - val_accuracy: 0.6978 - val_precision: 0.7744 - val_precision-0.55: 0.7982 - val_precision-0.60: 0.8282 - val_precision-0.65: 0.8581 - val_precision-0.70: 0.9029 - val_precision-0.75: 0.9289 - val_precision-0.80: 0.9686 - val_precision-0.85: 0.9697 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6080 - val_recall-0.55: 0.5568 - val_recall-0.60: 0.4994 - val_recall-0.65: 0.4217 - val_recall-0.70: 0.3145 - val_recall-0.75: 0.1741 - val_recall-0.80: 0.0554 - val_recall-0.85: 0.0082 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 13/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9341 - tp: 2457.0000 - fp: 1564.0000 - tn: 12772.0000 - fn: 4711.0000 - accuracy: 0.5398 - precision: 0.6110 - precision-0.55: 0.6478 - precision-0.60: 0.6805 - precision-0.65: 0.7048 - precision-0.70: 0.7324 - precision-0.75: 0.7963 - precision-0.80: 0.8587 - precision-0.85: 0.9130 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3428 - recall-0.55: 0.2566 - recall-0.60: 0.1869 - recall-0.65: 0.1263 - recall-0.70: 0.0741 - recall-0.75: 0.0360 - recall-0.80: 0.0110 - recall-0.85: 0.0029 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 13: val_loss improved from 0.75806 to 0.75642, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9338 - tp: 2683.0000 - fp: 1686.0000 - tn: 13918.0000 - fn: 5119.0000 - accuracy: 0.5405 - precision: 0.6141 - precision-0.55: 0.6517 - precision-0.60: 0.6876 - precision-0.65: 0.7107 - precision-0.70: 0.7382 - precision-0.75: 0.7930 - precision-0.80: 0.8351 - precision-0.85: 0.9130 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3439 - recall-0.55: 0.2574 - recall-0.60: 0.1891 - recall-0.65: 0.1275 - recall-0.70: 0.0741 - recall-0.75: 0.0349 - recall-0.80: 0.0104 - recall-0.85: 0.0027 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7564 - val_tp: 2368.0000 - val_fp: 677.0000 - val_tn: 7125.0000 - val_fn: 1533.0000 - val_accuracy: 0.6967 - val_precision: 0.7777 - val_precision-0.55: 0.8018 - val_precision-0.60: 0.8322 - val_precision-0.65: 0.8615 - val_precision-0.70: 0.9053 - val_precision-0.75: 0.9284 - val_precision-0.80: 0.9735 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6070 - val_recall-0.55: 0.5568 - val_recall-0.60: 0.4983 - val_recall-0.65: 0.4243 - val_recall-0.70: 0.3138 - val_recall-0.75: 0.1728 - val_recall-0.80: 0.0564 - val_recall-0.85: 0.0077 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 14/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9305 - tp: 2513.0000 - fp: 1539.0000 - tn: 12797.0000 - fn: 4655.0000 - accuracy: 0.5462 - precision: 0.6202 - precision-0.55: 0.6539 - precision-0.60: 0.6833 - precision-0.65: 0.7070 - precision-0.70: 0.7315 - precision-0.75: 0.7888 - precision-0.80: 0.9020 - precision-0.85: 0.6667 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3506 - recall-0.55: 0.2638 - recall-0.60: 0.1875 - recall-0.65: 0.1232 - recall-0.70: 0.0730 - recall-0.75: 0.0354 - recall-0.80: 0.0128 - recall-0.85: 5.5804e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 14: val_loss improved from 0.75642 to 0.75280, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.9298 - tp: 2737.0000 - fp: 1670.0000 - tn: 13934.0000 - fn: 5065.0000 - accuracy: 0.5496 - precision: 0.6211 - precision-0.55: 0.6540 - precision-0.60: 0.6854 - precision-0.65: 0.7087 - precision-0.70: 0.7334 - precision-0.75: 0.7901 - precision-0.80: 0.9043 - precision-0.85: 0.7500 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3508 - recall-0.55: 0.2643 - recall-0.60: 0.1879 - recall-0.65: 0.1232 - recall-0.70: 0.0737 - recall-0.75: 0.0367 - recall-0.80: 0.0133 - recall-0.85: 7.6903e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7528 - val_tp: 2395.0000 - val_fp: 717.0000 - val_tn: 7085.0000 - val_fn: 1506.0000 - val_accuracy: 0.6993 - val_precision: 0.7696 - val_precision-0.55: 0.7934 - val_precision-0.60: 0.8216 - val_precision-0.65: 0.8540 - val_precision-0.70: 0.8991 - val_precision-0.75: 0.9287 - val_precision-0.80: 0.9666 - val_precision-0.85: 0.9821 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6139 - val_recall-0.55: 0.5650 - val_recall-0.60: 0.5135 - val_recall-0.65: 0.4422 - val_recall-0.70: 0.3402 - val_recall-0.75: 0.2002 - val_recall-0.80: 0.0741 - val_recall-0.85: 0.0141 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 15/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9266 - tp: 2548.0000 - fp: 1555.0000 - tn: 12781.0000 - fn: 4620.0000 - accuracy: 0.5458 - precision: 0.6210 - precision-0.55: 0.6526 - precision-0.60: 0.6914 - precision-0.65: 0.7179 - precision-0.70: 0.7470 - precision-0.75: 0.8022 - precision-0.80: 0.8667 - precision-0.85: 0.9524 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3555 - recall-0.55: 0.2679 - recall-0.60: 0.1913 - recall-0.65: 0.1296 - recall-0.70: 0.0783 - recall-0.75: 0.0402 - recall-0.80: 0.0145 - recall-0.85: 0.0028 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 15: val_loss improved from 0.75280 to 0.74753, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.9249 - tp: 2783.0000 - fp: 1677.0000 - tn: 13927.0000 - fn: 5019.0000 - accuracy: 0.5472 - precision: 0.6240 - precision-0.55: 0.6548 - precision-0.60: 0.6929 - precision-0.65: 0.7188 - precision-0.70: 0.7461 - precision-0.75: 0.7995 - precision-0.80: 0.8550 - precision-0.85: 0.9583 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3567 - recall-0.55: 0.2686 - recall-0.60: 0.1920 - recall-0.65: 0.1307 - recall-0.70: 0.0791 - recall-0.75: 0.0409 - recall-0.80: 0.0144 - recall-0.85: 0.0029 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7475 - val_tp: 2413.0000 - val_fp: 719.0000 - val_tn: 7083.0000 - val_fn: 1488.0000 - val_accuracy: 0.7001 - val_precision: 0.7704 - val_precision-0.55: 0.7947 - val_precision-0.60: 0.8165 - val_precision-0.65: 0.8505 - val_precision-0.70: 0.8898 - val_precision-0.75: 0.9263 - val_precision-0.80: 0.9636 - val_precision-0.85: 0.9718 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6186 - val_recall-0.55: 0.5727 - val_recall-0.60: 0.5191 - val_recall-0.65: 0.4594 - val_recall-0.70: 0.3707 - val_recall-0.75: 0.2320 - val_recall-0.80: 0.0951 - val_recall-0.85: 0.0177 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 16/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9264 - tp: 2571.0000 - fp: 1591.0000 - tn: 12745.0000 - fn: 4597.0000 - accuracy: 0.5512 - precision: 0.6177 - precision-0.55: 0.6510 - precision-0.60: 0.6851 - precision-0.65: 0.7167 - precision-0.70: 0.7600 - precision-0.75: 0.8170 - precision-0.80: 0.8380 - precision-0.85: 1.0000 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3587 - recall-0.55: 0.2766 - recall-0.60: 0.2052 - recall-0.65: 0.1398 - recall-0.70: 0.0897 - recall-0.75: 0.0511 - recall-0.80: 0.0209 - recall-0.85: 0.0053 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 16: val_loss did not improve from 0.74753\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.9260 - tp: 2792.0000 - fp: 1717.0000 - tn: 13887.0000 - fn: 5010.0000 - accuracy: 0.5534 - precision: 0.6192 - precision-0.55: 0.6504 - precision-0.60: 0.6859 - precision-0.65: 0.7141 - precision-0.70: 0.7568 - precision-0.75: 0.8128 - precision-0.80: 0.8359 - precision-0.85: 0.9545 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3579 - recall-0.55: 0.2754 - recall-0.60: 0.2043 - recall-0.65: 0.1389 - recall-0.70: 0.0886 - recall-0.75: 0.0506 - recall-0.80: 0.0209 - recall-0.85: 0.0054 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7512 - val_tp: 2387.0000 - val_fp: 709.0000 - val_tn: 7093.0000 - val_fn: 1514.0000 - val_accuracy: 0.6970 - val_precision: 0.7710 - val_precision-0.55: 0.7958 - val_precision-0.60: 0.8224 - val_precision-0.65: 0.8559 - val_precision-0.70: 0.8965 - val_precision-0.75: 0.9258 - val_precision-0.80: 0.9634 - val_precision-0.85: 0.9833 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6119 - val_recall-0.55: 0.5655 - val_recall-0.60: 0.5140 - val_recall-0.65: 0.4430 - val_recall-0.70: 0.3440 - val_recall-0.75: 0.2079 - val_recall-0.80: 0.0810 - val_recall-0.85: 0.0151 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 17/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9226 - tp: 2578.0000 - fp: 1504.0000 - tn: 12832.0000 - fn: 4590.0000 - accuracy: 0.5442 - precision: 0.6316 - precision-0.55: 0.6616 - precision-0.60: 0.6886 - precision-0.65: 0.7226 - precision-0.70: 0.7751 - precision-0.75: 0.8076 - precision-0.80: 0.8889 - precision-0.85: 0.8667 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3597 - recall-0.55: 0.2725 - recall-0.60: 0.1959 - recall-0.65: 0.1334 - recall-0.70: 0.0808 - recall-0.75: 0.0416 - recall-0.80: 0.0145 - recall-0.85: 0.0018 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 17: val_loss improved from 0.74753 to 0.74151, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9222 - tp: 2806.0000 - fp: 1641.0000 - tn: 13963.0000 - fn: 4996.0000 - accuracy: 0.5465 - precision: 0.6310 - precision-0.55: 0.6622 - precision-0.60: 0.6912 - precision-0.65: 0.7249 - precision-0.70: 0.7793 - precision-0.75: 0.8161 - precision-0.80: 0.8960 - precision-0.85: 0.8947 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3597 - recall-0.55: 0.2736 - recall-0.60: 0.1974 - recall-0.65: 0.1351 - recall-0.70: 0.0819 - recall-0.75: 0.0415 - recall-0.80: 0.0144 - recall-0.85: 0.0022 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7415 - val_tp: 2437.0000 - val_fp: 734.0000 - val_tn: 7068.0000 - val_fn: 1464.0000 - val_accuracy: 0.7024 - val_precision: 0.7685 - val_precision-0.55: 0.7910 - val_precision-0.60: 0.8142 - val_precision-0.65: 0.8465 - val_precision-0.70: 0.8803 - val_precision-0.75: 0.9250 - val_precision-0.80: 0.9536 - val_precision-0.85: 0.9783 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6247 - val_recall-0.55: 0.5822 - val_recall-0.60: 0.5335 - val_recall-0.65: 0.4737 - val_recall-0.70: 0.3978 - val_recall-0.75: 0.2720 - val_recall-0.80: 0.1264 - val_recall-0.85: 0.0231 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 18/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9215 - tp: 2623.0000 - fp: 1643.0000 - tn: 12693.0000 - fn: 4545.0000 - accuracy: 0.5474 - precision: 0.6149 - precision-0.55: 0.6545 - precision-0.60: 0.6905 - precision-0.65: 0.7065 - precision-0.70: 0.7472 - precision-0.75: 0.8155 - precision-0.80: 0.8325 - precision-0.85: 0.8696 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3659 - recall-0.55: 0.2867 - recall-0.60: 0.2194 - recall-0.65: 0.1528 - recall-0.70: 0.1027 - recall-0.75: 0.0617 - recall-0.80: 0.0243 - recall-0.85: 0.0056 - recall-0.90: 4.1853e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 18: val_loss did not improve from 0.74151\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.9237 - tp: 2837.0000 - fp: 1770.0000 - tn: 13834.0000 - fn: 4965.0000 - accuracy: 0.5470 - precision: 0.6158 - precision-0.55: 0.6537 - precision-0.60: 0.6895 - precision-0.65: 0.7079 - precision-0.70: 0.7476 - precision-0.75: 0.8183 - precision-0.80: 0.8386 - precision-0.85: 0.8696 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3636 - recall-0.55: 0.2848 - recall-0.60: 0.2171 - recall-0.65: 0.1512 - recall-0.70: 0.1002 - recall-0.75: 0.0595 - recall-0.80: 0.0240 - recall-0.85: 0.0051 - recall-0.90: 3.8452e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7484 - val_tp: 2383.0000 - val_fp: 699.0000 - val_tn: 7103.0000 - val_fn: 1518.0000 - val_accuracy: 0.6973 - val_precision: 0.7732 - val_precision-0.55: 0.8005 - val_precision-0.60: 0.8254 - val_precision-0.65: 0.8580 - val_precision-0.70: 0.9005 - val_precision-0.75: 0.9286 - val_precision-0.80: 0.9660 - val_precision-0.85: 0.9821 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6109 - val_recall-0.55: 0.5688 - val_recall-0.60: 0.5150 - val_recall-0.65: 0.4445 - val_recall-0.70: 0.3479 - val_recall-0.75: 0.2166 - val_recall-0.80: 0.0874 - val_recall-0.85: 0.0141 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 19/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9210 - tp: 2582.0000 - fp: 1535.0000 - tn: 12801.0000 - fn: 4586.0000 - accuracy: 0.5451 - precision: 0.6272 - precision-0.55: 0.6572 - precision-0.60: 0.6965 - precision-0.65: 0.7289 - precision-0.70: 0.7683 - precision-0.75: 0.8196 - precision-0.80: 0.8357 - precision-0.85: 0.8500 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3602 - recall-0.55: 0.2771 - recall-0.60: 0.2052 - recall-0.65: 0.1406 - recall-0.70: 0.0833 - recall-0.75: 0.0431 - recall-0.80: 0.0163 - recall-0.85: 0.0024 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00   \n",
      "Epoch 19: val_loss did not improve from 0.74151\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.9205 - tp: 2818.0000 - fp: 1677.0000 - tn: 13927.0000 - fn: 4984.0000 - accuracy: 0.5465 - precision: 0.6269 - precision-0.55: 0.6580 - precision-0.60: 0.6948 - precision-0.65: 0.7258 - precision-0.70: 0.7665 - precision-0.75: 0.8095 - precision-0.80: 0.8280 - precision-0.85: 0.8636 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3612 - recall-0.55: 0.2786 - recall-0.60: 0.2055 - recall-0.65: 0.1411 - recall-0.70: 0.0850 - recall-0.75: 0.0436 - recall-0.80: 0.0167 - recall-0.85: 0.0024 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7425 - val_tp: 2439.0000 - val_fp: 747.0000 - val_tn: 7055.0000 - val_fn: 1462.0000 - val_accuracy: 0.6988 - val_precision: 0.7655 - val_precision-0.55: 0.7918 - val_precision-0.60: 0.8133 - val_precision-0.65: 0.8441 - val_precision-0.70: 0.8780 - val_precision-0.75: 0.9253 - val_precision-0.80: 0.9468 - val_precision-0.85: 0.9787 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6252 - val_recall-0.55: 0.5857 - val_recall-0.60: 0.5347 - val_recall-0.65: 0.4719 - val_recall-0.70: 0.3948 - val_recall-0.75: 0.2669 - val_recall-0.80: 0.1277 - val_recall-0.85: 0.0236 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 20/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9145 - tp: 2612.0000 - fp: 1569.0000 - tn: 12767.0000 - fn: 4556.0000 - accuracy: 0.5453 - precision: 0.6247 - precision-0.55: 0.6591 - precision-0.60: 0.6941 - precision-0.65: 0.7332 - precision-0.70: 0.7737 - precision-0.75: 0.8419 - precision-0.80: 0.9130 - precision-0.85: 0.9655 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3644 - recall-0.55: 0.2783 - recall-0.60: 0.2061 - recall-0.65: 0.1503 - recall-0.70: 0.1002 - recall-0.75: 0.0572 - recall-0.80: 0.0234 - recall-0.85: 0.0039 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00   \n",
      "Epoch 20: val_loss did not improve from 0.74151\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.9171 - tp: 2826.0000 - fp: 1705.0000 - tn: 13899.0000 - fn: 4976.0000 - accuracy: 0.5446 - precision: 0.6237 - precision-0.55: 0.6567 - precision-0.60: 0.6910 - precision-0.65: 0.7290 - precision-0.70: 0.7681 - precision-0.75: 0.8372 - precision-0.80: 0.9154 - precision-0.85: 0.9697 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3622 - recall-0.55: 0.2758 - recall-0.60: 0.2024 - recall-0.65: 0.1469 - recall-0.70: 0.0981 - recall-0.75: 0.0560 - recall-0.80: 0.0236 - recall-0.85: 0.0041 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7434 - val_tp: 2420.0000 - val_fp: 725.0000 - val_tn: 7077.0000 - val_fn: 1481.0000 - val_accuracy: 0.6978 - val_precision: 0.7695 - val_precision-0.55: 0.7947 - val_precision-0.60: 0.8175 - val_precision-0.65: 0.8512 - val_precision-0.70: 0.8856 - val_precision-0.75: 0.9274 - val_precision-0.80: 0.9518 - val_precision-0.85: 0.9753 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6204 - val_recall-0.55: 0.5806 - val_recall-0.60: 0.5294 - val_recall-0.65: 0.4632 - val_recall-0.70: 0.3809 - val_recall-0.75: 0.2520 - val_recall-0.80: 0.1164 - val_recall-0.85: 0.0203 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.9164 - tp: 2863.0000 - fp: 1651.0000 - tn: 13953.0000 - fn: 4939.0000 - accuracy: 0.5556 - precision: 0.6342 - precision-0.55: 0.6632 - precision-0.60: 0.6964 - precision-0.65: 0.7349 - precision-0.70: 0.7613 - precision-0.75: 0.8250 - precision-0.80: 0.8902 - precision-0.85: 0.9630 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3670 - recall-0.55: 0.2802 - recall-0.60: 0.2055 - recall-0.65: 0.1432 - recall-0.70: 0.0887 - recall-0.75: 0.0465 - recall-0.80: 0.0187 - recall-0.85: 0.0033 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00    \n",
      "Epoch 21: val_loss improved from 0.74151 to 0.73596, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154506.h5\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9164 - tp: 2863.0000 - fp: 1651.0000 - tn: 13953.0000 - fn: 4939.0000 - accuracy: 0.5556 - precision: 0.6342 - precision-0.55: 0.6632 - precision-0.60: 0.6964 - precision-0.65: 0.7349 - precision-0.70: 0.7613 - precision-0.75: 0.8250 - precision-0.80: 0.8902 - precision-0.85: 0.9630 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3670 - recall-0.55: 0.2802 - recall-0.60: 0.2055 - recall-0.65: 0.1432 - recall-0.70: 0.0887 - recall-0.75: 0.0465 - recall-0.80: 0.0187 - recall-0.85: 0.0033 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7360 - val_tp: 2481.0000 - val_fp: 785.0000 - val_tn: 7017.0000 - val_fn: 1420.0000 - val_accuracy: 0.7021 - val_precision: 0.7596 - val_precision-0.55: 0.7866 - val_precision-0.60: 0.8110 - val_precision-0.65: 0.8362 - val_precision-0.70: 0.8735 - val_precision-0.75: 0.9192 - val_precision-0.80: 0.9514 - val_precision-0.85: 0.9766 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6360 - val_recall-0.55: 0.5973 - val_recall-0.60: 0.5522 - val_recall-0.65: 0.4932 - val_recall-0.70: 0.4214 - val_recall-0.75: 0.3004 - val_recall-0.80: 0.1556 - val_recall-0.85: 0.0320 - val_recall-0.90: 5.1269e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 22/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9125 - tp: 2684.0000 - fp: 1599.0000 - tn: 12737.0000 - fn: 4484.0000 - accuracy: 0.5516 - precision: 0.6267 - precision-0.55: 0.6667 - precision-0.60: 0.6927 - precision-0.65: 0.7292 - precision-0.70: 0.7639 - precision-0.75: 0.8127 - precision-0.80: 0.8841 - precision-0.85: 0.9038 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3744 - recall-0.55: 0.2985 - recall-0.60: 0.2229 - recall-0.65: 0.1604 - recall-0.70: 0.1070 - recall-0.75: 0.0642 - recall-0.80: 0.0255 - recall-0.85: 0.0066 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 22: val_loss did not improve from 0.73596\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.9124 - tp: 2909.0000 - fp: 1726.0000 - tn: 13878.0000 - fn: 4893.0000 - accuracy: 0.5511 - precision: 0.6276 - precision-0.55: 0.6666 - precision-0.60: 0.6938 - precision-0.65: 0.7280 - precision-0.70: 0.7632 - precision-0.75: 0.8159 - precision-0.80: 0.8834 - precision-0.85: 0.9138 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3729 - recall-0.55: 0.2970 - recall-0.60: 0.2219 - recall-0.65: 0.1588 - recall-0.70: 0.1054 - recall-0.75: 0.0631 - recall-0.80: 0.0252 - recall-0.85: 0.0068 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7443 - val_tp: 2408.0000 - val_fp: 719.0000 - val_tn: 7083.0000 - val_fn: 1493.0000 - val_accuracy: 0.6975 - val_precision: 0.7701 - val_precision-0.55: 0.7971 - val_precision-0.60: 0.8197 - val_precision-0.65: 0.8510 - val_precision-0.70: 0.8902 - val_precision-0.75: 0.9254 - val_precision-0.80: 0.9547 - val_precision-0.85: 0.9756 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6173 - val_recall-0.55: 0.5760 - val_recall-0.60: 0.5255 - val_recall-0.65: 0.4599 - val_recall-0.70: 0.3743 - val_recall-0.75: 0.2448 - val_recall-0.80: 0.1136 - val_recall-0.85: 0.0205 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 23/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9127 - tp: 2642.0000 - fp: 1506.0000 - tn: 12830.0000 - fn: 4526.0000 - accuracy: 0.5612 - precision: 0.6369 - precision-0.55: 0.6732 - precision-0.60: 0.7052 - precision-0.65: 0.7286 - precision-0.70: 0.7562 - precision-0.75: 0.8042 - precision-0.80: 0.8817 - precision-0.85: 1.0000 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3686 - recall-0.55: 0.2847 - recall-0.60: 0.2119 - recall-0.65: 0.1472 - recall-0.70: 0.0939 - recall-0.75: 0.0533 - recall-0.80: 0.0229 - recall-0.85: 0.0060 - recall-0.90: 5.5804e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 23: val_loss did not improve from 0.73596\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.9109 - tp: 2892.0000 - fp: 1643.0000 - tn: 13961.0000 - fn: 4910.0000 - accuracy: 0.5629 - precision: 0.6377 - precision-0.55: 0.6736 - precision-0.60: 0.7092 - precision-0.65: 0.7341 - precision-0.70: 0.7667 - precision-0.75: 0.8154 - precision-0.80: 0.8798 - precision-0.85: 1.0000 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3707 - recall-0.55: 0.2862 - recall-0.60: 0.2151 - recall-0.65: 0.1497 - recall-0.70: 0.0969 - recall-0.75: 0.0555 - recall-0.80: 0.0235 - recall-0.85: 0.0060 - recall-0.90: 5.1269e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7394 - val_tp: 2444.0000 - val_fp: 746.0000 - val_tn: 7056.0000 - val_fn: 1457.0000 - val_accuracy: 0.6985 - val_precision: 0.7661 - val_precision-0.55: 0.7904 - val_precision-0.60: 0.8147 - val_precision-0.65: 0.8430 - val_precision-0.70: 0.8817 - val_precision-0.75: 0.9213 - val_precision-0.80: 0.9481 - val_precision-0.85: 0.9811 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6265 - val_recall-0.55: 0.5868 - val_recall-0.60: 0.5386 - val_recall-0.65: 0.4763 - val_recall-0.70: 0.3994 - val_recall-0.75: 0.2730 - val_recall-0.80: 0.1359 - val_recall-0.85: 0.0267 - val_recall-0.90: 5.1269e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 24/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9100 - tp: 2653.0000 - fp: 1509.0000 - tn: 12827.0000 - fn: 4515.0000 - accuracy: 0.5583 - precision: 0.6374 - precision-0.55: 0.6681 - precision-0.60: 0.7050 - precision-0.65: 0.7353 - precision-0.70: 0.7653 - precision-0.75: 0.8189 - precision-0.80: 0.8802 - precision-0.85: 0.8529 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3701 - recall-0.55: 0.2822 - recall-0.60: 0.2080 - recall-0.65: 0.1434 - recall-0.70: 0.0960 - recall-0.75: 0.0543 - recall-0.80: 0.0205 - recall-0.85: 0.0040 - recall-0.90: 2.7902e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 24: val_loss did not improve from 0.73596\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9099 - tp: 2882.0000 - fp: 1655.0000 - tn: 13949.0000 - fn: 4920.0000 - accuracy: 0.5583 - precision: 0.6352 - precision-0.55: 0.6670 - precision-0.60: 0.7056 - precision-0.65: 0.7363 - precision-0.70: 0.7652 - precision-0.75: 0.8175 - precision-0.80: 0.8723 - precision-0.85: 0.8718 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3694 - recall-0.55: 0.2824 - recall-0.60: 0.2101 - recall-0.65: 0.1446 - recall-0.70: 0.0965 - recall-0.75: 0.0551 - recall-0.80: 0.0210 - recall-0.85: 0.0044 - recall-0.90: 3.8452e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7399 - val_tp: 2440.0000 - val_fp: 743.0000 - val_tn: 7059.0000 - val_fn: 1461.0000 - val_accuracy: 0.6978 - val_precision: 0.7666 - val_precision-0.55: 0.7897 - val_precision-0.60: 0.8137 - val_precision-0.65: 0.8435 - val_precision-0.70: 0.8768 - val_precision-0.75: 0.9183 - val_precision-0.80: 0.9492 - val_precision-0.85: 0.9735 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6255 - val_recall-0.55: 0.5873 - val_recall-0.60: 0.5406 - val_recall-0.65: 0.4781 - val_recall-0.70: 0.4014 - val_recall-0.75: 0.2766 - val_recall-0.80: 0.1436 - val_recall-0.85: 0.0282 - val_recall-0.90: 5.1269e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 25/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9045 - tp: 2712.0000 - fp: 1508.0000 - tn: 12828.0000 - fn: 4456.0000 - accuracy: 0.5635 - precision: 0.6427 - precision-0.55: 0.6749 - precision-0.60: 0.7070 - precision-0.65: 0.7381 - precision-0.70: 0.7667 - precision-0.75: 0.8170 - precision-0.80: 0.8502 - precision-0.85: 0.9111 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3783 - recall-0.55: 0.2893 - recall-0.60: 0.2215 - recall-0.65: 0.1542 - recall-0.70: 0.1027 - recall-0.75: 0.0592 - recall-0.80: 0.0246 - recall-0.85: 0.0057 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 25: val_loss did not improve from 0.73596\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.9061 - tp: 2936.0000 - fp: 1650.0000 - tn: 13954.0000 - fn: 4866.0000 - accuracy: 0.5631 - precision: 0.6402 - precision-0.55: 0.6722 - precision-0.60: 0.7054 - precision-0.65: 0.7380 - precision-0.70: 0.7666 - precision-0.75: 0.8195 - precision-0.80: 0.8571 - precision-0.85: 0.9111 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3763 - recall-0.55: 0.2881 - recall-0.60: 0.2194 - recall-0.65: 0.1534 - recall-0.70: 0.1019 - recall-0.75: 0.0582 - recall-0.80: 0.0246 - recall-0.85: 0.0053 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7367 - val_tp: 2462.0000 - val_fp: 771.0000 - val_tn: 7031.0000 - val_fn: 1439.0000 - val_accuracy: 0.7003 - val_precision: 0.7615 - val_precision-0.55: 0.7871 - val_precision-0.60: 0.8118 - val_precision-0.65: 0.8331 - val_precision-0.70: 0.8713 - val_precision-0.75: 0.9159 - val_precision-0.80: 0.9487 - val_precision-0.85: 0.9745 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6311 - val_recall-0.55: 0.5932 - val_recall-0.60: 0.5486 - val_recall-0.65: 0.4914 - val_recall-0.70: 0.4201 - val_recall-0.75: 0.3015 - val_recall-0.80: 0.1659 - val_recall-0.85: 0.0392 - val_recall-0.90: 7.6903e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 26/200\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.9072 - tp: 2711.0000 - fp: 1536.0000 - tn: 12800.0000 - fn: 4457.0000 - accuracy: 0.5621 - precision: 0.6383 - precision-0.55: 0.6769 - precision-0.60: 0.7005 - precision-0.65: 0.7295 - precision-0.70: 0.7546 - precision-0.75: 0.8162 - precision-0.80: 0.8675 - precision-0.85: 0.9412 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3782 - recall-0.55: 0.2958 - recall-0.60: 0.2215 - recall-0.65: 0.1565 - recall-0.70: 0.1034 - recall-0.75: 0.0589 - recall-0.80: 0.0283 - recall-0.85: 0.0067 - recall-0.90: 1.3951e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 26: val_loss did not improve from 0.73596\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.9060 - tp: 2944.0000 - fp: 1675.0000 - tn: 13929.0000 - fn: 4858.0000 - accuracy: 0.5637 - precision: 0.6374 - precision-0.55: 0.6764 - precision-0.60: 0.7006 - precision-0.65: 0.7279 - precision-0.70: 0.7555 - precision-0.75: 0.8145 - precision-0.80: 0.8735 - precision-0.85: 0.9423 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.3773 - recall-0.55: 0.2949 - recall-0.60: 0.2198 - recall-0.65: 0.1539 - recall-0.70: 0.1010 - recall-0.75: 0.0574 - recall-0.80: 0.0274 - recall-0.85: 0.0063 - recall-0.90: 1.2817e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7413 - val_tp: 2428.0000 - val_fp: 732.0000 - val_tn: 7070.0000 - val_fn: 1473.0000 - val_accuracy: 0.6965 - val_precision: 0.7684 - val_precision-0.55: 0.7923 - val_precision-0.60: 0.8149 - val_precision-0.65: 0.8454 - val_precision-0.70: 0.8816 - val_precision-0.75: 0.9175 - val_precision-0.80: 0.9480 - val_precision-0.85: 0.9817 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6224 - val_recall-0.55: 0.5840 - val_recall-0.60: 0.5373 - val_recall-0.65: 0.4712 - val_recall-0.70: 0.3912 - val_recall-0.75: 0.2651 - val_recall-0.80: 0.1356 - val_recall-0.85: 0.0274 - val_recall-0.90: 5.1269e-04 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [350 570 575 352 573 355 358 568 354 359]\n",
      "Epoch 26: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6364 - tp: 2947.0000 - fp: 713.0000 - tn: 7089.0000 - fn: 954.0000 - accuracy: 0.7731 - precision: 0.8052 - precision-0.55: 0.8186 - precision-0.60: 0.8251 - precision-0.65: 0.8338 - precision-0.70: 0.8402 - precision-0.75: 0.8509 - precision-0.80: 0.8604 - precision-0.85: 0.8574 - precision-0.90: 0.8576 - precision-0.95: 0.0000e+00 - recall: 0.7554 - recall-0.55: 0.7439 - recall-0.60: 0.7306 - recall-0.65: 0.7149 - recall-0.70: 0.6860 - recall-0.75: 0.6347 - recall-0.80: 0.5435 - recall-0.85: 0.3484 - recall-0.90: 0.0725 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.87      3015\n",
      "           1       0.67      0.00      0.01       476\n",
      "           2       0.34      0.09      0.14       410\n",
      "\n",
      "    accuracy                           0.77      3901\n",
      "   macro avg       0.60      0.36      0.34      3901\n",
      "weighted avg       0.72      0.77      0.69      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1   P2  Total    RP0    RP1    RP2\n",
      "0      2978   0   37   3015  0.988  0.000  0.012\n",
      "1       441   2   33    476  0.926  0.004  0.069\n",
      "2       373   1   36    410  0.910  0.002  0.088\n",
      "Total  3792   3  106   3901  0.972  0.001  0.027\n",
      "\n",
      ">>>>>> FOLD 3\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 11703, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 5631(48.12%)\n",
      "Label 1: 2893(24.72%)\n",
      "Label 2: 3179(27.16%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 3015(77.29%)\n",
      "Label 1: 476(12.2%)\n",
      "Label 2: 410(10.51%)\n",
      "\n",
      "Test:\n",
      "Label 0: 2425(62.16%)\n",
      "Label 1: 710(18.2%)\n",
      "Label 2: 766(19.64%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.4125711192792883, -0.25342190099344386, -0.15914924506842806]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 1.0759 - tp: 5516.0000 - fp: 3164.0000 - tn: 27166.0000 - fn: 9649.0000 - accuracy: 0.5310 - precision: 0.6355 - precision-0.55: 0.6853 - precision-0.60: 0.7377 - precision-0.65: 0.7914 - precision-0.70: 0.8271 - precision-0.75: 0.8503 - precision-0.80: 0.8605 - precision-0.85: 0.8574 - precision-0.90: 0.8576 - precision-0.95: 0.0000e+00 - recall: 0.3637 - recall-0.55: 0.3022 - recall-0.60: 0.2477 - recall-0.65: 0.2087 - recall-0.70: 0.1836 - recall-0.75: 0.1649 - recall-0.80: 0.1399 - recall-0.85: 0.0896 - recall-0.90: 0.0187 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.77460, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 5s 206ms/step - loss: 1.0746 - tp: 5671.0000 - fp: 3304.0000 - tn: 27904.0000 - fn: 9933.0000 - accuracy: 0.5298 - precision: 0.6319 - precision-0.55: 0.6820 - precision-0.60: 0.7340 - precision-0.65: 0.7893 - precision-0.70: 0.8260 - precision-0.75: 0.8504 - precision-0.80: 0.8605 - precision-0.85: 0.8574 - precision-0.90: 0.8576 - precision-0.95: 0.0000e+00 - recall: 0.3634 - recall-0.55: 0.3008 - recall-0.60: 0.2447 - recall-0.65: 0.2048 - recall-0.70: 0.1792 - recall-0.75: 0.1603 - recall-0.80: 0.1360 - recall-0.85: 0.0871 - recall-0.90: 0.0181 - recall-0.95: 0.0000e+00 - val_loss: 0.7746 - val_tp: 2798.0000 - val_fp: 766.0000 - val_tn: 7036.0000 - val_fn: 1103.0000 - val_accuracy: 0.7685 - val_precision: 0.7851 - val_precision-0.55: 0.8061 - val_precision-0.60: 0.8427 - val_precision-0.65: 0.8768 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7173 - val_recall-0.55: 0.5957 - val_recall-0.60: 0.2966 - val_recall-0.65: 0.0310 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 1.0029 - tp: 3135.0000 - fp: 1989.0000 - tn: 20539.0000 - fn: 8129.0000 - accuracy: 0.5218 - precision: 0.6118 - precision-0.55: 0.6458 - precision-0.60: 0.6851 - precision-0.65: 0.7140 - precision-0.70: 0.7391 - precision-0.75: 0.5385 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2783 - recall-0.55: 0.1698 - recall-0.60: 0.0858 - recall-0.65: 0.0312 - recall-0.70: 0.0075 - recall-0.75: 6.2145e-04 - recall-0.80: 8.8778e-05 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 0.77460 to 0.74363, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 1.0010 - tp: 3281.0000 - fp: 2053.0000 - tn: 21353.0000 - fn: 8422.0000 - accuracy: 0.5229 - precision: 0.6151 - precision-0.55: 0.6508 - precision-0.60: 0.6901 - precision-0.65: 0.7162 - precision-0.70: 0.7459 - precision-0.75: 0.6000 - precision-0.80: 0.5000 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2804 - recall-0.55: 0.1713 - recall-0.60: 0.0866 - recall-0.65: 0.0313 - recall-0.70: 0.0078 - recall-0.75: 7.6903e-04 - recall-0.80: 8.5448e-05 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.7436 - val_tp: 2788.0000 - val_fp: 649.0000 - val_tn: 7153.0000 - val_fn: 1113.0000 - val_accuracy: 0.7716 - val_precision: 0.8112 - val_precision-0.55: 0.8316 - val_precision-0.60: 0.8551 - val_precision-0.65: 0.9080 - val_precision-0.70: 0.9000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7147 - val_recall-0.55: 0.6329 - val_recall-0.60: 0.4312 - val_recall-0.65: 0.1366 - val_recall-0.70: 0.0023 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.9526 - tp: 4185.0000 - fp: 2277.0000 - tn: 20251.0000 - fn: 7079.0000 - accuracy: 0.5537 - precision: 0.6476 - precision-0.55: 0.6945 - precision-0.60: 0.7420 - precision-0.65: 0.7812 - precision-0.70: 0.8403 - precision-0.75: 0.8533 - precision-0.80: 0.8571 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3715 - recall-0.55: 0.2844 - recall-0.60: 0.1987 - recall-0.65: 0.1157 - recall-0.70: 0.0537 - recall-0.75: 0.0139 - recall-0.80: 0.0021 - recall-0.85: 8.8778e-05 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00  \n",
      "Epoch 3: val_loss improved from 0.74363 to 0.69332, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.9515 - tp: 4347.0000 - fp: 2356.0000 - tn: 21050.0000 - fn: 7356.0000 - accuracy: 0.5541 - precision: 0.6485 - precision-0.55: 0.6958 - precision-0.60: 0.7441 - precision-0.65: 0.7841 - precision-0.70: 0.8439 - precision-0.75: 0.8615 - precision-0.80: 0.8667 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3714 - recall-0.55: 0.2844 - recall-0.60: 0.1990 - recall-0.65: 0.1164 - recall-0.70: 0.0545 - recall-0.75: 0.0144 - recall-0.80: 0.0022 - recall-0.85: 8.5448e-05 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.6933 - val_tp: 2890.0000 - val_fp: 690.0000 - val_tn: 7112.0000 - val_fn: 1011.0000 - val_accuracy: 0.7736 - val_precision: 0.8073 - val_precision-0.55: 0.8244 - val_precision-0.60: 0.8353 - val_precision-0.65: 0.8441 - val_precision-0.70: 0.8840 - val_precision-0.75: 0.9294 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7408 - val_recall-0.55: 0.7126 - val_recall-0.60: 0.6486 - val_recall-0.65: 0.5150 - val_recall-0.70: 0.2794 - val_recall-0.75: 0.0405 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.9194 - tp: 4428.0000 - fp: 2129.0000 - tn: 20399.0000 - fn: 6836.0000 - accuracy: 0.5727 - precision: 0.6753 - precision-0.55: 0.7107 - precision-0.60: 0.7439 - precision-0.65: 0.7935 - precision-0.70: 0.8369 - precision-0.75: 0.8660 - precision-0.80: 0.8878 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3931 - recall-0.55: 0.3149 - recall-0.60: 0.2357 - recall-0.65: 0.1614 - recall-0.70: 0.0925 - recall-0.75: 0.0373 - recall-0.80: 0.0077 - recall-0.85: 6.2145e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 0.69332 to 0.65589, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.9187 - tp: 4603.0000 - fp: 2210.0000 - tn: 21196.0000 - fn: 7100.0000 - accuracy: 0.5726 - precision: 0.6756 - precision-0.55: 0.7107 - precision-0.60: 0.7452 - precision-0.65: 0.7952 - precision-0.70: 0.8397 - precision-0.75: 0.8712 - precision-0.80: 0.8972 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3933 - recall-0.55: 0.3155 - recall-0.60: 0.2364 - recall-0.65: 0.1629 - recall-0.70: 0.0944 - recall-0.75: 0.0387 - recall-0.80: 0.0082 - recall-0.85: 5.9814e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.6559 - val_tp: 2943.0000 - val_fp: 724.0000 - val_tn: 7078.0000 - val_fn: 958.0000 - val_accuracy: 0.7767 - val_precision: 0.8026 - val_precision-0.55: 0.8154 - val_precision-0.60: 0.8268 - val_precision-0.65: 0.8356 - val_precision-0.70: 0.8424 - val_precision-0.75: 0.8699 - val_precision-0.80: 0.9041 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7544 - val_recall-0.55: 0.7403 - val_recall-0.60: 0.7196 - val_recall-0.65: 0.6721 - val_recall-0.70: 0.5647 - val_recall-0.75: 0.3789 - val_recall-0.80: 0.1015 - val_recall-0.85: 5.1269e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8985 - tp: 4724.0000 - fp: 2378.0000 - tn: 20150.0000 - fn: 6540.0000 - accuracy: 0.5813 - precision: 0.6652 - precision-0.55: 0.6985 - precision-0.60: 0.7434 - precision-0.65: 0.7834 - precision-0.70: 0.8275 - precision-0.75: 0.8599 - precision-0.80: 0.9181 - precision-0.85: 0.9683 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4194 - recall-0.55: 0.3491 - recall-0.60: 0.2863 - recall-0.65: 0.2173 - recall-0.70: 0.1499 - recall-0.75: 0.0790 - recall-0.80: 0.0279 - recall-0.85: 0.0054 - recall-0.90: 5.3267e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 5: val_loss improved from 0.65589 to 0.64541, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.8995 - tp: 4895.0000 - fp: 2486.0000 - tn: 20920.0000 - fn: 6808.0000 - accuracy: 0.5799 - precision: 0.6632 - precision-0.55: 0.6977 - precision-0.60: 0.7417 - precision-0.65: 0.7817 - precision-0.70: 0.8259 - precision-0.75: 0.8604 - precision-0.80: 0.9188 - precision-0.85: 0.9565 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4183 - recall-0.55: 0.3491 - recall-0.60: 0.2862 - recall-0.65: 0.2178 - recall-0.70: 0.1504 - recall-0.75: 0.0796 - recall-0.80: 0.0280 - recall-0.85: 0.0056 - recall-0.90: 5.1269e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.6454 - val_tp: 2942.0000 - val_fp: 705.0000 - val_tn: 7097.0000 - val_fn: 959.0000 - val_accuracy: 0.7770 - val_precision: 0.8067 - val_precision-0.55: 0.8180 - val_precision-0.60: 0.8265 - val_precision-0.65: 0.8327 - val_precision-0.70: 0.8417 - val_precision-0.75: 0.8536 - val_precision-0.80: 0.8733 - val_precision-0.85: 0.8870 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7542 - val_recall-0.55: 0.7398 - val_recall-0.60: 0.7229 - val_recall-0.65: 0.6888 - val_recall-0.70: 0.6204 - val_recall-0.75: 0.4901 - val_recall-0.80: 0.2633 - val_recall-0.85: 0.0261 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8896 - tp: 4763.0000 - fp: 2398.0000 - tn: 20130.0000 - fn: 6501.0000 - accuracy: 0.5822 - precision: 0.6651 - precision-0.55: 0.7022 - precision-0.60: 0.7434 - precision-0.65: 0.7744 - precision-0.70: 0.8119 - precision-0.75: 0.8538 - precision-0.80: 0.8963 - precision-0.85: 0.8935 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4229 - recall-0.55: 0.3584 - recall-0.60: 0.2978 - recall-0.65: 0.2344 - recall-0.70: 0.1721 - recall-0.75: 0.1104 - recall-0.80: 0.0514 - recall-0.85: 0.0134 - recall-0.90: 0.0013 - recall-0.95: 0.0000e+00  \n",
      "Epoch 6: val_loss improved from 0.64541 to 0.63842, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.8868 - tp: 4970.0000 - fp: 2465.0000 - tn: 20941.0000 - fn: 6733.0000 - accuracy: 0.5850 - precision: 0.6685 - precision-0.55: 0.7051 - precision-0.60: 0.7457 - precision-0.65: 0.7772 - precision-0.70: 0.8150 - precision-0.75: 0.8557 - precision-0.80: 0.8954 - precision-0.85: 0.8977 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4247 - recall-0.55: 0.3599 - recall-0.60: 0.2984 - recall-0.65: 0.2352 - recall-0.70: 0.1732 - recall-0.75: 0.1110 - recall-0.80: 0.0520 - recall-0.85: 0.0135 - recall-0.90: 0.0014 - recall-0.95: 0.0000e+00 - val_loss: 0.6384 - val_tp: 2956.0000 - val_fp: 713.0000 - val_tn: 7089.0000 - val_fn: 945.0000 - val_accuracy: 0.7783 - val_precision: 0.8057 - val_precision-0.55: 0.8164 - val_precision-0.60: 0.8230 - val_precision-0.65: 0.8310 - val_precision-0.70: 0.8369 - val_precision-0.75: 0.8489 - val_precision-0.80: 0.8617 - val_precision-0.85: 0.8677 - val_precision-0.90: 0.9000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7578 - val_recall-0.55: 0.7444 - val_recall-0.60: 0.7308 - val_recall-0.65: 0.7111 - val_recall-0.70: 0.6655 - val_recall-0.75: 0.5788 - val_recall-0.80: 0.4248 - val_recall-0.85: 0.1412 - val_recall-0.90: 0.0023 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8770 - tp: 4994.0000 - fp: 2436.0000 - tn: 20092.0000 - fn: 6270.0000 - accuracy: 0.5934 - precision: 0.6721 - precision-0.55: 0.7045 - precision-0.60: 0.7352 - precision-0.65: 0.7686 - precision-0.70: 0.8133 - precision-0.75: 0.8570 - precision-0.80: 0.9012 - precision-0.85: 0.9460 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4434 - recall-0.55: 0.3790 - recall-0.60: 0.3161 - recall-0.65: 0.2580 - recall-0.70: 0.2003 - recall-0.75: 0.1346 - recall-0.80: 0.0737 - recall-0.85: 0.0233 - recall-0.90: 0.0020 - recall-0.95: 0.0000e+00\n",
      "Epoch 7: val_loss improved from 0.63842 to 0.63577, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.8755 - tp: 5191.0000 - fp: 2531.0000 - tn: 20875.0000 - fn: 6512.0000 - accuracy: 0.5943 - precision: 0.6722 - precision-0.55: 0.7053 - precision-0.60: 0.7363 - precision-0.65: 0.7697 - precision-0.70: 0.8152 - precision-0.75: 0.8588 - precision-0.80: 0.9030 - precision-0.85: 0.9497 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4436 - recall-0.55: 0.3799 - recall-0.60: 0.3170 - recall-0.65: 0.2591 - recall-0.70: 0.2017 - recall-0.75: 0.1357 - recall-0.80: 0.0748 - recall-0.85: 0.0242 - recall-0.90: 0.0023 - recall-0.95: 0.0000e+00 - val_loss: 0.6358 - val_tp: 2961.0000 - val_fp: 706.0000 - val_tn: 7096.0000 - val_fn: 940.0000 - val_accuracy: 0.7777 - val_precision: 0.8075 - val_precision-0.55: 0.8173 - val_precision-0.60: 0.8229 - val_precision-0.65: 0.8308 - val_precision-0.70: 0.8370 - val_precision-0.75: 0.8464 - val_precision-0.80: 0.8643 - val_precision-0.85: 0.8613 - val_precision-0.90: 0.8036 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7590 - val_recall-0.55: 0.7444 - val_recall-0.60: 0.7326 - val_recall-0.65: 0.7139 - val_recall-0.70: 0.6780 - val_recall-0.75: 0.6132 - val_recall-0.80: 0.4865 - val_recall-0.85: 0.2276 - val_recall-0.90: 0.0115 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8715 - tp: 5137.0000 - fp: 2575.0000 - tn: 19953.0000 - fn: 6127.0000 - accuracy: 0.5937 - precision: 0.6661 - precision-0.55: 0.7035 - precision-0.60: 0.7325 - precision-0.65: 0.7686 - precision-0.70: 0.8061 - precision-0.75: 0.8449 - precision-0.80: 0.8978 - precision-0.85: 0.9343 - precision-0.90: 0.9868 - precision-0.95: 0.0000e+00 - recall: 0.4561 - recall-0.55: 0.3955 - recall-0.60: 0.3340 - recall-0.65: 0.2819 - recall-0.70: 0.2236 - recall-0.75: 0.1673 - recall-0.80: 0.0983 - recall-0.85: 0.0404 - recall-0.90: 0.0067 - recall-0.95: 0.0000e+00\n",
      "Epoch 8: val_loss improved from 0.63577 to 0.63574, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.8718 - tp: 5331.0000 - fp: 2681.0000 - tn: 20725.0000 - fn: 6372.0000 - accuracy: 0.5925 - precision: 0.6654 - precision-0.55: 0.7028 - precision-0.60: 0.7324 - precision-0.65: 0.7692 - precision-0.70: 0.8078 - precision-0.75: 0.8459 - precision-0.80: 0.8961 - precision-0.85: 0.9356 - precision-0.90: 0.9870 - precision-0.95: 0.0000e+00 - recall: 0.4555 - recall-0.55: 0.3945 - recall-0.60: 0.3328 - recall-0.65: 0.2804 - recall-0.70: 0.2227 - recall-0.75: 0.1660 - recall-0.80: 0.0972 - recall-0.85: 0.0397 - recall-0.90: 0.0065 - recall-0.95: 0.0000e+00 - val_loss: 0.6357 - val_tp: 2929.0000 - val_fp: 669.0000 - val_tn: 7133.0000 - val_fn: 972.0000 - val_accuracy: 0.7772 - val_precision: 0.8141 - val_precision-0.55: 0.8200 - val_precision-0.60: 0.8277 - val_precision-0.65: 0.8351 - val_precision-0.70: 0.8396 - val_precision-0.75: 0.8503 - val_precision-0.80: 0.8647 - val_precision-0.85: 0.8605 - val_precision-0.90: 0.8077 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7508 - val_recall-0.55: 0.7383 - val_recall-0.60: 0.7216 - val_recall-0.65: 0.6996 - val_recall-0.70: 0.6591 - val_recall-0.75: 0.5840 - val_recall-0.80: 0.4571 - val_recall-0.85: 0.2071 - val_recall-0.90: 0.0108 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8698 - tp: 5042.0000 - fp: 2495.0000 - tn: 20033.0000 - fn: 6222.0000 - accuracy: 0.5920 - precision: 0.6690 - precision-0.55: 0.7055 - precision-0.60: 0.7398 - precision-0.65: 0.7737 - precision-0.70: 0.8146 - precision-0.75: 0.8540 - precision-0.80: 0.8960 - precision-0.85: 0.9330 - precision-0.90: 0.9714 - precision-0.95: 0.0000e+00 - recall: 0.4476 - recall-0.55: 0.3802 - recall-0.60: 0.3208 - recall-0.65: 0.2638 - recall-0.70: 0.2086 - recall-0.75: 0.1522 - recall-0.80: 0.0918 - recall-0.85: 0.0384 - recall-0.90: 0.0060 - recall-0.95: 0.0000e+00\n",
      "Epoch 9: val_loss improved from 0.63574 to 0.63514, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.8689 - tp: 5248.0000 - fp: 2593.0000 - tn: 20813.0000 - fn: 6455.0000 - accuracy: 0.5922 - precision: 0.6693 - precision-0.55: 0.7050 - precision-0.60: 0.7392 - precision-0.65: 0.7728 - precision-0.70: 0.8155 - precision-0.75: 0.8556 - precision-0.80: 0.8974 - precision-0.85: 0.9325 - precision-0.90: 0.9737 - precision-0.95: 0.0000e+00 - recall: 0.4484 - recall-0.55: 0.3807 - recall-0.60: 0.3219 - recall-0.65: 0.2645 - recall-0.70: 0.2100 - recall-0.75: 0.1534 - recall-0.80: 0.0926 - recall-0.85: 0.0390 - recall-0.90: 0.0063 - recall-0.95: 0.0000e+00 - val_loss: 0.6351 - val_tp: 2971.0000 - val_fp: 724.0000 - val_tn: 7078.0000 - val_fn: 930.0000 - val_accuracy: 0.7785 - val_precision: 0.8041 - val_precision-0.55: 0.8145 - val_precision-0.60: 0.8202 - val_precision-0.65: 0.8252 - val_precision-0.70: 0.8345 - val_precision-0.75: 0.8400 - val_precision-0.80: 0.8522 - val_precision-0.85: 0.8666 - val_precision-0.90: 0.8212 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7616 - val_recall-0.55: 0.7519 - val_recall-0.60: 0.7390 - val_recall-0.65: 0.7214 - val_recall-0.70: 0.6991 - val_recall-0.75: 0.6580 - val_recall-0.80: 0.5675 - val_recall-0.85: 0.3996 - val_recall-0.90: 0.0636 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8625 - tp: 5140.0000 - fp: 2493.0000 - tn: 20035.0000 - fn: 6124.0000 - accuracy: 0.5939 - precision: 0.6734 - precision-0.55: 0.7132 - precision-0.60: 0.7450 - precision-0.65: 0.7775 - precision-0.70: 0.8074 - precision-0.75: 0.8472 - precision-0.80: 0.8909 - precision-0.85: 0.9427 - precision-0.90: 0.9787 - precision-0.95: 1.0000 - recall: 0.4563 - recall-0.55: 0.3916 - recall-0.60: 0.3302 - recall-0.65: 0.2727 - recall-0.70: 0.2192 - recall-0.75: 0.1615 - recall-0.80: 0.1022 - recall-0.85: 0.0439 - recall-0.90: 0.0082 - recall-0.95: 8.8778e-05\n",
      "Epoch 10: val_loss improved from 0.63514 to 0.63390, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.8642 - tp: 5326.0000 - fp: 2606.0000 - tn: 20800.0000 - fn: 6377.0000 - accuracy: 0.5929 - precision: 0.6715 - precision-0.55: 0.7112 - precision-0.60: 0.7435 - precision-0.65: 0.7770 - precision-0.70: 0.8065 - precision-0.75: 0.8444 - precision-0.80: 0.8858 - precision-0.85: 0.9380 - precision-0.90: 0.9794 - precision-0.95: 1.0000 - recall: 0.4551 - recall-0.55: 0.3906 - recall-0.60: 0.3298 - recall-0.65: 0.2730 - recall-0.70: 0.2190 - recall-0.75: 0.1618 - recall-0.80: 0.1021 - recall-0.85: 0.0439 - recall-0.90: 0.0081 - recall-0.95: 8.5448e-05 - val_loss: 0.6339 - val_tp: 2966.0000 - val_fp: 715.0000 - val_tn: 7087.0000 - val_fn: 935.0000 - val_accuracy: 0.7780 - val_precision: 0.8058 - val_precision-0.55: 0.8161 - val_precision-0.60: 0.8208 - val_precision-0.65: 0.8287 - val_precision-0.70: 0.8358 - val_precision-0.75: 0.8406 - val_precision-0.80: 0.8517 - val_precision-0.85: 0.8668 - val_precision-0.90: 0.8189 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7603 - val_recall-0.55: 0.7496 - val_recall-0.60: 0.7385 - val_recall-0.65: 0.7206 - val_recall-0.70: 0.6993 - val_recall-0.75: 0.6598 - val_recall-0.80: 0.5714 - val_recall-0.85: 0.4119 - val_recall-0.90: 0.0754 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8615 - tp: 5174.0000 - fp: 2510.0000 - tn: 20018.0000 - fn: 6090.0000 - accuracy: 0.5977 - precision: 0.6733 - precision-0.55: 0.7044 - precision-0.60: 0.7405 - precision-0.65: 0.7769 - precision-0.70: 0.8184 - precision-0.75: 0.8512 - precision-0.80: 0.8986 - precision-0.85: 0.9504 - precision-0.90: 0.9890 - precision-0.95: 0.0000e+00 - recall: 0.4593 - recall-0.55: 0.3927 - recall-0.60: 0.3324 - recall-0.65: 0.2766 - recall-0.70: 0.2233 - recall-0.75: 0.1691 - recall-0.80: 0.1086 - recall-0.85: 0.0477 - recall-0.90: 0.0080 - recall-0.95: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from 0.63390\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.8613 - tp: 5378.0000 - fp: 2624.0000 - tn: 20782.0000 - fn: 6325.0000 - accuracy: 0.5977 - precision: 0.6721 - precision-0.55: 0.7026 - precision-0.60: 0.7387 - precision-0.65: 0.7750 - precision-0.70: 0.8176 - precision-0.75: 0.8508 - precision-0.80: 0.8966 - precision-0.85: 0.9515 - precision-0.90: 0.9898 - precision-0.95: 0.0000e+00 - recall: 0.4595 - recall-0.55: 0.3927 - recall-0.60: 0.3332 - recall-0.65: 0.2776 - recall-0.70: 0.2245 - recall-0.75: 0.1700 - recall-0.80: 0.1097 - recall-0.85: 0.0486 - recall-0.90: 0.0083 - recall-0.95: 0.0000e+00 - val_loss: 0.6370 - val_tp: 2976.0000 - val_fp: 719.0000 - val_tn: 7083.0000 - val_fn: 925.0000 - val_accuracy: 0.7775 - val_precision: 0.8054 - val_precision-0.55: 0.8156 - val_precision-0.60: 0.8207 - val_precision-0.65: 0.8270 - val_precision-0.70: 0.8352 - val_precision-0.75: 0.8409 - val_precision-0.80: 0.8508 - val_precision-0.85: 0.8685 - val_precision-0.90: 0.8362 - val_precision-0.95: 1.0000 - val_recall: 0.7629 - val_recall-0.55: 0.7526 - val_recall-0.60: 0.7393 - val_recall-0.65: 0.7216 - val_recall-0.70: 0.7003 - val_recall-0.75: 0.6639 - val_recall-0.80: 0.5832 - val_recall-0.85: 0.4350 - val_recall-0.90: 0.0995 - val_recall-0.95: 2.5634e-04\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8594 - tp: 5376.0000 - fp: 2611.0000 - tn: 20795.0000 - fn: 6327.0000 - accuracy: 0.5999 - precision: 0.6731 - precision-0.55: 0.7095 - precision-0.60: 0.7467 - precision-0.65: 0.7786 - precision-0.70: 0.8238 - precision-0.75: 0.8626 - precision-0.80: 0.9071 - precision-0.85: 0.9536 - precision-0.90: 0.9744 - precision-0.95: 1.0000 - recall: 0.4594 - recall-0.55: 0.3966 - recall-0.60: 0.3339 - recall-0.65: 0.2761 - recall-0.70: 0.2237 - recall-0.75: 0.1673 - recall-0.80: 0.1060 - recall-0.85: 0.0491 - recall-0.90: 0.0097 - recall-0.95: 1.7090e-04\n",
      "Epoch 12: val_loss did not improve from 0.63390\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.8594 - tp: 5376.0000 - fp: 2611.0000 - tn: 20795.0000 - fn: 6327.0000 - accuracy: 0.5999 - precision: 0.6731 - precision-0.55: 0.7095 - precision-0.60: 0.7467 - precision-0.65: 0.7786 - precision-0.70: 0.8238 - precision-0.75: 0.8626 - precision-0.80: 0.9071 - precision-0.85: 0.9536 - precision-0.90: 0.9744 - precision-0.95: 1.0000 - recall: 0.4594 - recall-0.55: 0.3966 - recall-0.60: 0.3339 - recall-0.65: 0.2761 - recall-0.70: 0.2237 - recall-0.75: 0.1673 - recall-0.80: 0.1060 - recall-0.85: 0.0491 - recall-0.90: 0.0097 - recall-0.95: 1.7090e-04 - val_loss: 0.6352 - val_tp: 2976.0000 - val_fp: 733.0000 - val_tn: 7069.0000 - val_fn: 925.0000 - val_accuracy: 0.7777 - val_precision: 0.8024 - val_precision-0.55: 0.8141 - val_precision-0.60: 0.8187 - val_precision-0.65: 0.8242 - val_precision-0.70: 0.8336 - val_precision-0.75: 0.8398 - val_precision-0.80: 0.8502 - val_precision-0.85: 0.8681 - val_precision-0.90: 0.8512 - val_precision-0.95: 1.0000 - val_recall: 0.7629 - val_recall-0.55: 0.7554 - val_recall-0.60: 0.7411 - val_recall-0.65: 0.7285 - val_recall-0.70: 0.7052 - val_recall-0.75: 0.6734 - val_recall-0.80: 0.6037 - val_recall-0.85: 0.4706 - val_recall-0.90: 0.1466 - val_recall-0.95: 5.1269e-04\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8578 - tp: 5483.0000 - fp: 2688.0000 - tn: 20718.0000 - fn: 6220.0000 - accuracy: 0.5998 - precision: 0.6710 - precision-0.55: 0.7045 - precision-0.60: 0.7384 - precision-0.65: 0.7743 - precision-0.70: 0.8111 - precision-0.75: 0.8500 - precision-0.80: 0.8994 - precision-0.85: 0.9428 - precision-0.90: 0.9649 - precision-0.95: 0.0000e+00 - recall: 0.4685 - recall-0.55: 0.4016 - recall-0.60: 0.3411 - recall-0.65: 0.2834 - recall-0.70: 0.2300 - recall-0.75: 0.1747 - recall-0.80: 0.1138 - recall-0.85: 0.0535 - recall-0.90: 0.0094 - recall-0.95: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from 0.63390\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.8578 - tp: 5483.0000 - fp: 2688.0000 - tn: 20718.0000 - fn: 6220.0000 - accuracy: 0.5998 - precision: 0.6710 - precision-0.55: 0.7045 - precision-0.60: 0.7384 - precision-0.65: 0.7743 - precision-0.70: 0.8111 - precision-0.75: 0.8500 - precision-0.80: 0.8994 - precision-0.85: 0.9428 - precision-0.90: 0.9649 - precision-0.95: 0.0000e+00 - recall: 0.4685 - recall-0.55: 0.4016 - recall-0.60: 0.3411 - recall-0.65: 0.2834 - recall-0.70: 0.2300 - recall-0.75: 0.1747 - recall-0.80: 0.1138 - recall-0.85: 0.0535 - recall-0.90: 0.0094 - recall-0.95: 0.0000e+00 - val_loss: 0.6377 - val_tp: 2979.0000 - val_fp: 707.0000 - val_tn: 7095.0000 - val_fn: 922.0000 - val_accuracy: 0.7775 - val_precision: 0.8082 - val_precision-0.55: 0.8167 - val_precision-0.60: 0.8223 - val_precision-0.65: 0.8286 - val_precision-0.70: 0.8365 - val_precision-0.75: 0.8441 - val_precision-0.80: 0.8517 - val_precision-0.85: 0.8673 - val_precision-0.90: 0.8266 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7637 - val_recall-0.55: 0.7506 - val_recall-0.60: 0.7378 - val_recall-0.65: 0.7175 - val_recall-0.70: 0.6965 - val_recall-0.75: 0.6565 - val_recall-0.80: 0.5773 - val_recall-0.85: 0.4255 - val_recall-0.90: 0.0989 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 14/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8522 - tp: 5285.0000 - fp: 2561.0000 - tn: 19967.0000 - fn: 5979.0000 - accuracy: 0.6044 - precision: 0.6736 - precision-0.55: 0.7053 - precision-0.60: 0.7414 - precision-0.65: 0.7770 - precision-0.70: 0.8155 - precision-0.75: 0.8537 - precision-0.80: 0.8886 - precision-0.85: 0.9439 - precision-0.90: 0.9804 - precision-0.95: 1.0000 - recall: 0.4692 - recall-0.55: 0.4074 - recall-0.60: 0.3523 - recall-0.65: 0.2972 - recall-0.70: 0.2425 - recall-0.75: 0.1860 - recall-0.80: 0.1254 - recall-0.85: 0.0627 - recall-0.90: 0.0133 - recall-0.95: 8.8778e-05    \n",
      "Epoch 14: val_loss improved from 0.63390 to 0.62953, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154529.h5\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.8517 - tp: 5487.0000 - fp: 2646.0000 - tn: 20760.0000 - fn: 6216.0000 - accuracy: 0.6044 - precision: 0.6747 - precision-0.55: 0.7073 - precision-0.60: 0.7427 - precision-0.65: 0.7782 - precision-0.70: 0.8171 - precision-0.75: 0.8558 - precision-0.80: 0.8905 - precision-0.85: 0.9451 - precision-0.90: 0.9806 - precision-0.95: 1.0000 - recall: 0.4689 - recall-0.55: 0.4066 - recall-0.60: 0.3503 - recall-0.65: 0.2952 - recall-0.70: 0.2401 - recall-0.75: 0.1846 - recall-0.80: 0.1243 - recall-0.85: 0.0618 - recall-0.90: 0.0130 - recall-0.95: 8.5448e-05 - val_loss: 0.6295 - val_tp: 2960.0000 - val_fp: 674.0000 - val_tn: 7128.0000 - val_fn: 941.0000 - val_accuracy: 0.7780 - val_precision: 0.8145 - val_precision-0.55: 0.8192 - val_precision-0.60: 0.8248 - val_precision-0.65: 0.8327 - val_precision-0.70: 0.8379 - val_precision-0.75: 0.8465 - val_precision-0.80: 0.8578 - val_precision-0.85: 0.8679 - val_precision-0.90: 0.7970 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7588 - val_recall-0.55: 0.7421 - val_recall-0.60: 0.7303 - val_recall-0.65: 0.7096 - val_recall-0.70: 0.6865 - val_recall-0.75: 0.6416 - val_recall-0.80: 0.5599 - val_recall-0.85: 0.3855 - val_recall-0.90: 0.0684 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 15/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8517 - tp: 5225.0000 - fp: 2543.0000 - tn: 19985.0000 - fn: 6039.0000 - accuracy: 0.6053 - precision: 0.6726 - precision-0.55: 0.7130 - precision-0.60: 0.7442 - precision-0.65: 0.7791 - precision-0.70: 0.8116 - precision-0.75: 0.8546 - precision-0.80: 0.8974 - precision-0.85: 0.9339 - precision-0.90: 0.9928 - precision-0.95: 0.0000e+00 - recall: 0.4639 - recall-0.55: 0.4028 - recall-0.60: 0.3438 - recall-0.65: 0.2891 - recall-0.70: 0.2341 - recall-0.75: 0.1811 - recall-0.80: 0.1196 - recall-0.85: 0.0589 - recall-0.90: 0.0122 - recall-0.95: 0.0000e+00\n",
      "Epoch 15: val_loss did not improve from 0.62953\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.8520 - tp: 5436.0000 - fp: 2657.0000 - tn: 20749.0000 - fn: 6267.0000 - accuracy: 0.6052 - precision: 0.6717 - precision-0.55: 0.7111 - precision-0.60: 0.7439 - precision-0.65: 0.7778 - precision-0.70: 0.8100 - precision-0.75: 0.8529 - precision-0.80: 0.8966 - precision-0.85: 0.9335 - precision-0.90: 0.9861 - precision-0.95: 0.0000e+00 - recall: 0.4645 - recall-0.55: 0.4030 - recall-0.60: 0.3445 - recall-0.65: 0.2892 - recall-0.70: 0.2343 - recall-0.75: 0.1808 - recall-0.80: 0.1193 - recall-0.85: 0.0588 - recall-0.90: 0.0121 - recall-0.95: 0.0000e+00 - val_loss: 0.6354 - val_tp: 2979.0000 - val_fp: 703.0000 - val_tn: 7099.0000 - val_fn: 922.0000 - val_accuracy: 0.7772 - val_precision: 0.8091 - val_precision-0.55: 0.8165 - val_precision-0.60: 0.8217 - val_precision-0.65: 0.8277 - val_precision-0.70: 0.8361 - val_precision-0.75: 0.8439 - val_precision-0.80: 0.8512 - val_precision-0.85: 0.8680 - val_precision-0.90: 0.8542 - val_precision-0.95: 1.0000 - val_recall: 0.7637 - val_recall-0.55: 0.7526 - val_recall-0.60: 0.7396 - val_recall-0.65: 0.7206 - val_recall-0.70: 0.7011 - val_recall-0.75: 0.6678 - val_recall-0.80: 0.5937 - val_recall-0.85: 0.4568 - val_recall-0.90: 0.1487 - val_recall-0.95: 7.6903e-04\n",
      "Epoch 16/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8470 - tp: 5294.0000 - fp: 2487.0000 - tn: 20041.0000 - fn: 5970.0000 - accuracy: 0.6084 - precision: 0.6804 - precision-0.55: 0.7161 - precision-0.60: 0.7509 - precision-0.65: 0.7839 - precision-0.70: 0.8199 - precision-0.75: 0.8621 - precision-0.80: 0.9094 - precision-0.85: 0.9314 - precision-0.90: 0.9483 - precision-0.95: 0.0000e+00 - recall: 0.4700 - recall-0.55: 0.4003 - recall-0.60: 0.3399 - recall-0.65: 0.2825 - recall-0.70: 0.2308 - recall-0.75: 0.1760 - recall-0.80: 0.1159 - recall-0.85: 0.0555 - recall-0.90: 0.0098 - recall-0.95: 0.0000e+00\n",
      "Epoch 16: val_loss did not improve from 0.62953\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.8486 - tp: 5498.0000 - fp: 2587.0000 - tn: 20819.0000 - fn: 6205.0000 - accuracy: 0.6080 - precision: 0.6800 - precision-0.55: 0.7148 - precision-0.60: 0.7494 - precision-0.65: 0.7826 - precision-0.70: 0.8190 - precision-0.75: 0.8606 - precision-0.80: 0.9066 - precision-0.85: 0.9294 - precision-0.90: 0.9508 - precision-0.95: 0.0000e+00 - recall: 0.4698 - recall-0.55: 0.4002 - recall-0.60: 0.3394 - recall-0.65: 0.2818 - recall-0.70: 0.2301 - recall-0.75: 0.1751 - recall-0.80: 0.1153 - recall-0.85: 0.0551 - recall-0.90: 0.0099 - recall-0.95: 0.0000e+00 - val_loss: 0.6333 - val_tp: 2978.0000 - val_fp: 710.0000 - val_tn: 7092.0000 - val_fn: 923.0000 - val_accuracy: 0.7788 - val_precision: 0.8075 - val_precision-0.55: 0.8173 - val_precision-0.60: 0.8213 - val_precision-0.65: 0.8266 - val_precision-0.70: 0.8350 - val_precision-0.75: 0.8439 - val_precision-0.80: 0.8518 - val_precision-0.85: 0.8681 - val_precision-0.90: 0.8610 - val_precision-0.95: 0.8000 - val_recall: 0.7634 - val_recall-0.55: 0.7544 - val_recall-0.60: 0.7398 - val_recall-0.65: 0.7224 - val_recall-0.70: 0.7029 - val_recall-0.75: 0.6719 - val_recall-0.80: 0.6011 - val_recall-0.85: 0.4740 - val_recall-0.90: 0.1651 - val_recall-0.95: 0.0010\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8461 - tp: 5558.0000 - fp: 2613.0000 - tn: 20793.0000 - fn: 6145.0000 - accuracy: 0.6099 - precision: 0.6802 - precision-0.55: 0.7125 - precision-0.60: 0.7469 - precision-0.65: 0.7838 - precision-0.70: 0.8211 - precision-0.75: 0.8570 - precision-0.80: 0.8994 - precision-0.85: 0.9444 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4749 - recall-0.55: 0.4068 - recall-0.60: 0.3475 - recall-0.65: 0.2955 - recall-0.70: 0.2432 - recall-0.75: 0.1858 - recall-0.80: 0.1246 - recall-0.85: 0.0638 - recall-0.90: 0.0151 - recall-0.95: 0.0000e+00\n",
      "Epoch 17: val_loss did not improve from 0.62953\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.8461 - tp: 5558.0000 - fp: 2613.0000 - tn: 20793.0000 - fn: 6145.0000 - accuracy: 0.6099 - precision: 0.6802 - precision-0.55: 0.7125 - precision-0.60: 0.7469 - precision-0.65: 0.7838 - precision-0.70: 0.8211 - precision-0.75: 0.8570 - precision-0.80: 0.8994 - precision-0.85: 0.9444 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4749 - recall-0.55: 0.4068 - recall-0.60: 0.3475 - recall-0.65: 0.2955 - recall-0.70: 0.2432 - recall-0.75: 0.1858 - recall-0.80: 0.1246 - recall-0.85: 0.0638 - recall-0.90: 0.0151 - recall-0.95: 0.0000e+00 - val_loss: 0.6362 - val_tp: 2979.0000 - val_fp: 708.0000 - val_tn: 7094.0000 - val_fn: 922.0000 - val_accuracy: 0.7762 - val_precision: 0.8080 - val_precision-0.55: 0.8168 - val_precision-0.60: 0.8223 - val_precision-0.65: 0.8298 - val_precision-0.70: 0.8371 - val_precision-0.75: 0.8443 - val_precision-0.80: 0.8515 - val_precision-0.85: 0.8666 - val_precision-0.90: 0.8569 - val_precision-0.95: 1.0000 - val_recall: 0.7637 - val_recall-0.55: 0.7542 - val_recall-0.60: 0.7380 - val_recall-0.65: 0.7201 - val_recall-0.70: 0.6993 - val_recall-0.75: 0.6698 - val_recall-0.80: 0.5955 - val_recall-0.85: 0.4545 - val_recall-0.90: 0.1551 - val_recall-0.95: 0.0010\n",
      "Epoch 18/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.8423 - tp: 5350.0000 - fp: 2495.0000 - tn: 20033.0000 - fn: 5914.0000 - accuracy: 0.6080 - precision: 0.6820 - precision-0.55: 0.7139 - precision-0.60: 0.7526 - precision-0.65: 0.7849 - precision-0.70: 0.8194 - precision-0.75: 0.8660 - precision-0.80: 0.8995 - precision-0.85: 0.9454 - precision-0.90: 0.9702 - precision-0.95: 1.0000 - recall: 0.4750 - recall-0.55: 0.4055 - recall-0.60: 0.3451 - recall-0.65: 0.2906 - recall-0.70: 0.2381 - recall-0.75: 0.1847 - recall-0.80: 0.1255 - recall-0.85: 0.0630 - recall-0.90: 0.0145 - recall-0.95: 8.8778e-05   \n",
      "Epoch 18: val_loss did not improve from 0.62953\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.8425 - tp: 5554.0000 - fp: 2592.0000 - tn: 20814.0000 - fn: 6149.0000 - accuracy: 0.6079 - precision: 0.6818 - precision-0.55: 0.7143 - precision-0.60: 0.7528 - precision-0.65: 0.7859 - precision-0.70: 0.8201 - precision-0.75: 0.8667 - precision-0.80: 0.9013 - precision-0.85: 0.9464 - precision-0.90: 0.9665 - precision-0.95: 1.0000 - recall: 0.4746 - recall-0.55: 0.4055 - recall-0.60: 0.3451 - recall-0.65: 0.2910 - recall-0.70: 0.2380 - recall-0.75: 0.1850 - recall-0.80: 0.1257 - recall-0.85: 0.0633 - recall-0.90: 0.0148 - recall-0.95: 8.5448e-05 - val_loss: 0.6354 - val_tp: 2984.0000 - val_fp: 709.0000 - val_tn: 7093.0000 - val_fn: 917.0000 - val_accuracy: 0.7777 - val_precision: 0.8080 - val_precision-0.55: 0.8177 - val_precision-0.60: 0.8216 - val_precision-0.65: 0.8271 - val_precision-0.70: 0.8365 - val_precision-0.75: 0.8445 - val_precision-0.80: 0.8514 - val_precision-0.85: 0.8678 - val_precision-0.90: 0.8637 - val_precision-0.95: 0.8000 - val_recall: 0.7649 - val_recall-0.55: 0.7567 - val_recall-0.60: 0.7401 - val_recall-0.65: 0.7234 - val_recall-0.70: 0.7029 - val_recall-0.75: 0.6739 - val_recall-0.80: 0.6034 - val_recall-0.85: 0.4830 - val_recall-0.90: 0.1771 - val_recall-0.95: 0.0010\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8407 - tp: 5574.0000 - fp: 2577.0000 - tn: 20829.0000 - fn: 6129.0000 - accuracy: 0.6131 - precision: 0.6838 - precision-0.55: 0.7150 - precision-0.60: 0.7545 - precision-0.65: 0.7866 - precision-0.70: 0.8280 - precision-0.75: 0.8615 - precision-0.80: 0.9010 - precision-0.85: 0.9439 - precision-0.90: 0.9627 - precision-0.95: 1.0000 - recall: 0.4763 - recall-0.55: 0.4093 - recall-0.60: 0.3464 - recall-0.65: 0.2900 - recall-0.70: 0.2394 - recall-0.75: 0.1834 - recall-0.80: 0.1244 - recall-0.85: 0.0632 - recall-0.90: 0.0132 - recall-0.95: 8.5448e-05   \n",
      "Epoch 19: val_loss did not improve from 0.62953\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.8407 - tp: 5574.0000 - fp: 2577.0000 - tn: 20829.0000 - fn: 6129.0000 - accuracy: 0.6131 - precision: 0.6838 - precision-0.55: 0.7150 - precision-0.60: 0.7545 - precision-0.65: 0.7866 - precision-0.70: 0.8280 - precision-0.75: 0.8615 - precision-0.80: 0.9010 - precision-0.85: 0.9439 - precision-0.90: 0.9627 - precision-0.95: 1.0000 - recall: 0.4763 - recall-0.55: 0.4093 - recall-0.60: 0.3464 - recall-0.65: 0.2900 - recall-0.70: 0.2394 - recall-0.75: 0.1834 - recall-0.80: 0.1244 - recall-0.85: 0.0632 - recall-0.90: 0.0132 - recall-0.95: 8.5448e-05 - val_loss: 0.6353 - val_tp: 2984.0000 - val_fp: 720.0000 - val_tn: 7082.0000 - val_fn: 917.0000 - val_accuracy: 0.7780 - val_precision: 0.8056 - val_precision-0.55: 0.8154 - val_precision-0.60: 0.8200 - val_precision-0.65: 0.8262 - val_precision-0.70: 0.8351 - val_precision-0.75: 0.8435 - val_precision-0.80: 0.8497 - val_precision-0.85: 0.8655 - val_precision-0.90: 0.8691 - val_precision-0.95: 0.5455 - val_recall: 0.7649 - val_recall-0.55: 0.7575 - val_recall-0.60: 0.7449 - val_recall-0.65: 0.7298 - val_recall-0.70: 0.7088 - val_recall-0.75: 0.6814 - val_recall-0.80: 0.6204 - val_recall-0.85: 0.5114 - val_recall-0.90: 0.2161 - val_recall-0.95: 0.0015\n",
      "Most important variables:  [577 576 578 579 708 580 569 581 570 216]\n",
      "Epoch 19: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8408 - tp: 2381.0000 - fp: 1032.0000 - tn: 6770.0000 - fn: 1520.0000 - accuracy: 0.6624 - precision: 0.6976 - precision-0.55: 0.7128 - precision-0.60: 0.7329 - precision-0.65: 0.7447 - precision-0.70: 0.7557 - precision-0.75: 0.7634 - precision-0.80: 0.7870 - precision-0.85: 0.8016 - precision-0.90: 0.7343 - precision-0.95: 0.0000e+00 - recall: 0.6104 - recall-0.55: 0.5873 - recall-0.60: 0.5634 - recall-0.65: 0.5309 - recall-0.70: 0.4876 - recall-0.75: 0.4250 - recall-0.80: 0.3391 - recall-0.85: 0.2041 - recall-0.90: 0.0510 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80      2425\n",
      "           1       0.29      0.02      0.04       710\n",
      "           2       0.50      0.32      0.39       766\n",
      "\n",
      "    accuracy                           0.66      3901\n",
      "   macro avg       0.49      0.43      0.41      3901\n",
      "weighted avg       0.58      0.66      0.58      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1   P2  Total    RP0    RP1    RP2\n",
      "0      2322   4   99   2425  0.958  0.002  0.041\n",
      "1       550  16  144    710  0.775  0.023  0.203\n",
      "2       484  36  246    766  0.632  0.047  0.321\n",
      "Total  3356  56  489   3901  0.860  0.014  0.125\n",
      "\n",
      ">>>>>> FOLD 4\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 15604, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 8646(55.41%)\n",
      "Label 1: 3369(21.59%)\n",
      "Label 2: 3589(23.0%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 2425(62.16%)\n",
      "Label 1: 710(18.2%)\n",
      "Label 2: 766(19.64%)\n",
      "\n",
      "Test:\n",
      "Label 0: 2617(67.09%)\n",
      "Label 1: 642(16.46%)\n",
      "Label 2: 642(16.46%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.6072346760172822, -0.33524614579973194, -0.2719884980652085]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0043 - tp: 8782.0000 - fp: 5643.0000 - tn: 33367.0000 - fn: 10723.0000 - accuracy: 0.5629 - precision: 0.6088 - precision-0.55: 0.6337 - precision-0.60: 0.6570 - precision-0.65: 0.6901 - precision-0.70: 0.7190 - precision-0.75: 0.7503 - precision-0.80: 0.7826 - precision-0.85: 0.8004 - precision-0.90: 0.7343 - precision-0.95: 0.0000e+00 - recall: 0.4502 - recall-0.55: 0.3872 - recall-0.60: 0.3034 - recall-0.65: 0.2216 - recall-0.70: 0.1488 - recall-0.75: 0.0995 - recall-0.80: 0.0696 - recall-0.85: 0.0409 - recall-0.90: 0.0102 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.89810, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 6s 168ms/step - loss: 1.0043 - tp: 8782.0000 - fp: 5643.0000 - tn: 33367.0000 - fn: 10723.0000 - accuracy: 0.5629 - precision: 0.6088 - precision-0.55: 0.6337 - precision-0.60: 0.6570 - precision-0.65: 0.6901 - precision-0.70: 0.7190 - precision-0.75: 0.7503 - precision-0.80: 0.7826 - precision-0.85: 0.8004 - precision-0.90: 0.7343 - precision-0.95: 0.0000e+00 - recall: 0.4502 - recall-0.55: 0.3872 - recall-0.60: 0.3034 - recall-0.65: 0.2216 - recall-0.70: 0.1488 - recall-0.75: 0.0995 - recall-0.80: 0.0696 - recall-0.85: 0.0409 - recall-0.90: 0.0102 - recall-0.95: 0.0000e+00 - val_loss: 0.8981 - val_tp: 2127.0000 - val_fp: 928.0000 - val_tn: 6874.0000 - val_fn: 1774.0000 - val_accuracy: 0.6314 - val_precision: 0.6962 - val_precision-0.55: 0.7251 - val_precision-0.60: 0.7476 - val_precision-0.65: 0.7467 - val_precision-0.70: 1.0000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5452 - val_recall-0.55: 0.4286 - val_recall-0.60: 0.2005 - val_recall-0.65: 0.0287 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.9101 - tp: 7056.0000 - fp: 3293.0000 - tn: 27427.0000 - fn: 8304.0000 - accuracy: 0.5990 - precision: 0.6818 - precision-0.55: 0.7202 - precision-0.60: 0.7584 - precision-0.65: 0.7996 - precision-0.70: 0.8334 - precision-0.75: 0.8411 - precision-0.80: 0.8828 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.4594 - recall-0.55: 0.3765 - recall-0.60: 0.2770 - recall-0.65: 0.1766 - recall-0.70: 0.0906 - recall-0.75: 0.0327 - recall-0.80: 0.0074 - recall-0.85: 3.2552e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00   \n",
      "Epoch 2: val_loss improved from 0.89810 to 0.85675, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.9097 - tp: 7175.0000 - fp: 3350.0000 - tn: 27858.0000 - fn: 8429.0000 - accuracy: 0.5992 - precision: 0.6817 - precision-0.55: 0.7198 - precision-0.60: 0.7581 - precision-0.65: 0.7995 - precision-0.70: 0.8339 - precision-0.75: 0.8459 - precision-0.80: 0.8889 - precision-0.85: 1.0000 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.4598 - recall-0.55: 0.3774 - recall-0.60: 0.2779 - recall-0.65: 0.1782 - recall-0.70: 0.0927 - recall-0.75: 0.0345 - recall-0.80: 0.0077 - recall-0.85: 3.8452e-04 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00 - val_loss: 0.8567 - val_tp: 2295.0000 - val_fp: 1031.0000 - val_tn: 6771.0000 - val_fn: 1606.0000 - val_accuracy: 0.6427 - val_precision: 0.6900 - val_precision-0.55: 0.7191 - val_precision-0.60: 0.7397 - val_precision-0.65: 0.7503 - val_precision-0.70: 0.7812 - val_precision-0.75: 0.8170 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5883 - val_recall-0.55: 0.5586 - val_recall-0.60: 0.5004 - val_recall-0.65: 0.3696 - val_recall-0.70: 0.1830 - val_recall-0.75: 0.0320 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.8636 - tp: 7648.0000 - fp: 3289.0000 - tn: 27431.0000 - fn: 7712.0000 - accuracy: 0.6184 - precision: 0.6993 - precision-0.55: 0.7340 - precision-0.60: 0.7647 - precision-0.65: 0.7955 - precision-0.70: 0.8230 - precision-0.75: 0.8581 - precision-0.80: 0.9054 - precision-0.85: 0.9507 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4979 - recall-0.55: 0.4423 - recall-0.60: 0.3766 - recall-0.65: 0.2964 - recall-0.70: 0.2077 - recall-0.75: 0.1161 - recall-0.80: 0.0449 - recall-0.85: 0.0088 - recall-0.90: 3.9063e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 0.85675 to 0.83765, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.8639 - tp: 7765.0000 - fp: 3350.0000 - tn: 27858.0000 - fn: 7839.0000 - accuracy: 0.6184 - precision: 0.6986 - precision-0.55: 0.7329 - precision-0.60: 0.7638 - precision-0.65: 0.7952 - precision-0.70: 0.8221 - precision-0.75: 0.8567 - precision-0.80: 0.9045 - precision-0.85: 0.9536 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4976 - recall-0.55: 0.4423 - recall-0.60: 0.3767 - recall-0.65: 0.2974 - recall-0.70: 0.2088 - recall-0.75: 0.1173 - recall-0.80: 0.0455 - recall-0.85: 0.0092 - recall-0.90: 5.1269e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.8377 - val_tp: 2318.0000 - val_fp: 1002.0000 - val_tn: 6800.0000 - val_fn: 1583.0000 - val_accuracy: 0.6424 - val_precision: 0.6982 - val_precision-0.55: 0.7170 - val_precision-0.60: 0.7372 - val_precision-0.65: 0.7495 - val_precision-0.70: 0.7700 - val_precision-0.75: 0.7969 - val_precision-0.80: 0.8065 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5942 - val_recall-0.55: 0.5701 - val_recall-0.60: 0.5322 - val_recall-0.65: 0.4763 - val_recall-0.70: 0.3571 - val_recall-0.75: 0.1961 - val_recall-0.80: 0.0385 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.8397 - tp: 7811.0000 - fp: 3269.0000 - tn: 27451.0000 - fn: 7549.0000 - accuracy: 0.6277 - precision: 0.7050 - precision-0.55: 0.7367 - precision-0.60: 0.7662 - precision-0.65: 0.7954 - precision-0.70: 0.8237 - precision-0.75: 0.8495 - precision-0.80: 0.8687 - precision-0.85: 0.8825 - precision-0.90: 0.9048 - precision-0.95: 0.0000e+00 - recall: 0.5085 - recall-0.55: 0.4555 - recall-0.60: 0.4018 - recall-0.65: 0.3434 - recall-0.70: 0.2749 - recall-0.75: 0.1951 - recall-0.80: 0.1060 - recall-0.85: 0.0308 - recall-0.90: 0.0025 - recall-0.95: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 0.83765 to 0.83115, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.8401 - tp: 7933.0000 - fp: 3326.0000 - tn: 27882.0000 - fn: 7671.0000 - accuracy: 0.6273 - precision: 0.7046 - precision-0.55: 0.7361 - precision-0.60: 0.7661 - precision-0.65: 0.7947 - precision-0.70: 0.8227 - precision-0.75: 0.8490 - precision-0.80: 0.8687 - precision-0.85: 0.8843 - precision-0.90: 0.9070 - precision-0.95: 0.0000e+00 - recall: 0.5084 - recall-0.55: 0.4556 - recall-0.60: 0.4019 - recall-0.65: 0.3435 - recall-0.70: 0.2751 - recall-0.75: 0.1957 - recall-0.80: 0.1064 - recall-0.85: 0.0313 - recall-0.90: 0.0025 - recall-0.95: 0.0000e+00 - val_loss: 0.8312 - val_tp: 2333.0000 - val_fp: 973.0000 - val_tn: 6829.0000 - val_fn: 1568.0000 - val_accuracy: 0.6557 - val_precision: 0.7057 - val_precision-0.55: 0.7226 - val_precision-0.60: 0.7410 - val_precision-0.65: 0.7482 - val_precision-0.70: 0.7652 - val_precision-0.75: 0.8059 - val_precision-0.80: 0.7904 - val_precision-0.85: 0.6087 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5981 - val_recall-0.55: 0.5655 - val_recall-0.60: 0.5360 - val_recall-0.65: 0.4776 - val_recall-0.70: 0.3884 - val_recall-0.75: 0.2640 - val_recall-0.80: 0.1092 - val_recall-0.85: 0.0036 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8263 - tp: 8065.0000 - fp: 3340.0000 - tn: 27868.0000 - fn: 7539.0000 - accuracy: 0.6300 - precision: 0.7071 - precision-0.55: 0.7361 - precision-0.60: 0.7642 - precision-0.65: 0.7957 - precision-0.70: 0.8229 - precision-0.75: 0.8476 - precision-0.80: 0.8707 - precision-0.85: 0.8828 - precision-0.90: 0.9048 - precision-0.95: 1.0000 - recall: 0.5169 - recall-0.55: 0.4643 - recall-0.60: 0.4121 - recall-0.65: 0.3616 - recall-0.70: 0.3043 - recall-0.75: 0.2374 - recall-0.80: 0.1532 - recall-0.85: 0.0671 - recall-0.90: 0.0110 - recall-0.95: 6.4086e-05  \n",
      "Epoch 5: val_loss improved from 0.83115 to 0.82682, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.8263 - tp: 8065.0000 - fp: 3340.0000 - tn: 27868.0000 - fn: 7539.0000 - accuracy: 0.6300 - precision: 0.7071 - precision-0.55: 0.7361 - precision-0.60: 0.7642 - precision-0.65: 0.7957 - precision-0.70: 0.8229 - precision-0.75: 0.8476 - precision-0.80: 0.8707 - precision-0.85: 0.8828 - precision-0.90: 0.9048 - precision-0.95: 1.0000 - recall: 0.5169 - recall-0.55: 0.4643 - recall-0.60: 0.4121 - recall-0.65: 0.3616 - recall-0.70: 0.3043 - recall-0.75: 0.2374 - recall-0.80: 0.1532 - recall-0.85: 0.0671 - recall-0.90: 0.0110 - recall-0.95: 6.4086e-05 - val_loss: 0.8268 - val_tp: 2309.0000 - val_fp: 945.0000 - val_tn: 6857.0000 - val_fn: 1592.0000 - val_accuracy: 0.6550 - val_precision: 0.7096 - val_precision-0.55: 0.7281 - val_precision-0.60: 0.7407 - val_precision-0.65: 0.7491 - val_precision-0.70: 0.7618 - val_precision-0.75: 0.7997 - val_precision-0.80: 0.8030 - val_precision-0.85: 0.6850 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5919 - val_recall-0.55: 0.5614 - val_recall-0.60: 0.5324 - val_recall-0.65: 0.4791 - val_recall-0.70: 0.4043 - val_recall-0.75: 0.3009 - val_recall-0.80: 0.1525 - val_recall-0.85: 0.0223 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8161 - tp: 8205.0000 - fp: 3327.0000 - tn: 27881.0000 - fn: 7399.0000 - accuracy: 0.6384 - precision: 0.7115 - precision-0.55: 0.7391 - precision-0.60: 0.7685 - precision-0.65: 0.7938 - precision-0.70: 0.8167 - precision-0.75: 0.8484 - precision-0.80: 0.8718 - precision-0.85: 0.8882 - precision-0.90: 0.8833 - precision-0.95: 1.0000 - recall: 0.5258 - recall-0.55: 0.4753 - recall-0.60: 0.4253 - recall-0.65: 0.3772 - recall-0.70: 0.3227 - recall-0.75: 0.2651 - recall-0.80: 0.1866 - recall-0.85: 0.0962 - recall-0.90: 0.0204 - recall-0.95: 1.9226e-04\n",
      "Epoch 6: val_loss improved from 0.82682 to 0.82395, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.8161 - tp: 8205.0000 - fp: 3327.0000 - tn: 27881.0000 - fn: 7399.0000 - accuracy: 0.6384 - precision: 0.7115 - precision-0.55: 0.7391 - precision-0.60: 0.7685 - precision-0.65: 0.7938 - precision-0.70: 0.8167 - precision-0.75: 0.8484 - precision-0.80: 0.8718 - precision-0.85: 0.8882 - precision-0.90: 0.8833 - precision-0.95: 1.0000 - recall: 0.5258 - recall-0.55: 0.4753 - recall-0.60: 0.4253 - recall-0.65: 0.3772 - recall-0.70: 0.3227 - recall-0.75: 0.2651 - recall-0.80: 0.1866 - recall-0.85: 0.0962 - recall-0.90: 0.0204 - recall-0.95: 1.9226e-04 - val_loss: 0.8240 - val_tp: 2302.0000 - val_fp: 941.0000 - val_tn: 6861.0000 - val_fn: 1599.0000 - val_accuracy: 0.6585 - val_precision: 0.7098 - val_precision-0.55: 0.7303 - val_precision-0.60: 0.7443 - val_precision-0.65: 0.7522 - val_precision-0.70: 0.7612 - val_precision-0.75: 0.7966 - val_precision-0.80: 0.8162 - val_precision-0.85: 0.7035 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5901 - val_recall-0.55: 0.5581 - val_recall-0.60: 0.5283 - val_recall-0.65: 0.4771 - val_recall-0.70: 0.4045 - val_recall-0.75: 0.3163 - val_recall-0.80: 0.1787 - val_recall-0.85: 0.0359 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8119 - tp: 8227.0000 - fp: 3383.0000 - tn: 27825.0000 - fn: 7377.0000 - accuracy: 0.6424 - precision: 0.7086 - precision-0.55: 0.7396 - precision-0.60: 0.7678 - precision-0.65: 0.7987 - precision-0.70: 0.8244 - precision-0.75: 0.8484 - precision-0.80: 0.8712 - precision-0.85: 0.8768 - precision-0.90: 0.8776 - precision-0.95: 0.6667 - recall: 0.5272 - recall-0.55: 0.4783 - recall-0.60: 0.4323 - recall-0.65: 0.3853 - recall-0.70: 0.3337 - recall-0.75: 0.2741 - recall-0.80: 0.2016 - recall-0.85: 0.1136 - recall-0.90: 0.0294 - recall-0.95: 2.5634e-04\n",
      "Epoch 7: val_loss improved from 0.82395 to 0.82165, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.8119 - tp: 8227.0000 - fp: 3383.0000 - tn: 27825.0000 - fn: 7377.0000 - accuracy: 0.6424 - precision: 0.7086 - precision-0.55: 0.7396 - precision-0.60: 0.7678 - precision-0.65: 0.7987 - precision-0.70: 0.8244 - precision-0.75: 0.8484 - precision-0.80: 0.8712 - precision-0.85: 0.8768 - precision-0.90: 0.8776 - precision-0.95: 0.6667 - recall: 0.5272 - recall-0.55: 0.4783 - recall-0.60: 0.4323 - recall-0.65: 0.3853 - recall-0.70: 0.3337 - recall-0.75: 0.2741 - recall-0.80: 0.2016 - recall-0.85: 0.1136 - recall-0.90: 0.0294 - recall-0.95: 2.5634e-04 - val_loss: 0.8217 - val_tp: 2269.0000 - val_fp: 906.0000 - val_tn: 6896.0000 - val_fn: 1632.0000 - val_accuracy: 0.6575 - val_precision: 0.7146 - val_precision-0.55: 0.7372 - val_precision-0.60: 0.7497 - val_precision-0.65: 0.7547 - val_precision-0.70: 0.7695 - val_precision-0.75: 0.8045 - val_precision-0.80: 0.8166 - val_precision-0.85: 0.6494 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5816 - val_recall-0.55: 0.5509 - val_recall-0.60: 0.5153 - val_recall-0.65: 0.4558 - val_recall-0.70: 0.3850 - val_recall-0.75: 0.2943 - val_recall-0.80: 0.1610 - val_recall-0.85: 0.0256 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.8091 - tp: 8165.0000 - fp: 3312.0000 - tn: 27408.0000 - fn: 7195.0000 - accuracy: 0.6410 - precision: 0.7114 - precision-0.55: 0.7417 - precision-0.60: 0.7686 - precision-0.65: 0.7949 - precision-0.70: 0.8189 - precision-0.75: 0.8486 - precision-0.80: 0.8681 - precision-0.85: 0.8870 - precision-0.90: 0.8872 - precision-0.95: 0.7500 - recall: 0.5316 - recall-0.55: 0.4780 - recall-0.60: 0.4280 - recall-0.65: 0.3795 - recall-0.70: 0.3309 - recall-0.75: 0.2738 - recall-0.80: 0.2018 - recall-0.85: 0.1191 - recall-0.90: 0.0312 - recall-0.95: 3.9063e-04\n",
      "Epoch 8: val_loss did not improve from 0.82165\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.8082 - tp: 8303.0000 - fp: 3358.0000 - tn: 27850.0000 - fn: 7301.0000 - accuracy: 0.6423 - precision: 0.7120 - precision-0.55: 0.7420 - precision-0.60: 0.7692 - precision-0.65: 0.7954 - precision-0.70: 0.8191 - precision-0.75: 0.8486 - precision-0.80: 0.8676 - precision-0.85: 0.8872 - precision-0.90: 0.8883 - precision-0.95: 0.7500 - recall: 0.5321 - recall-0.55: 0.4782 - recall-0.60: 0.4281 - recall-0.65: 0.3798 - recall-0.70: 0.3313 - recall-0.75: 0.2741 - recall-0.80: 0.2021 - recall-0.85: 0.1195 - recall-0.90: 0.0316 - recall-0.95: 3.8452e-04 - val_loss: 0.8235 - val_tp: 2309.0000 - val_fp: 937.0000 - val_tn: 6865.0000 - val_fn: 1592.0000 - val_accuracy: 0.6575 - val_precision: 0.7113 - val_precision-0.55: 0.7319 - val_precision-0.60: 0.7484 - val_precision-0.65: 0.7536 - val_precision-0.70: 0.7672 - val_precision-0.75: 0.8031 - val_precision-0.80: 0.8190 - val_precision-0.85: 0.7227 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5919 - val_recall-0.55: 0.5570 - val_recall-0.60: 0.5224 - val_recall-0.65: 0.4665 - val_recall-0.70: 0.3912 - val_recall-0.75: 0.3063 - val_recall-0.80: 0.1787 - val_recall-0.85: 0.0441 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8070 - tp: 8269.0000 - fp: 3328.0000 - tn: 27880.0000 - fn: 7335.0000 - accuracy: 0.6425 - precision: 0.7130 - precision-0.55: 0.7435 - precision-0.60: 0.7735 - precision-0.65: 0.7987 - precision-0.70: 0.8230 - precision-0.75: 0.8496 - precision-0.80: 0.8720 - precision-0.85: 0.8925 - precision-0.90: 0.8889 - precision-0.95: 0.5833 - recall: 0.5299 - recall-0.55: 0.4756 - recall-0.60: 0.4303 - recall-0.65: 0.3825 - recall-0.70: 0.3327 - recall-0.75: 0.2747 - recall-0.80: 0.2070 - recall-0.85: 0.1229 - recall-0.90: 0.0344 - recall-0.95: 4.4860e-04\n",
      "Epoch 9: val_loss did not improve from 0.82165\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.8070 - tp: 8269.0000 - fp: 3328.0000 - tn: 27880.0000 - fn: 7335.0000 - accuracy: 0.6425 - precision: 0.7130 - precision-0.55: 0.7435 - precision-0.60: 0.7735 - precision-0.65: 0.7987 - precision-0.70: 0.8230 - precision-0.75: 0.8496 - precision-0.80: 0.8720 - precision-0.85: 0.8925 - precision-0.90: 0.8889 - precision-0.95: 0.5833 - recall: 0.5299 - recall-0.55: 0.4756 - recall-0.60: 0.4303 - recall-0.65: 0.3825 - recall-0.70: 0.3327 - recall-0.75: 0.2747 - recall-0.80: 0.2070 - recall-0.85: 0.1229 - recall-0.90: 0.0344 - recall-0.95: 4.4860e-04 - val_loss: 0.8230 - val_tp: 2301.0000 - val_fp: 931.0000 - val_tn: 6871.0000 - val_fn: 1600.0000 - val_accuracy: 0.6578 - val_precision: 0.7119 - val_precision-0.55: 0.7328 - val_precision-0.60: 0.7479 - val_precision-0.65: 0.7534 - val_precision-0.70: 0.7605 - val_precision-0.75: 0.7935 - val_precision-0.80: 0.8099 - val_precision-0.85: 0.7769 - val_precision-0.90: 0.2500 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5898 - val_recall-0.55: 0.5609 - val_recall-0.60: 0.5247 - val_recall-0.65: 0.4786 - val_recall-0.70: 0.4071 - val_recall-0.75: 0.3320 - val_recall-0.80: 0.2130 - val_recall-0.85: 0.0723 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.8047 - tp: 8153.0000 - fp: 3272.0000 - tn: 27448.0000 - fn: 7207.0000 - accuracy: 0.6436 - precision: 0.7136 - precision-0.55: 0.7416 - precision-0.60: 0.7708 - precision-0.65: 0.8001 - precision-0.70: 0.8217 - precision-0.75: 0.8452 - precision-0.80: 0.8730 - precision-0.85: 0.8903 - precision-0.90: 0.8783 - precision-0.95: 0.5714 - recall: 0.5308 - recall-0.55: 0.4787 - recall-0.60: 0.4324 - recall-0.65: 0.3844 - recall-0.70: 0.3354 - recall-0.75: 0.2788 - recall-0.80: 0.2108 - recall-0.85: 0.1236 - recall-0.90: 0.0343 - recall-0.95: 5.2083e-04\n",
      "Epoch 10: val_loss improved from 0.82165 to 0.82113, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.8044 - tp: 8282.0000 - fp: 3315.0000 - tn: 27893.0000 - fn: 7322.0000 - accuracy: 0.6438 - precision: 0.7142 - precision-0.55: 0.7422 - precision-0.60: 0.7715 - precision-0.65: 0.8007 - precision-0.70: 0.8225 - precision-0.75: 0.8455 - precision-0.80: 0.8729 - precision-0.85: 0.8906 - precision-0.90: 0.8787 - precision-0.95: 0.5714 - recall: 0.5308 - recall-0.55: 0.4787 - recall-0.60: 0.4326 - recall-0.65: 0.3850 - recall-0.70: 0.3364 - recall-0.75: 0.2792 - recall-0.80: 0.2112 - recall-0.85: 0.1237 - recall-0.90: 0.0344 - recall-0.95: 5.1269e-04 - val_loss: 0.8211 - val_tp: 2313.0000 - val_fp: 930.0000 - val_tn: 6872.0000 - val_fn: 1588.0000 - val_accuracy: 0.6550 - val_precision: 0.7132 - val_precision-0.55: 0.7344 - val_precision-0.60: 0.7470 - val_precision-0.65: 0.7542 - val_precision-0.70: 0.7633 - val_precision-0.75: 0.7930 - val_precision-0.80: 0.8117 - val_precision-0.85: 0.7853 - val_precision-0.90: 0.4286 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5929 - val_recall-0.55: 0.5614 - val_recall-0.60: 0.5260 - val_recall-0.65: 0.4750 - val_recall-0.70: 0.4091 - val_recall-0.75: 0.3379 - val_recall-0.80: 0.2176 - val_recall-0.85: 0.0769 - val_recall-0.90: 7.6903e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8011 - tp: 8388.0000 - fp: 3331.0000 - tn: 27877.0000 - fn: 7216.0000 - accuracy: 0.6476 - precision: 0.7158 - precision-0.55: 0.7439 - precision-0.60: 0.7702 - precision-0.65: 0.7958 - precision-0.70: 0.8226 - precision-0.75: 0.8520 - precision-0.80: 0.8734 - precision-0.85: 0.8970 - precision-0.90: 0.8955 - precision-0.95: 0.5000 - recall: 0.5376 - recall-0.55: 0.4884 - recall-0.60: 0.4396 - recall-0.65: 0.3903 - recall-0.70: 0.3394 - recall-0.75: 0.2863 - recall-0.80: 0.2154 - recall-0.85: 0.1305 - recall-0.90: 0.0385 - recall-0.95: 1.2817e-04\n",
      "Epoch 11: val_loss improved from 0.82113 to 0.82008, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154550.h5\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.8011 - tp: 8388.0000 - fp: 3331.0000 - tn: 27877.0000 - fn: 7216.0000 - accuracy: 0.6476 - precision: 0.7158 - precision-0.55: 0.7439 - precision-0.60: 0.7702 - precision-0.65: 0.7958 - precision-0.70: 0.8226 - precision-0.75: 0.8520 - precision-0.80: 0.8734 - precision-0.85: 0.8970 - precision-0.90: 0.8955 - precision-0.95: 0.5000 - recall: 0.5376 - recall-0.55: 0.4884 - recall-0.60: 0.4396 - recall-0.65: 0.3903 - recall-0.70: 0.3394 - recall-0.75: 0.2863 - recall-0.80: 0.2154 - recall-0.85: 0.1305 - recall-0.90: 0.0385 - recall-0.95: 1.2817e-04 - val_loss: 0.8201 - val_tp: 2293.0000 - val_fp: 906.0000 - val_tn: 6896.0000 - val_fn: 1608.0000 - val_accuracy: 0.6552 - val_precision: 0.7168 - val_precision-0.55: 0.7357 - val_precision-0.60: 0.7518 - val_precision-0.65: 0.7558 - val_precision-0.70: 0.7692 - val_precision-0.75: 0.7981 - val_precision-0.80: 0.8182 - val_precision-0.85: 0.7761 - val_precision-0.90: 0.5000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5878 - val_recall-0.55: 0.5537 - val_recall-0.60: 0.5147 - val_recall-0.65: 0.4563 - val_recall-0.70: 0.3948 - val_recall-0.75: 0.3202 - val_recall-0.80: 0.2030 - val_recall-0.85: 0.0649 - val_recall-0.90: 5.1269e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 12/200\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.7976 - tp: 8212.0000 - fp: 3253.0000 - tn: 27467.0000 - fn: 7148.0000 - accuracy: 0.6504 - precision: 0.7163 - precision-0.55: 0.7489 - precision-0.60: 0.7759 - precision-0.65: 0.8025 - precision-0.70: 0.8256 - precision-0.75: 0.8518 - precision-0.80: 0.8772 - precision-0.85: 0.8934 - precision-0.90: 0.8744 - precision-0.95: 0.4286 - recall: 0.5346 - recall-0.55: 0.4819 - recall-0.60: 0.4312 - recall-0.65: 0.3844 - recall-0.70: 0.3351 - recall-0.75: 0.2796 - recall-0.80: 0.2158 - recall-0.85: 0.1321 - recall-0.90: 0.0381 - recall-0.95: 1.9531e-04\n",
      "Epoch 12: val_loss did not improve from 0.82008\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.7975 - tp: 8351.0000 - fp: 3302.0000 - tn: 27906.0000 - fn: 7253.0000 - accuracy: 0.6503 - precision: 0.7166 - precision-0.55: 0.7495 - precision-0.60: 0.7762 - precision-0.65: 0.8026 - precision-0.70: 0.8258 - precision-0.75: 0.8517 - precision-0.80: 0.8767 - precision-0.85: 0.8922 - precision-0.90: 0.8759 - precision-0.95: 0.4286 - recall: 0.5352 - recall-0.55: 0.4826 - recall-0.60: 0.4320 - recall-0.65: 0.3853 - recall-0.70: 0.3357 - recall-0.75: 0.2805 - recall-0.80: 0.2165 - recall-0.85: 0.1327 - recall-0.90: 0.0385 - recall-0.95: 1.9226e-04 - val_loss: 0.8216 - val_tp: 2316.0000 - val_fp: 923.0000 - val_tn: 6879.0000 - val_fn: 1585.0000 - val_accuracy: 0.6580 - val_precision: 0.7150 - val_precision-0.55: 0.7340 - val_precision-0.60: 0.7478 - val_precision-0.65: 0.7531 - val_precision-0.70: 0.7635 - val_precision-0.75: 0.7928 - val_precision-0.80: 0.8049 - val_precision-0.85: 0.7900 - val_precision-0.90: 0.4118 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5937 - val_recall-0.55: 0.5609 - val_recall-0.60: 0.5252 - val_recall-0.65: 0.4699 - val_recall-0.70: 0.4096 - val_recall-0.75: 0.3394 - val_recall-0.80: 0.2253 - val_recall-0.85: 0.0887 - val_recall-0.90: 0.0018 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7971 - tp: 8387.0000 - fp: 3307.0000 - tn: 27901.0000 - fn: 7217.0000 - accuracy: 0.6496 - precision: 0.7172 - precision-0.55: 0.7474 - precision-0.60: 0.7751 - precision-0.65: 0.7987 - precision-0.70: 0.8249 - precision-0.75: 0.8500 - precision-0.80: 0.8788 - precision-0.85: 0.8904 - precision-0.90: 0.8781 - precision-0.95: 0.9000 - recall: 0.5375 - recall-0.55: 0.4863 - recall-0.60: 0.4387 - recall-0.65: 0.3895 - recall-0.70: 0.3397 - recall-0.75: 0.2862 - recall-0.80: 0.2203 - recall-0.85: 0.1390 - recall-0.90: 0.0425 - recall-0.95: 5.7678e-04\n",
      "Epoch 13: val_loss did not improve from 0.82008\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.7971 - tp: 8387.0000 - fp: 3307.0000 - tn: 27901.0000 - fn: 7217.0000 - accuracy: 0.6496 - precision: 0.7172 - precision-0.55: 0.7474 - precision-0.60: 0.7751 - precision-0.65: 0.7987 - precision-0.70: 0.8249 - precision-0.75: 0.8500 - precision-0.80: 0.8788 - precision-0.85: 0.8904 - precision-0.90: 0.8781 - precision-0.95: 0.9000 - recall: 0.5375 - recall-0.55: 0.4863 - recall-0.60: 0.4387 - recall-0.65: 0.3895 - recall-0.70: 0.3397 - recall-0.75: 0.2862 - recall-0.80: 0.2203 - recall-0.85: 0.1390 - recall-0.90: 0.0425 - recall-0.95: 5.7678e-04 - val_loss: 0.8220 - val_tp: 2280.0000 - val_fp: 892.0000 - val_tn: 6910.0000 - val_fn: 1621.0000 - val_accuracy: 0.6580 - val_precision: 0.7188 - val_precision-0.55: 0.7386 - val_precision-0.60: 0.7518 - val_precision-0.65: 0.7563 - val_precision-0.70: 0.7832 - val_precision-0.75: 0.7977 - val_precision-0.80: 0.8204 - val_precision-0.85: 0.7452 - val_precision-0.90: 0.3333 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5845 - val_recall-0.55: 0.5455 - val_recall-0.60: 0.4978 - val_recall-0.65: 0.4327 - val_recall-0.70: 0.3761 - val_recall-0.75: 0.2902 - val_recall-0.80: 0.1756 - val_recall-0.85: 0.0502 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7946 - tp: 8370.0000 - fp: 3185.0000 - tn: 28023.0000 - fn: 7234.0000 - accuracy: 0.6483 - precision: 0.7244 - precision-0.55: 0.7540 - precision-0.60: 0.7776 - precision-0.65: 0.8030 - precision-0.70: 0.8307 - precision-0.75: 0.8537 - precision-0.80: 0.8762 - precision-0.85: 0.8933 - precision-0.90: 0.8905 - precision-0.95: 0.5000 - recall: 0.5364 - recall-0.55: 0.4835 - recall-0.60: 0.4307 - recall-0.65: 0.3832 - recall-0.70: 0.3327 - recall-0.75: 0.2763 - recall-0.80: 0.2113 - recall-0.85: 0.1299 - recall-0.90: 0.0365 - recall-0.95: 3.2043e-04\n",
      "Epoch 14: val_loss did not improve from 0.82008\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.7946 - tp: 8370.0000 - fp: 3185.0000 - tn: 28023.0000 - fn: 7234.0000 - accuracy: 0.6483 - precision: 0.7244 - precision-0.55: 0.7540 - precision-0.60: 0.7776 - precision-0.65: 0.8030 - precision-0.70: 0.8307 - precision-0.75: 0.8537 - precision-0.80: 0.8762 - precision-0.85: 0.8933 - precision-0.90: 0.8905 - precision-0.95: 0.5000 - recall: 0.5364 - recall-0.55: 0.4835 - recall-0.60: 0.4307 - recall-0.65: 0.3832 - recall-0.70: 0.3327 - recall-0.75: 0.2763 - recall-0.80: 0.2113 - recall-0.85: 0.1299 - recall-0.90: 0.0365 - recall-0.95: 3.2043e-04 - val_loss: 0.8219 - val_tp: 2335.0000 - val_fp: 925.0000 - val_tn: 6877.0000 - val_fn: 1566.0000 - val_accuracy: 0.6583 - val_precision: 0.7163 - val_precision-0.55: 0.7328 - val_precision-0.60: 0.7506 - val_precision-0.65: 0.7530 - val_precision-0.70: 0.7671 - val_precision-0.75: 0.7947 - val_precision-0.80: 0.8104 - val_precision-0.85: 0.8075 - val_precision-0.90: 0.3125 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5986 - val_recall-0.55: 0.5617 - val_recall-0.60: 0.5255 - val_recall-0.65: 0.4635 - val_recall-0.70: 0.4053 - val_recall-0.75: 0.3335 - val_recall-0.80: 0.2246 - val_recall-0.85: 0.0882 - val_recall-0.90: 0.0013 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7919 - tp: 8415.0000 - fp: 3268.0000 - tn: 27940.0000 - fn: 7189.0000 - accuracy: 0.6518 - precision: 0.7203 - precision-0.55: 0.7495 - precision-0.60: 0.7783 - precision-0.65: 0.8057 - precision-0.70: 0.8305 - precision-0.75: 0.8573 - precision-0.80: 0.8824 - precision-0.85: 0.8937 - precision-0.90: 0.8645 - precision-0.95: 0.5000 - recall: 0.5393 - recall-0.55: 0.4885 - recall-0.60: 0.4394 - recall-0.65: 0.3905 - recall-0.70: 0.3441 - recall-0.75: 0.2883 - recall-0.80: 0.2221 - recall-0.85: 0.1412 - recall-0.90: 0.0397 - recall-0.95: 2.5634e-04\n",
      "Epoch 15: val_loss did not improve from 0.82008\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.7919 - tp: 8415.0000 - fp: 3268.0000 - tn: 27940.0000 - fn: 7189.0000 - accuracy: 0.6518 - precision: 0.7203 - precision-0.55: 0.7495 - precision-0.60: 0.7783 - precision-0.65: 0.8057 - precision-0.70: 0.8305 - precision-0.75: 0.8573 - precision-0.80: 0.8824 - precision-0.85: 0.8937 - precision-0.90: 0.8645 - precision-0.95: 0.5000 - recall: 0.5393 - recall-0.55: 0.4885 - recall-0.60: 0.4394 - recall-0.65: 0.3905 - recall-0.70: 0.3441 - recall-0.75: 0.2883 - recall-0.80: 0.2221 - recall-0.85: 0.1412 - recall-0.90: 0.0397 - recall-0.95: 2.5634e-04 - val_loss: 0.8216 - val_tp: 2328.0000 - val_fp: 914.0000 - val_tn: 6888.0000 - val_fn: 1573.0000 - val_accuracy: 0.6580 - val_precision: 0.7181 - val_precision-0.55: 0.7330 - val_precision-0.60: 0.7511 - val_precision-0.65: 0.7565 - val_precision-0.70: 0.7715 - val_precision-0.75: 0.7963 - val_precision-0.80: 0.8086 - val_precision-0.85: 0.7995 - val_precision-0.90: 0.3333 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5968 - val_recall-0.55: 0.5573 - val_recall-0.60: 0.5191 - val_recall-0.65: 0.4596 - val_recall-0.70: 0.4007 - val_recall-0.75: 0.3238 - val_recall-0.80: 0.2176 - val_recall-0.85: 0.0849 - val_recall-0.90: 0.0015 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7895 - tp: 8527.0000 - fp: 3294.0000 - tn: 27914.0000 - fn: 7077.0000 - accuracy: 0.6541 - precision: 0.7213 - precision-0.55: 0.7505 - precision-0.60: 0.7763 - precision-0.65: 0.8049 - precision-0.70: 0.8314 - precision-0.75: 0.8523 - precision-0.80: 0.8756 - precision-0.85: 0.8949 - precision-0.90: 0.8921 - precision-0.95: 0.6500 - recall: 0.5465 - recall-0.55: 0.4938 - recall-0.60: 0.4417 - recall-0.65: 0.3911 - recall-0.70: 0.3433 - recall-0.75: 0.2892 - recall-0.80: 0.2241 - recall-0.85: 0.1440 - recall-0.90: 0.0440 - recall-0.95: 8.3312e-04\n",
      "Epoch 16: val_loss did not improve from 0.82008\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.7895 - tp: 8527.0000 - fp: 3294.0000 - tn: 27914.0000 - fn: 7077.0000 - accuracy: 0.6541 - precision: 0.7213 - precision-0.55: 0.7505 - precision-0.60: 0.7763 - precision-0.65: 0.8049 - precision-0.70: 0.8314 - precision-0.75: 0.8523 - precision-0.80: 0.8756 - precision-0.85: 0.8949 - precision-0.90: 0.8921 - precision-0.95: 0.6500 - recall: 0.5465 - recall-0.55: 0.4938 - recall-0.60: 0.4417 - recall-0.65: 0.3911 - recall-0.70: 0.3433 - recall-0.75: 0.2892 - recall-0.80: 0.2241 - recall-0.85: 0.1440 - recall-0.90: 0.0440 - recall-0.95: 8.3312e-04 - val_loss: 0.8205 - val_tp: 2276.0000 - val_fp: 882.0000 - val_tn: 6920.0000 - val_fn: 1625.0000 - val_accuracy: 0.6552 - val_precision: 0.7207 - val_precision-0.55: 0.7394 - val_precision-0.60: 0.7512 - val_precision-0.65: 0.7611 - val_precision-0.70: 0.7898 - val_precision-0.75: 0.7989 - val_precision-0.80: 0.8211 - val_precision-0.85: 0.7698 - val_precision-0.90: 0.2500 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5834 - val_recall-0.55: 0.5411 - val_recall-0.60: 0.4876 - val_recall-0.65: 0.4289 - val_recall-0.70: 0.3709 - val_recall-0.75: 0.2871 - val_recall-0.80: 0.1812 - val_recall-0.85: 0.0574 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [577 576 579 578 581 580 582 583 584 708]\n",
      "Epoch 16: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7874 - tp: 2641.0000 - fp: 1000.0000 - tn: 6802.0000 - fn: 1260.0000 - accuracy: 0.7067 - precision: 0.7254 - precision-0.55: 0.7291 - precision-0.60: 0.7293 - precision-0.65: 0.7383 - precision-0.70: 0.7438 - precision-0.75: 0.7728 - precision-0.80: 0.7724 - precision-0.85: 0.7963 - precision-0.90: 0.8243 - precision-0.95: 0.0000e+00 - recall: 0.6770 - recall-0.55: 0.6568 - recall-0.60: 0.6319 - recall-0.65: 0.6088 - recall-0.70: 0.5701 - recall-0.75: 0.5268 - recall-0.80: 0.4212 - recall-0.85: 0.2556 - recall-0.90: 0.0469 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83      2617\n",
      "           1       0.61      0.09      0.16       642\n",
      "           2       0.54      0.14      0.22       642\n",
      "\n",
      "    accuracy                           0.71      3901\n",
      "   macro avg       0.62      0.41      0.41      3901\n",
      "weighted avg       0.67      0.71      0.62      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1   P2  Total    RP0    RP1    RP2\n",
      "0      2608   2    7   2617  0.997  0.001  0.003\n",
      "1       513  60   69    642  0.799  0.093  0.107\n",
      "2       517  36   89    642  0.805  0.056  0.139\n",
      "Total  3638  98  165   3901  0.933  0.025  0.042\n",
      "\n",
      ">>>>>> FOLD 5\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 19505, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 11071(56.76%)\n",
      "Label 1: 4079(20.91%)\n",
      "Label 2: 4355(22.33%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 2617(67.09%)\n",
      "Label 1: 642(16.46%)\n",
      "Label 2: 642(16.46%)\n",
      "\n",
      "Test:\n",
      "Label 0: 3107(79.65%)\n",
      "Label 1: 347(8.9%)\n",
      "Label 2: 447(11.46%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.6438272488252699, -0.3546499677169948, -0.28917721774624233]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "18/20 [==========================>...] - ETA: 0s - loss: 0.9895 - tp: 10720.0000 - fp: 6546.0000 - tn: 38120.0000 - fn: 11613.0000 - accuracy: 0.5828 - precision: 0.6209 - precision-0.55: 0.6356 - precision-0.60: 0.6576 - precision-0.65: 0.6800 - precision-0.70: 0.7038 - precision-0.75: 0.7492 - precision-0.80: 0.7637 - precision-0.85: 0.7968 - precision-0.90: 0.8243 - precision-0.95: 0.0000e+00 - recall: 0.4800 - recall-0.55: 0.4133 - recall-0.60: 0.3322 - recall-0.65: 0.2437 - recall-0.70: 0.1615 - recall-0.75: 0.1106 - recall-0.80: 0.0764 - recall-0.85: 0.0448 - recall-0.90: 0.0082 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.85568, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154612.h5\n",
      "20/20 [==============================] - 5s 137ms/step - loss: 0.9866 - tp: 11161.0000 - fp: 6761.0000 - tn: 40051.0000 - fn: 12245.0000 - accuracy: 0.5828 - precision: 0.6228 - precision-0.55: 0.6383 - precision-0.60: 0.6597 - precision-0.65: 0.6820 - precision-0.70: 0.7047 - precision-0.75: 0.7495 - precision-0.80: 0.7638 - precision-0.85: 0.7968 - precision-0.90: 0.8243 - precision-0.95: 0.0000e+00 - recall: 0.4768 - recall-0.55: 0.4082 - recall-0.60: 0.3255 - recall-0.65: 0.2369 - recall-0.70: 0.1553 - recall-0.75: 0.1058 - recall-0.80: 0.0729 - recall-0.85: 0.0427 - recall-0.90: 0.0078 - recall-0.95: 0.0000e+00 - val_loss: 0.8557 - val_tp: 2203.0000 - val_fp: 783.0000 - val_tn: 7019.0000 - val_fn: 1698.0000 - val_accuracy: 0.6901 - val_precision: 0.7378 - val_precision-0.55: 0.7600 - val_precision-0.60: 0.7476 - val_precision-0.65: 0.7340 - val_precision-0.70: 1.0000 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5647 - val_recall-0.55: 0.4002 - val_recall-0.60: 0.1625 - val_recall-0.65: 0.0177 - val_recall-0.70: 2.5634e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9012 - tp: 9433.0000 - fp: 4447.0000 - tn: 34563.0000 - fn: 10072.0000 - accuracy: 0.6057 - precision: 0.6796 - precision-0.55: 0.7110 - precision-0.60: 0.7363 - precision-0.65: 0.7615 - precision-0.70: 0.7938 - precision-0.75: 0.8241 - precision-0.80: 0.8416 - precision-0.85: 0.8784 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4836 - recall-0.55: 0.4116 - recall-0.60: 0.3231 - recall-0.65: 0.2341 - recall-0.70: 0.1480 - recall-0.75: 0.0737 - recall-0.80: 0.0234 - recall-0.85: 0.0033 - recall-0.90: 5.1269e-05 - recall-0.95: 0.0000e+00         \n",
      "Epoch 2: val_loss improved from 0.85568 to 0.79738, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154612.h5\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.9012 - tp: 9433.0000 - fp: 4447.0000 - tn: 34563.0000 - fn: 10072.0000 - accuracy: 0.6057 - precision: 0.6796 - precision-0.55: 0.7110 - precision-0.60: 0.7363 - precision-0.65: 0.7615 - precision-0.70: 0.7938 - precision-0.75: 0.8241 - precision-0.80: 0.8416 - precision-0.85: 0.8784 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4836 - recall-0.55: 0.4116 - recall-0.60: 0.3231 - recall-0.65: 0.2341 - recall-0.70: 0.1480 - recall-0.75: 0.0737 - recall-0.80: 0.0234 - recall-0.85: 0.0033 - recall-0.90: 5.1269e-05 - recall-0.95: 0.0000e+00 - val_loss: 0.7974 - val_tp: 2598.0000 - val_fp: 1028.0000 - val_tn: 6774.0000 - val_fn: 1303.0000 - val_accuracy: 0.6934 - val_precision: 0.7165 - val_precision-0.55: 0.7280 - val_precision-0.60: 0.7382 - val_precision-0.65: 0.7596 - val_precision-0.70: 0.7815 - val_precision-0.75: 0.7642 - val_precision-0.80: 0.8000 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6660 - val_recall-0.55: 0.6380 - val_recall-0.60: 0.5855 - val_recall-0.65: 0.4924 - val_recall-0.70: 0.3320 - val_recall-0.75: 0.1105 - val_recall-0.80: 0.0041 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8556 - tp: 10068.0000 - fp: 4343.0000 - tn: 34667.0000 - fn: 9437.0000 - accuracy: 0.6236 - precision: 0.6986 - precision-0.55: 0.7298 - precision-0.60: 0.7592 - precision-0.65: 0.7830 - precision-0.70: 0.8095 - precision-0.75: 0.8441 - precision-0.80: 0.8650 - precision-0.85: 0.8852 - precision-0.90: 0.6000 - precision-0.95: 0.0000e+00 - recall: 0.5162 - recall-0.55: 0.4658 - recall-0.60: 0.4062 - recall-0.65: 0.3303 - recall-0.70: 0.2385 - recall-0.75: 0.1407 - recall-0.80: 0.0575 - recall-0.85: 0.0111 - recall-0.90: 1.5381e-04 - recall-0.95: 0.0000e+00 \n",
      "Epoch 3: val_loss improved from 0.79738 to 0.78760, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154612.h5\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.8556 - tp: 10068.0000 - fp: 4343.0000 - tn: 34667.0000 - fn: 9437.0000 - accuracy: 0.6236 - precision: 0.6986 - precision-0.55: 0.7298 - precision-0.60: 0.7592 - precision-0.65: 0.7830 - precision-0.70: 0.8095 - precision-0.75: 0.8441 - precision-0.80: 0.8650 - precision-0.85: 0.8852 - precision-0.90: 0.6000 - precision-0.95: 0.0000e+00 - recall: 0.5162 - recall-0.55: 0.4658 - recall-0.60: 0.4062 - recall-0.65: 0.3303 - recall-0.70: 0.2385 - recall-0.75: 0.1407 - recall-0.80: 0.0575 - recall-0.85: 0.0111 - recall-0.90: 1.5381e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.7876 - val_tp: 2596.0000 - val_fp: 1012.0000 - val_tn: 6790.0000 - val_fn: 1305.0000 - val_accuracy: 0.6993 - val_precision: 0.7195 - val_precision-0.55: 0.7316 - val_precision-0.60: 0.7338 - val_precision-0.65: 0.7453 - val_precision-0.70: 0.7692 - val_precision-0.75: 0.7805 - val_precision-0.80: 0.7667 - val_precision-0.85: 0.5385 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6655 - val_recall-0.55: 0.6457 - val_recall-0.60: 0.6114 - val_recall-0.65: 0.5542 - val_recall-0.70: 0.4563 - val_recall-0.75: 0.2989 - val_recall-0.80: 0.0884 - val_recall-0.85: 0.0018 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8359 - tp: 10135.0000 - fp: 4249.0000 - tn: 34663.0000 - fn: 9321.0000 - accuracy: 0.6322 - precision: 0.7046 - precision-0.55: 0.7369 - precision-0.60: 0.7639 - precision-0.65: 0.7879 - precision-0.70: 0.8102 - precision-0.75: 0.8330 - precision-0.80: 0.8581 - precision-0.85: 0.8923 - precision-0.90: 0.9245 - precision-0.95: 0.0000e+00 - recall: 0.5209 - recall-0.55: 0.4717 - recall-0.60: 0.4190 - recall-0.65: 0.3594 - recall-0.70: 0.2872 - recall-0.75: 0.1999 - recall-0.80: 0.1088 - recall-0.85: 0.0341 - recall-0.90: 0.0025 - recall-0.95: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 0.78760 to 0.78563, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154612.h5\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.8361 - tp: 10155.0000 - fp: 4261.0000 - tn: 34749.0000 - fn: 9350.0000 - accuracy: 0.6319 - precision: 0.7044 - precision-0.55: 0.7369 - precision-0.60: 0.7639 - precision-0.65: 0.7878 - precision-0.70: 0.8100 - precision-0.75: 0.8328 - precision-0.80: 0.8580 - precision-0.85: 0.8923 - precision-0.90: 0.9245 - precision-0.95: 0.0000e+00 - recall: 0.5206 - recall-0.55: 0.4714 - recall-0.60: 0.4188 - recall-0.65: 0.3592 - recall-0.70: 0.2871 - recall-0.75: 0.1999 - recall-0.80: 0.1087 - recall-0.85: 0.0340 - recall-0.90: 0.0025 - recall-0.95: 0.0000e+00 - val_loss: 0.7856 - val_tp: 2617.0000 - val_fp: 1009.0000 - val_tn: 6793.0000 - val_fn: 1284.0000 - val_accuracy: 0.6991 - val_precision: 0.7217 - val_precision-0.55: 0.7293 - val_precision-0.60: 0.7319 - val_precision-0.65: 0.7378 - val_precision-0.70: 0.7635 - val_precision-0.75: 0.7751 - val_precision-0.80: 0.7857 - val_precision-0.85: 0.7550 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6709 - val_recall-0.55: 0.6506 - val_recall-0.60: 0.6234 - val_recall-0.65: 0.5791 - val_recall-0.70: 0.5163 - val_recall-0.75: 0.3976 - val_recall-0.80: 0.2115 - val_recall-0.85: 0.0292 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8247 - tp: 10343.0000 - fp: 4320.0000 - tn: 34592.0000 - fn: 9113.0000 - accuracy: 0.6384 - precision: 0.7054 - precision-0.55: 0.7328 - precision-0.60: 0.7598 - precision-0.65: 0.7850 - precision-0.70: 0.8125 - precision-0.75: 0.8311 - precision-0.80: 0.8593 - precision-0.85: 0.8820 - precision-0.90: 0.8750 - precision-0.95: 0.0000e+00 - recall: 0.5316 - recall-0.55: 0.4797 - recall-0.60: 0.4306 - recall-0.65: 0.3774 - recall-0.70: 0.3152 - recall-0.75: 0.2428 - recall-0.80: 0.1567 - recall-0.85: 0.0676 - recall-0.90: 0.0094 - recall-0.95: 0.0000e+00\n",
      "Epoch 5: val_loss did not improve from 0.78563\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.8245 - tp: 10371.0000 - fp: 4331.0000 - tn: 34679.0000 - fn: 9134.0000 - accuracy: 0.6384 - precision: 0.7054 - precision-0.55: 0.7328 - precision-0.60: 0.7600 - precision-0.65: 0.7850 - precision-0.70: 0.8125 - precision-0.75: 0.8312 - precision-0.80: 0.8597 - precision-0.85: 0.8825 - precision-0.90: 0.8750 - precision-0.95: 0.0000e+00 - recall: 0.5317 - recall-0.55: 0.4798 - recall-0.60: 0.4308 - recall-0.65: 0.3774 - recall-0.70: 0.3153 - recall-0.75: 0.2429 - recall-0.80: 0.1567 - recall-0.85: 0.0678 - recall-0.90: 0.0093 - recall-0.95: 0.0000e+00 - val_loss: 0.7889 - val_tp: 2640.0000 - val_fp: 1024.0000 - val_tn: 6778.0000 - val_fn: 1261.0000 - val_accuracy: 0.7003 - val_precision: 0.7205 - val_precision-0.55: 0.7269 - val_precision-0.60: 0.7309 - val_precision-0.65: 0.7326 - val_precision-0.70: 0.7451 - val_precision-0.75: 0.7705 - val_precision-0.80: 0.7823 - val_precision-0.85: 0.7966 - val_precision-0.90: 0.5556 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6767 - val_recall-0.55: 0.6585 - val_recall-0.60: 0.6393 - val_recall-0.65: 0.6055 - val_recall-0.70: 0.5604 - val_recall-0.75: 0.4871 - val_recall-0.80: 0.3435 - val_recall-0.85: 0.1336 - val_recall-0.90: 0.0026 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8187 - tp: 10411.0000 - fp: 4274.0000 - tn: 34638.0000 - fn: 9045.0000 - accuracy: 0.6372 - precision: 0.7090 - precision-0.55: 0.7376 - precision-0.60: 0.7628 - precision-0.65: 0.7858 - precision-0.70: 0.8104 - precision-0.75: 0.8348 - precision-0.80: 0.8551 - precision-0.85: 0.8674 - precision-0.90: 0.8670 - precision-0.95: 0.6667 - recall: 0.5351 - recall-0.55: 0.4891 - recall-0.60: 0.4402 - recall-0.65: 0.3904 - recall-0.70: 0.3342 - recall-0.75: 0.2705 - recall-0.80: 0.1829 - recall-0.85: 0.0891 - recall-0.90: 0.0174 - recall-0.95: 1.0280e-04 \n",
      "Epoch 6: val_loss did not improve from 0.78563\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.8189 - tp: 10436.0000 - fp: 4288.0000 - tn: 34722.0000 - fn: 9069.0000 - accuracy: 0.6371 - precision: 0.7088 - precision-0.55: 0.7375 - precision-0.60: 0.7626 - precision-0.65: 0.7856 - precision-0.70: 0.8101 - precision-0.75: 0.8345 - precision-0.80: 0.8548 - precision-0.85: 0.8666 - precision-0.90: 0.8673 - precision-0.95: 0.6667 - recall: 0.5350 - recall-0.55: 0.4891 - recall-0.60: 0.4402 - recall-0.65: 0.3903 - recall-0.70: 0.3341 - recall-0.75: 0.2704 - recall-0.80: 0.1829 - recall-0.85: 0.0890 - recall-0.90: 0.0174 - recall-0.95: 1.0254e-04 - val_loss: 0.7894 - val_tp: 2640.0000 - val_fp: 1023.0000 - val_tn: 6779.0000 - val_fn: 1261.0000 - val_accuracy: 0.7011 - val_precision: 0.7207 - val_precision-0.55: 0.7269 - val_precision-0.60: 0.7317 - val_precision-0.65: 0.7316 - val_precision-0.70: 0.7454 - val_precision-0.75: 0.7672 - val_precision-0.80: 0.7841 - val_precision-0.85: 0.7839 - val_precision-0.90: 0.6389 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6767 - val_recall-0.55: 0.6583 - val_recall-0.60: 0.6391 - val_recall-0.65: 0.6052 - val_recall-0.70: 0.5658 - val_recall-0.75: 0.5042 - val_recall-0.80: 0.3725 - val_recall-0.85: 0.1600 - val_recall-0.90: 0.0059 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8149 - tp: 10403.0000 - fp: 4262.0000 - tn: 34650.0000 - fn: 9053.0000 - accuracy: 0.6416 - precision: 0.7094 - precision-0.55: 0.7400 - precision-0.60: 0.7657 - precision-0.65: 0.7880 - precision-0.70: 0.8115 - precision-0.75: 0.8349 - precision-0.80: 0.8577 - precision-0.85: 0.8783 - precision-0.90: 0.9126 - precision-0.95: 0.5000 - recall: 0.5347 - recall-0.55: 0.4842 - recall-0.60: 0.4371 - recall-0.65: 0.3883 - recall-0.70: 0.3345 - recall-0.75: 0.2695 - recall-0.80: 0.1883 - recall-0.85: 0.0939 - recall-0.90: 0.0182 - recall-0.95: 5.1398e-05 \n",
      "Epoch 7: val_loss did not improve from 0.78563\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.8150 - tp: 10427.0000 - fp: 4276.0000 - tn: 34734.0000 - fn: 9078.0000 - accuracy: 0.6415 - precision: 0.7092 - precision-0.55: 0.7397 - precision-0.60: 0.7654 - precision-0.65: 0.7877 - precision-0.70: 0.8114 - precision-0.75: 0.8348 - precision-0.80: 0.8577 - precision-0.85: 0.8782 - precision-0.90: 0.9105 - precision-0.95: 0.5000 - recall: 0.5346 - recall-0.55: 0.4841 - recall-0.60: 0.4370 - recall-0.65: 0.3883 - recall-0.70: 0.3346 - recall-0.75: 0.2696 - recall-0.80: 0.1885 - recall-0.85: 0.0939 - recall-0.90: 0.0183 - recall-0.95: 5.1269e-05 - val_loss: 0.7902 - val_tp: 2646.0000 - val_fp: 1023.0000 - val_tn: 6779.0000 - val_fn: 1255.0000 - val_accuracy: 0.7008 - val_precision: 0.7212 - val_precision-0.55: 0.7270 - val_precision-0.60: 0.7321 - val_precision-0.65: 0.7324 - val_precision-0.70: 0.7423 - val_precision-0.75: 0.7687 - val_precision-0.80: 0.7798 - val_precision-0.85: 0.7716 - val_precision-0.90: 0.7143 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6783 - val_recall-0.55: 0.6593 - val_recall-0.60: 0.6424 - val_recall-0.65: 0.6083 - val_recall-0.70: 0.5693 - val_recall-0.75: 0.5129 - val_recall-0.80: 0.3858 - val_recall-0.85: 0.1697 - val_recall-0.90: 0.0090 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8128 - tp: 10485.0000 - fp: 4271.0000 - tn: 34641.0000 - fn: 8971.0000 - accuracy: 0.6436 - precision: 0.7106 - precision-0.55: 0.7402 - precision-0.60: 0.7634 - precision-0.65: 0.7885 - precision-0.70: 0.8126 - precision-0.75: 0.8385 - precision-0.80: 0.8627 - precision-0.85: 0.8770 - precision-0.90: 0.8883 - precision-0.95: 0.0000e+00 - recall: 0.5389 - recall-0.55: 0.4876 - recall-0.60: 0.4383 - recall-0.65: 0.3899 - recall-0.70: 0.3351 - recall-0.75: 0.2692 - recall-0.80: 0.1900 - recall-0.85: 0.0952 - recall-0.90: 0.0188 - recall-0.95: 0.0000e+00\n",
      "Epoch 8: val_loss did not improve from 0.78563\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.8130 - tp: 10510.0000 - fp: 4286.0000 - tn: 34724.0000 - fn: 8995.0000 - accuracy: 0.6435 - precision: 0.7103 - precision-0.55: 0.7402 - precision-0.60: 0.7633 - precision-0.65: 0.7883 - precision-0.70: 0.8124 - precision-0.75: 0.8386 - precision-0.80: 0.8627 - precision-0.85: 0.8770 - precision-0.90: 0.8892 - precision-0.95: 0.0000e+00 - recall: 0.5388 - recall-0.55: 0.4877 - recall-0.60: 0.4383 - recall-0.65: 0.3901 - recall-0.70: 0.3352 - recall-0.75: 0.2694 - recall-0.80: 0.1901 - recall-0.85: 0.0954 - recall-0.90: 0.0189 - recall-0.95: 0.0000e+00 - val_loss: 0.7952 - val_tp: 2642.0000 - val_fp: 1034.0000 - val_tn: 6768.0000 - val_fn: 1259.0000 - val_accuracy: 0.6993 - val_precision: 0.7187 - val_precision-0.55: 0.7281 - val_precision-0.60: 0.7297 - val_precision-0.65: 0.7321 - val_precision-0.70: 0.7362 - val_precision-0.75: 0.7559 - val_precision-0.80: 0.7739 - val_precision-0.85: 0.7866 - val_precision-0.90: 0.7736 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6773 - val_recall-0.55: 0.6657 - val_recall-0.60: 0.6491 - val_recall-0.65: 0.6227 - val_recall-0.70: 0.5865 - val_recall-0.75: 0.5391 - val_recall-0.80: 0.4299 - val_recall-0.85: 0.2315 - val_recall-0.90: 0.0210 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.8123 - tp: 10508.0000 - fp: 4327.0000 - tn: 34683.0000 - fn: 8997.0000 - accuracy: 0.6447 - precision: 0.7083 - precision-0.55: 0.7392 - precision-0.60: 0.7658 - precision-0.65: 0.7888 - precision-0.70: 0.8104 - precision-0.75: 0.8362 - precision-0.80: 0.8633 - precision-0.85: 0.8783 - precision-0.90: 0.8819 - precision-0.95: 0.8000 - recall: 0.5387 - recall-0.55: 0.4864 - recall-0.60: 0.4382 - recall-0.65: 0.3903 - recall-0.70: 0.3369 - recall-0.75: 0.2756 - recall-0.80: 0.1971 - recall-0.85: 0.1050 - recall-0.90: 0.0237 - recall-0.95: 2.0508e-04\n",
      "Epoch 9: val_loss did not improve from 0.78563\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.8123 - tp: 10508.0000 - fp: 4327.0000 - tn: 34683.0000 - fn: 8997.0000 - accuracy: 0.6447 - precision: 0.7083 - precision-0.55: 0.7392 - precision-0.60: 0.7658 - precision-0.65: 0.7888 - precision-0.70: 0.8104 - precision-0.75: 0.8362 - precision-0.80: 0.8633 - precision-0.85: 0.8783 - precision-0.90: 0.8819 - precision-0.95: 0.8000 - recall: 0.5387 - recall-0.55: 0.4864 - recall-0.60: 0.4382 - recall-0.65: 0.3903 - recall-0.70: 0.3369 - recall-0.75: 0.2756 - recall-0.80: 0.1971 - recall-0.85: 0.1050 - recall-0.90: 0.0237 - recall-0.95: 2.0508e-04 - val_loss: 0.7884 - val_tp: 2640.0000 - val_fp: 1012.0000 - val_tn: 6790.0000 - val_fn: 1261.0000 - val_accuracy: 0.7011 - val_precision: 0.7229 - val_precision-0.55: 0.7276 - val_precision-0.60: 0.7311 - val_precision-0.65: 0.7348 - val_precision-0.70: 0.7445 - val_precision-0.75: 0.7690 - val_precision-0.80: 0.7800 - val_precision-0.85: 0.7791 - val_precision-0.90: 0.7424 - val_precision-0.95: 0.0000e+00 - val_recall: 0.6767 - val_recall-0.55: 0.6573 - val_recall-0.60: 0.6357 - val_recall-0.65: 0.6057 - val_recall-0.70: 0.5686 - val_recall-0.75: 0.5119 - val_recall-0.80: 0.3917 - val_recall-0.85: 0.1889 - val_recall-0.90: 0.0126 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 216 588 720 709 721 551 217 228 727]\n",
      "Epoch 9: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5939 - tp: 2991.0000 - fp: 688.0000 - tn: 7114.0000 - fn: 910.0000 - accuracy: 0.7970 - precision: 0.8130 - precision-0.55: 0.8207 - precision-0.60: 0.8344 - precision-0.65: 0.8455 - precision-0.70: 0.8562 - precision-0.75: 0.8814 - precision-0.80: 0.9072 - precision-0.85: 0.9125 - precision-0.90: 0.9851 - precision-0.95: 0.0000e+00 - recall: 0.7667 - recall-0.55: 0.7531 - recall-0.60: 0.7401 - recall-0.65: 0.7139 - recall-0.70: 0.6534 - recall-0.75: 0.5793 - recall-0.80: 0.4512 - recall-0.85: 0.2594 - recall-0.90: 0.0508 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3107\n",
      "           1       0.36      0.01      0.03       347\n",
      "           2       0.37      0.09      0.14       447\n",
      "\n",
      "    accuracy                           0.80      3901\n",
      "   macro avg       0.51      0.36      0.35      3901\n",
      "weighted avg       0.72      0.80      0.73      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1   P2  Total    RP0    RP1    RP2\n",
      "0      3064   6   37   3107  0.986  0.002  0.012\n",
      "1       310   5   32    347  0.893  0.014  0.092\n",
      "2       404   3   40    447  0.904  0.007  0.089\n",
      "Total  3778  14  109   3901  0.968  0.004  0.028\n",
      "\n",
      ">>>>>> FOLD 6\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 23406, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 13688(58.48%)\n",
      "Label 1: 4721(20.17%)\n",
      "Label 2: 4997(21.35%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 3107(79.65%)\n",
      "Label 1: 347(8.9%)\n",
      "Label 2: 447(11.46%)\n",
      "\n",
      "Test:\n",
      "Label 0: 1783(45.71%)\n",
      "Label 1: 1128(28.92%)\n",
      "Label 2: 990(25.38%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.690726906149285, -0.37377198880262286, -0.31695489815544897]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.9637 - tp: 13727.0000 - fp: 7382.0000 - tn: 45476.0000 - fn: 12702.0000 - accuracy: 0.6105 - precision: 0.6503 - precision-0.55: 0.6696 - precision-0.60: 0.6961 - precision-0.65: 0.7313 - precision-0.70: 0.7739 - precision-0.75: 0.8413 - precision-0.80: 0.8962 - precision-0.85: 0.9123 - precision-0.90: 0.9851 - precision-0.95: 0.0000e+00 - recall: 0.5194 - recall-0.55: 0.4531 - recall-0.60: 0.3679 - recall-0.65: 0.2675 - recall-0.70: 0.1747 - recall-0.75: 0.1106 - recall-0.80: 0.0702 - recall-0.85: 0.0386 - recall-0.90: 0.0075 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.69935, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 6s 130ms/step - loss: 0.9619 - tp: 14173.0000 - fp: 7598.0000 - tn: 47016.0000 - fn: 13134.0000 - accuracy: 0.6105 - precision: 0.6510 - precision-0.55: 0.6704 - precision-0.60: 0.6973 - precision-0.65: 0.7321 - precision-0.70: 0.7734 - precision-0.75: 0.8410 - precision-0.80: 0.8962 - precision-0.85: 0.9123 - precision-0.90: 0.9851 - precision-0.95: 0.0000e+00 - recall: 0.5190 - recall-0.55: 0.4520 - recall-0.60: 0.3661 - recall-0.65: 0.2651 - recall-0.70: 0.1713 - recall-0.75: 0.1075 - recall-0.80: 0.0680 - recall-0.85: 0.0373 - recall-0.90: 0.0073 - recall-0.95: 0.0000e+00 - val_loss: 0.6994 - val_tp: 2971.0000 - val_fp: 655.0000 - val_tn: 7147.0000 - val_fn: 930.0000 - val_accuracy: 0.8003 - val_precision: 0.8194 - val_precision-0.55: 0.8300 - val_precision-0.60: 0.8541 - val_precision-0.65: 0.9055 - val_precision-0.70: 0.9633 - val_precision-0.75: 1.0000 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7616 - val_recall-0.55: 0.7157 - val_recall-0.60: 0.5791 - val_recall-0.65: 0.2948 - val_recall-0.70: 0.0269 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8685 - tp: 12553.0000 - fp: 5686.0000 - tn: 41126.0000 - fn: 10853.0000 - accuracy: 0.6260 - precision: 0.6883 - precision-0.55: 0.7154 - precision-0.60: 0.7456 - precision-0.65: 0.7710 - precision-0.70: 0.7949 - precision-0.75: 0.8155 - precision-0.80: 0.8361 - precision-0.85: 0.8739 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.5363 - recall-0.55: 0.4836 - recall-0.60: 0.4128 - recall-0.65: 0.3176 - recall-0.70: 0.2092 - recall-0.75: 0.1007 - recall-0.80: 0.0305 - recall-0.85: 0.0044 - recall-0.90: 2.1362e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 0.69935 to 0.63568, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.8685 - tp: 12553.0000 - fp: 5686.0000 - tn: 41126.0000 - fn: 10853.0000 - accuracy: 0.6260 - precision: 0.6883 - precision-0.55: 0.7154 - precision-0.60: 0.7456 - precision-0.65: 0.7710 - precision-0.70: 0.7949 - precision-0.75: 0.8155 - precision-0.80: 0.8361 - precision-0.85: 0.8739 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.5363 - recall-0.55: 0.4836 - recall-0.60: 0.4128 - recall-0.65: 0.3176 - recall-0.70: 0.2092 - recall-0.75: 0.1007 - recall-0.80: 0.0305 - recall-0.85: 0.0044 - recall-0.90: 2.1362e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.6357 - val_tp: 3010.0000 - val_fp: 677.0000 - val_tn: 7125.0000 - val_fn: 891.0000 - val_accuracy: 0.8013 - val_precision: 0.8164 - val_precision-0.55: 0.8204 - val_precision-0.60: 0.8341 - val_precision-0.65: 0.8534 - val_precision-0.70: 0.8801 - val_precision-0.75: 0.9133 - val_precision-0.80: 0.9454 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7716 - val_recall-0.55: 0.7472 - val_recall-0.60: 0.7139 - val_recall-0.65: 0.6445 - val_recall-0.70: 0.4947 - val_recall-0.75: 0.2728 - val_recall-0.80: 0.0443 - val_recall-0.85: 2.5634e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.8367 - tp: 12262.0000 - fp: 5077.0000 - tn: 39979.0000 - fn: 10266.0000 - accuracy: 0.6409 - precision: 0.7072 - precision-0.55: 0.7324 - precision-0.60: 0.7551 - precision-0.65: 0.7759 - precision-0.70: 0.7931 - precision-0.75: 0.8146 - precision-0.80: 0.8346 - precision-0.85: 0.8637 - precision-0.90: 0.8542 - precision-0.95: 0.0000e+00 - recall: 0.5443 - recall-0.55: 0.4998 - recall-0.60: 0.4472 - recall-0.65: 0.3811 - recall-0.70: 0.2976 - recall-0.75: 0.2001 - recall-0.80: 0.1001 - recall-0.85: 0.0284 - recall-0.90: 0.0018 - recall-0.95: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 0.63568 to 0.61268, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.8358 - tp: 12740.0000 - fp: 5268.0000 - tn: 41544.0000 - fn: 10666.0000 - accuracy: 0.6409 - precision: 0.7075 - precision-0.55: 0.7323 - precision-0.60: 0.7556 - precision-0.65: 0.7768 - precision-0.70: 0.7943 - precision-0.75: 0.8155 - precision-0.80: 0.8360 - precision-0.85: 0.8627 - precision-0.90: 0.8571 - precision-0.95: 0.0000e+00 - recall: 0.5443 - recall-0.55: 0.4995 - recall-0.60: 0.4480 - recall-0.65: 0.3824 - recall-0.70: 0.2998 - recall-0.75: 0.2025 - recall-0.80: 0.1021 - recall-0.85: 0.0295 - recall-0.90: 0.0018 - recall-0.95: 0.0000e+00 - val_loss: 0.6127 - val_tp: 3003.0000 - val_fp: 687.0000 - val_tn: 7115.0000 - val_fn: 898.0000 - val_accuracy: 0.7990 - val_precision: 0.8138 - val_precision-0.55: 0.8184 - val_precision-0.60: 0.8308 - val_precision-0.65: 0.8488 - val_precision-0.70: 0.8644 - val_precision-0.75: 0.8982 - val_precision-0.80: 0.9144 - val_precision-0.85: 0.9330 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7698 - val_recall-0.55: 0.7498 - val_recall-0.60: 0.7288 - val_recall-0.65: 0.6906 - val_recall-0.70: 0.6014 - val_recall-0.75: 0.4683 - val_recall-0.80: 0.2712 - val_recall-0.85: 0.0536 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8233 - tp: 12857.0000 - fp: 5285.0000 - tn: 41527.0000 - fn: 10549.0000 - accuracy: 0.6477 - precision: 0.7087 - precision-0.55: 0.7340 - precision-0.60: 0.7565 - precision-0.65: 0.7764 - precision-0.70: 0.7968 - precision-0.75: 0.8160 - precision-0.80: 0.8381 - precision-0.85: 0.8505 - precision-0.90: 0.8194 - precision-0.95: 1.0000 - recall: 0.5493 - recall-0.55: 0.5053 - recall-0.60: 0.4586 - recall-0.65: 0.4044 - recall-0.70: 0.3400 - recall-0.75: 0.2570 - recall-0.80: 0.1586 - recall-0.85: 0.0610 - recall-0.90: 0.0079 - recall-0.95: 4.2724e-05\n",
      "Epoch 4: val_loss improved from 0.61268 to 0.61219, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.8233 - tp: 12857.0000 - fp: 5285.0000 - tn: 41527.0000 - fn: 10549.0000 - accuracy: 0.6477 - precision: 0.7087 - precision-0.55: 0.7340 - precision-0.60: 0.7565 - precision-0.65: 0.7764 - precision-0.70: 0.7968 - precision-0.75: 0.8160 - precision-0.80: 0.8381 - precision-0.85: 0.8505 - precision-0.90: 0.8194 - precision-0.95: 1.0000 - recall: 0.5493 - recall-0.55: 0.5053 - recall-0.60: 0.4586 - recall-0.65: 0.4044 - recall-0.70: 0.3400 - recall-0.75: 0.2570 - recall-0.80: 0.1586 - recall-0.85: 0.0610 - recall-0.90: 0.0079 - recall-0.95: 4.2724e-05 - val_loss: 0.6122 - val_tp: 2962.0000 - val_fp: 684.0000 - val_tn: 7118.0000 - val_fn: 939.0000 - val_accuracy: 0.7972 - val_precision: 0.8124 - val_precision-0.55: 0.8238 - val_precision-0.60: 0.8380 - val_precision-0.65: 0.8542 - val_precision-0.70: 0.8710 - val_precision-0.75: 0.9033 - val_precision-0.80: 0.9096 - val_precision-0.85: 0.9341 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7593 - val_recall-0.55: 0.7406 - val_recall-0.60: 0.7211 - val_recall-0.65: 0.6701 - val_recall-0.70: 0.5852 - val_recall-0.75: 0.4622 - val_recall-0.80: 0.2915 - val_recall-0.85: 0.0836 - val_recall-0.90: 0.0013 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.8126 - tp: 12573.0000 - fp: 5098.0000 - tn: 39958.0000 - fn: 9955.0000 - accuracy: 0.6510 - precision: 0.7115 - precision-0.55: 0.7353 - precision-0.60: 0.7559 - precision-0.65: 0.7747 - precision-0.70: 0.7955 - precision-0.75: 0.8206 - precision-0.80: 0.8474 - precision-0.85: 0.8627 - precision-0.90: 0.8834 - precision-0.95: 0.5000 - recall: 0.5581 - recall-0.55: 0.5119 - recall-0.60: 0.4649 - recall-0.65: 0.4123 - recall-0.70: 0.3519 - recall-0.75: 0.2792 - recall-0.80: 0.1894 - recall-0.85: 0.0865 - recall-0.90: 0.0134 - recall-0.95: 4.4389e-05  \n",
      "Epoch 5: val_loss improved from 0.61219 to 0.61132, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.8127 - tp: 13047.0000 - fp: 5290.0000 - tn: 41522.0000 - fn: 10359.0000 - accuracy: 0.6503 - precision: 0.7115 - precision-0.55: 0.7350 - precision-0.60: 0.7561 - precision-0.65: 0.7755 - precision-0.70: 0.7966 - precision-0.75: 0.8215 - precision-0.80: 0.8483 - precision-0.85: 0.8625 - precision-0.90: 0.8814 - precision-0.95: 0.5000 - recall: 0.5574 - recall-0.55: 0.5108 - recall-0.60: 0.4639 - recall-0.65: 0.4113 - recall-0.70: 0.3514 - recall-0.75: 0.2790 - recall-0.80: 0.1890 - recall-0.85: 0.0860 - recall-0.90: 0.0133 - recall-0.95: 4.2724e-05 - val_loss: 0.6113 - val_tp: 2952.0000 - val_fp: 664.0000 - val_tn: 7138.0000 - val_fn: 949.0000 - val_accuracy: 0.7975 - val_precision: 0.8164 - val_precision-0.55: 0.8280 - val_precision-0.60: 0.8424 - val_precision-0.65: 0.8523 - val_precision-0.70: 0.8756 - val_precision-0.75: 0.9024 - val_precision-0.80: 0.9061 - val_precision-0.85: 0.9397 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7567 - val_recall-0.55: 0.7416 - val_recall-0.60: 0.7193 - val_recall-0.65: 0.6655 - val_recall-0.70: 0.5829 - val_recall-0.75: 0.4717 - val_recall-0.80: 0.3043 - val_recall-0.85: 0.1079 - val_recall-0.90: 0.0023 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8085 - tp: 13050.0000 - fp: 5156.0000 - tn: 41656.0000 - fn: 10356.0000 - accuracy: 0.6564 - precision: 0.7168 - precision-0.55: 0.7395 - precision-0.60: 0.7589 - precision-0.65: 0.7804 - precision-0.70: 0.7977 - precision-0.75: 0.8227 - precision-0.80: 0.8409 - precision-0.85: 0.8598 - precision-0.90: 0.8622 - precision-0.95: 0.6667 - recall: 0.5575 - recall-0.55: 0.5091 - recall-0.60: 0.4596 - recall-0.65: 0.4108 - recall-0.70: 0.3521 - recall-0.75: 0.2796 - recall-0.80: 0.1920 - recall-0.85: 0.0919 - recall-0.90: 0.0166 - recall-0.95: 8.5448e-05\n",
      "Epoch 6: val_loss improved from 0.61132 to 0.60561, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154628.h5\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.8085 - tp: 13050.0000 - fp: 5156.0000 - tn: 41656.0000 - fn: 10356.0000 - accuracy: 0.6564 - precision: 0.7168 - precision-0.55: 0.7395 - precision-0.60: 0.7589 - precision-0.65: 0.7804 - precision-0.70: 0.7977 - precision-0.75: 0.8227 - precision-0.80: 0.8409 - precision-0.85: 0.8598 - precision-0.90: 0.8622 - precision-0.95: 0.6667 - recall: 0.5575 - recall-0.55: 0.5091 - recall-0.60: 0.4596 - recall-0.65: 0.4108 - recall-0.70: 0.3521 - recall-0.75: 0.2796 - recall-0.80: 0.1920 - recall-0.85: 0.0919 - recall-0.90: 0.0166 - recall-0.95: 8.5448e-05 - val_loss: 0.6056 - val_tp: 2968.0000 - val_fp: 673.0000 - val_tn: 7129.0000 - val_fn: 933.0000 - val_accuracy: 0.7967 - val_precision: 0.8152 - val_precision-0.55: 0.8240 - val_precision-0.60: 0.8366 - val_precision-0.65: 0.8500 - val_precision-0.70: 0.8661 - val_precision-0.75: 0.8894 - val_precision-0.80: 0.9056 - val_precision-0.85: 0.9300 - val_precision-0.90: 0.9643 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7608 - val_recall-0.55: 0.7442 - val_recall-0.60: 0.7272 - val_recall-0.65: 0.6883 - val_recall-0.70: 0.6168 - val_recall-0.75: 0.5196 - val_recall-0.80: 0.3566 - val_recall-0.85: 0.1600 - val_recall-0.90: 0.0069 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8054 - tp: 13081.0000 - fp: 5128.0000 - tn: 41684.0000 - fn: 10325.0000 - accuracy: 0.6565 - precision: 0.7184 - precision-0.55: 0.7424 - precision-0.60: 0.7655 - precision-0.65: 0.7846 - precision-0.70: 0.8034 - precision-0.75: 0.8258 - precision-0.80: 0.8419 - precision-0.85: 0.8449 - precision-0.90: 0.8605 - precision-0.95: 0.5000 - recall: 0.5589 - recall-0.55: 0.5129 - recall-0.60: 0.4656 - recall-0.65: 0.4131 - recall-0.70: 0.3567 - recall-0.75: 0.2840 - recall-0.80: 0.1937 - recall-0.85: 0.0922 - recall-0.90: 0.0156 - recall-0.95: 4.2724e-05\n",
      "Epoch 7: val_loss did not improve from 0.60561\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.8054 - tp: 13081.0000 - fp: 5128.0000 - tn: 41684.0000 - fn: 10325.0000 - accuracy: 0.6565 - precision: 0.7184 - precision-0.55: 0.7424 - precision-0.60: 0.7655 - precision-0.65: 0.7846 - precision-0.70: 0.8034 - precision-0.75: 0.8258 - precision-0.80: 0.8419 - precision-0.85: 0.8449 - precision-0.90: 0.8605 - precision-0.95: 0.5000 - recall: 0.5589 - recall-0.55: 0.5129 - recall-0.60: 0.4656 - recall-0.65: 0.4131 - recall-0.70: 0.3567 - recall-0.75: 0.2840 - recall-0.80: 0.1937 - recall-0.85: 0.0922 - recall-0.90: 0.0156 - recall-0.95: 4.2724e-05 - val_loss: 0.6084 - val_tp: 2953.0000 - val_fp: 663.0000 - val_tn: 7139.0000 - val_fn: 948.0000 - val_accuracy: 0.7939 - val_precision: 0.8166 - val_precision-0.55: 0.8311 - val_precision-0.60: 0.8434 - val_precision-0.65: 0.8558 - val_precision-0.70: 0.8770 - val_precision-0.75: 0.8998 - val_precision-0.80: 0.9047 - val_precision-0.85: 0.9476 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7570 - val_recall-0.55: 0.7419 - val_recall-0.60: 0.7190 - val_recall-0.65: 0.6678 - val_recall-0.70: 0.5924 - val_recall-0.75: 0.4881 - val_recall-0.80: 0.3235 - val_recall-0.85: 0.1343 - val_recall-0.90: 0.0031 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8000 - tp: 13139.0000 - fp: 5140.0000 - tn: 41672.0000 - fn: 10267.0000 - accuracy: 0.6591 - precision: 0.7188 - precision-0.55: 0.7417 - precision-0.60: 0.7642 - precision-0.65: 0.7846 - precision-0.70: 0.8046 - precision-0.75: 0.8257 - precision-0.80: 0.8479 - precision-0.85: 0.8615 - precision-0.90: 0.8394 - precision-0.95: 1.0000 - recall: 0.5614 - recall-0.55: 0.5150 - recall-0.60: 0.4684 - recall-0.65: 0.4206 - recall-0.70: 0.3625 - recall-0.75: 0.2934 - recall-0.80: 0.2050 - recall-0.85: 0.1010 - recall-0.90: 0.0167 - recall-0.95: 4.2724e-05\n",
      "Epoch 8: val_loss did not improve from 0.60561\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.8000 - tp: 13139.0000 - fp: 5140.0000 - tn: 41672.0000 - fn: 10267.0000 - accuracy: 0.6591 - precision: 0.7188 - precision-0.55: 0.7417 - precision-0.60: 0.7642 - precision-0.65: 0.7846 - precision-0.70: 0.8046 - precision-0.75: 0.8257 - precision-0.80: 0.8479 - precision-0.85: 0.8615 - precision-0.90: 0.8394 - precision-0.95: 1.0000 - recall: 0.5614 - recall-0.55: 0.5150 - recall-0.60: 0.4684 - recall-0.65: 0.4206 - recall-0.70: 0.3625 - recall-0.75: 0.2934 - recall-0.80: 0.2050 - recall-0.85: 0.1010 - recall-0.90: 0.0167 - recall-0.95: 4.2724e-05 - val_loss: 0.6092 - val_tp: 2947.0000 - val_fp: 656.0000 - val_tn: 7146.0000 - val_fn: 954.0000 - val_accuracy: 0.7929 - val_precision: 0.8179 - val_precision-0.55: 0.8321 - val_precision-0.60: 0.8441 - val_precision-0.65: 0.8581 - val_precision-0.70: 0.8805 - val_precision-0.75: 0.9018 - val_precision-0.80: 0.9025 - val_precision-0.85: 0.9462 - val_precision-0.90: 0.9333 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7554 - val_recall-0.55: 0.7396 - val_recall-0.60: 0.7137 - val_recall-0.65: 0.6619 - val_recall-0.70: 0.5875 - val_recall-0.75: 0.4804 - val_recall-0.80: 0.3181 - val_recall-0.85: 0.1307 - val_recall-0.90: 0.0036 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7986 - tp: 13214.0000 - fp: 5203.0000 - tn: 41609.0000 - fn: 10192.0000 - accuracy: 0.6592 - precision: 0.7175 - precision-0.55: 0.7424 - precision-0.60: 0.7636 - precision-0.65: 0.7855 - precision-0.70: 0.8080 - precision-0.75: 0.8298 - precision-0.80: 0.8465 - precision-0.85: 0.8559 - precision-0.90: 0.8482 - precision-0.95: 0.5000 - recall: 0.5646 - recall-0.55: 0.5174 - recall-0.60: 0.4687 - recall-0.65: 0.4191 - recall-0.70: 0.3655 - recall-0.75: 0.2937 - recall-0.80: 0.2041 - recall-0.85: 0.1015 - recall-0.90: 0.0174 - recall-0.95: 4.2724e-05\n",
      "Epoch 9: val_loss did not improve from 0.60561\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.7986 - tp: 13214.0000 - fp: 5203.0000 - tn: 41609.0000 - fn: 10192.0000 - accuracy: 0.6592 - precision: 0.7175 - precision-0.55: 0.7424 - precision-0.60: 0.7636 - precision-0.65: 0.7855 - precision-0.70: 0.8080 - precision-0.75: 0.8298 - precision-0.80: 0.8465 - precision-0.85: 0.8559 - precision-0.90: 0.8482 - precision-0.95: 0.5000 - recall: 0.5646 - recall-0.55: 0.5174 - recall-0.60: 0.4687 - recall-0.65: 0.4191 - recall-0.70: 0.3655 - recall-0.75: 0.2937 - recall-0.80: 0.2041 - recall-0.85: 0.1015 - recall-0.90: 0.0174 - recall-0.95: 4.2724e-05 - val_loss: 0.6123 - val_tp: 2926.0000 - val_fp: 635.0000 - val_tn: 7167.0000 - val_fn: 975.0000 - val_accuracy: 0.7913 - val_precision: 0.8217 - val_precision-0.55: 0.8365 - val_precision-0.60: 0.8483 - val_precision-0.65: 0.8623 - val_precision-0.70: 0.8828 - val_precision-0.75: 0.9100 - val_precision-0.80: 0.9101 - val_precision-0.85: 0.9572 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7501 - val_recall-0.55: 0.7344 - val_recall-0.60: 0.6996 - val_recall-0.65: 0.6452 - val_recall-0.70: 0.5716 - val_recall-0.75: 0.4586 - val_recall-0.80: 0.2958 - val_recall-0.85: 0.1089 - val_recall-0.90: 0.0013 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.7960 - tp: 12716.0000 - fp: 4931.0000 - tn: 40125.0000 - fn: 9812.0000 - accuracy: 0.6615 - precision: 0.7206 - precision-0.55: 0.7449 - precision-0.60: 0.7673 - precision-0.65: 0.7875 - precision-0.70: 0.8072 - precision-0.75: 0.8250 - precision-0.80: 0.8479 - precision-0.85: 0.8588 - precision-0.90: 0.8695 - precision-0.95: 0.0000e+00 - recall: 0.5645 - recall-0.55: 0.5168 - recall-0.60: 0.4687 - recall-0.65: 0.4188 - recall-0.70: 0.3632 - recall-0.75: 0.2909 - recall-0.80: 0.2049 - recall-0.85: 0.1044 - recall-0.90: 0.0183 - recall-0.95: 0.0000e+00\n",
      "Epoch 10: val_loss did not improve from 0.60561\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7957 - tp: 13233.0000 - fp: 5118.0000 - tn: 41694.0000 - fn: 10173.0000 - accuracy: 0.6621 - precision: 0.7211 - precision-0.55: 0.7456 - precision-0.60: 0.7676 - precision-0.65: 0.7879 - precision-0.70: 0.8072 - precision-0.75: 0.8251 - precision-0.80: 0.8479 - precision-0.85: 0.8599 - precision-0.90: 0.8691 - precision-0.95: 0.0000e+00 - recall: 0.5654 - recall-0.55: 0.5176 - recall-0.60: 0.4695 - recall-0.65: 0.4190 - recall-0.70: 0.3634 - recall-0.75: 0.2909 - recall-0.80: 0.2044 - recall-0.85: 0.1041 - recall-0.90: 0.0182 - recall-0.95: 0.0000e+00 - val_loss: 0.6158 - val_tp: 2918.0000 - val_fp: 622.0000 - val_tn: 7180.0000 - val_fn: 983.0000 - val_accuracy: 0.7880 - val_precision: 0.8243 - val_precision-0.55: 0.8403 - val_precision-0.60: 0.8505 - val_precision-0.65: 0.8650 - val_precision-0.70: 0.8864 - val_precision-0.75: 0.9115 - val_precision-0.80: 0.9135 - val_precision-0.85: 0.9634 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7480 - val_recall-0.55: 0.7296 - val_recall-0.60: 0.6839 - val_recall-0.65: 0.6273 - val_recall-0.70: 0.5519 - val_recall-0.75: 0.4332 - val_recall-0.80: 0.2707 - val_recall-0.85: 0.0946 - val_recall-0.90: 7.6903e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7937 - tp: 13218.0000 - fp: 5108.0000 - tn: 41704.0000 - fn: 10188.0000 - accuracy: 0.6616 - precision: 0.7213 - precision-0.55: 0.7441 - precision-0.60: 0.7654 - precision-0.65: 0.7865 - precision-0.70: 0.8093 - precision-0.75: 0.8340 - precision-0.80: 0.8535 - precision-0.85: 0.8765 - precision-0.90: 0.8618 - precision-0.95: 0.0000e+00 - recall: 0.5647 - recall-0.55: 0.5162 - recall-0.60: 0.4686 - recall-0.65: 0.4208 - recall-0.70: 0.3628 - recall-0.75: 0.2927 - recall-0.80: 0.2070 - recall-0.85: 0.1037 - recall-0.90: 0.0168 - recall-0.95: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from 0.60561\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.7937 - tp: 13218.0000 - fp: 5108.0000 - tn: 41704.0000 - fn: 10188.0000 - accuracy: 0.6616 - precision: 0.7213 - precision-0.55: 0.7441 - precision-0.60: 0.7654 - precision-0.65: 0.7865 - precision-0.70: 0.8093 - precision-0.75: 0.8340 - precision-0.80: 0.8535 - precision-0.85: 0.8765 - precision-0.90: 0.8618 - precision-0.95: 0.0000e+00 - recall: 0.5647 - recall-0.55: 0.5162 - recall-0.60: 0.4686 - recall-0.65: 0.4208 - recall-0.70: 0.3628 - recall-0.75: 0.2927 - recall-0.80: 0.2070 - recall-0.85: 0.1037 - recall-0.90: 0.0168 - recall-0.95: 0.0000e+00 - val_loss: 0.6141 - val_tp: 2939.0000 - val_fp: 628.0000 - val_tn: 7174.0000 - val_fn: 962.0000 - val_accuracy: 0.7918 - val_precision: 0.8239 - val_precision-0.55: 0.8401 - val_precision-0.60: 0.8496 - val_precision-0.65: 0.8616 - val_precision-0.70: 0.8830 - val_precision-0.75: 0.9048 - val_precision-0.80: 0.9070 - val_precision-0.85: 0.9572 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.7534 - val_recall-0.55: 0.7355 - val_recall-0.60: 0.6978 - val_recall-0.65: 0.6478 - val_recall-0.70: 0.5747 - val_recall-0.75: 0.4607 - val_recall-0.80: 0.3002 - val_recall-0.85: 0.1146 - val_recall-0.90: 0.0018 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 216 720 576 588 709 577 579 578 721]\n",
      "Epoch 11: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0170 - tp: 1435.0000 - fp: 1066.0000 - tn: 6736.0000 - fn: 2466.0000 - accuracy: 0.5022 - precision: 0.5738 - precision-0.55: 0.6070 - precision-0.60: 0.6680 - precision-0.65: 0.7479 - precision-0.70: 0.8060 - precision-0.75: 0.8435 - precision-0.80: 0.8646 - precision-0.85: 0.6667 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.3679 - recall-0.55: 0.2843 - recall-0.60: 0.2146 - recall-0.65: 0.1597 - recall-0.70: 0.1033 - recall-0.75: 0.0746 - recall-0.80: 0.0508 - recall-0.85: 0.0072 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      1783\n",
      "           1       0.35      0.47      0.40      1128\n",
      "           2       0.39      0.35      0.37       990\n",
      "\n",
      "    accuracy                           0.50      3901\n",
      "   macro avg       0.48      0.47      0.48      3901\n",
      "weighted avg       0.52      0.50      0.51      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0    P1   P2  Total    RP0    RP1    RP2\n",
      "0      1091   467  225   1783  0.612  0.262  0.126\n",
      "1       301   526  301   1128  0.267  0.466  0.267\n",
      "2       153   495  342    990  0.155  0.500  0.345\n",
      "Total  1545  1488  868   3901  0.396  0.381  0.223\n",
      "\n",
      ">>>>>> FOLD 7\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 27307, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 16795(61.5%)\n",
      "Label 1: 5068(18.56%)\n",
      "Label 2: 5444(19.94%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 1783(45.71%)\n",
      "Label 1: 1128(28.92%)\n",
      "Label 2: 990(25.38%)\n",
      "\n",
      "Test:\n",
      "Label 0: 1935(49.6%)\n",
      "Label 1: 866(22.2%)\n",
      "Label 2: 1100(28.2%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.7749007119519201, -0.4232342486477877, -0.35166642632830675]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.9235 - tp: 15725.0000 - fp: 8860.0000 - tn: 52190.0000 - fn: 14800.0000 - accuracy: 0.5996 - precision: 0.6396 - precision-0.55: 0.6563 - precision-0.60: 0.6808 - precision-0.65: 0.6981 - precision-0.70: 0.7079 - precision-0.75: 0.7285 - precision-0.80: 0.7727 - precision-0.85: 0.6974 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.5152 - recall-0.55: 0.4514 - recall-0.60: 0.3674 - recall-0.65: 0.2589 - recall-0.70: 0.1451 - recall-0.75: 0.0601 - recall-0.80: 0.0170 - recall-0.85: 0.0017 - recall-0.90: 3.2760e-05 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1.02615, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154648.h5\n",
      "27/27 [==============================] - 6s 115ms/step - loss: 0.9217 - tp: 16116.0000 - fp: 9026.0000 - tn: 53390.0000 - fn: 15092.0000 - accuracy: 0.6005 - precision: 0.6410 - precision-0.55: 0.6579 - precision-0.60: 0.6824 - precision-0.65: 0.7002 - precision-0.70: 0.7105 - precision-0.75: 0.7307 - precision-0.80: 0.7738 - precision-0.85: 0.7051 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.5164 - recall-0.55: 0.4525 - recall-0.60: 0.3686 - recall-0.65: 0.2602 - recall-0.70: 0.1462 - recall-0.75: 0.0606 - recall-0.80: 0.0172 - recall-0.85: 0.0018 - recall-0.90: 3.2043e-05 - recall-0.95: 0.0000e+00 - val_loss: 1.0261 - val_tp: 1680.0000 - val_fp: 1464.0000 - val_tn: 6338.0000 - val_fn: 2221.0000 - val_accuracy: 0.4917 - val_precision: 0.5344 - val_precision-0.55: 0.5646 - val_precision-0.60: 0.6277 - val_precision-0.65: 0.6868 - val_precision-0.70: 0.7611 - val_precision-0.75: 0.8856 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4307 - val_recall-0.55: 0.3886 - val_recall-0.60: 0.3294 - val_recall-0.65: 0.2474 - val_recall-0.70: 0.1453 - val_recall-0.75: 0.0456 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8289 - tp: 15846.0000 - fp: 6522.0000 - tn: 48092.0000 - fn: 11461.0000 - accuracy: 0.6521 - precision: 0.7084 - precision-0.55: 0.7333 - precision-0.60: 0.7564 - precision-0.65: 0.7820 - precision-0.70: 0.8053 - precision-0.75: 0.8240 - precision-0.80: 0.8432 - precision-0.85: 0.8768 - precision-0.90: 0.9143 - precision-0.95: 0.0000e+00 - recall: 0.5803 - recall-0.55: 0.5392 - recall-0.60: 0.4819 - recall-0.65: 0.4084 - recall-0.70: 0.3102 - recall-0.75: 0.1917 - recall-0.80: 0.0873 - recall-0.85: 0.0224 - recall-0.90: 0.0012 - recall-0.95: 0.0000e+00  \n",
      "Epoch 2: val_loss improved from 1.02615 to 0.97063, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154648.h5\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.8289 - tp: 15846.0000 - fp: 6522.0000 - tn: 48092.0000 - fn: 11461.0000 - accuracy: 0.6521 - precision: 0.7084 - precision-0.55: 0.7333 - precision-0.60: 0.7564 - precision-0.65: 0.7820 - precision-0.70: 0.8053 - precision-0.75: 0.8240 - precision-0.80: 0.8432 - precision-0.85: 0.8768 - precision-0.90: 0.9143 - precision-0.95: 0.0000e+00 - recall: 0.5803 - recall-0.55: 0.5392 - recall-0.60: 0.4819 - recall-0.65: 0.4084 - recall-0.70: 0.3102 - recall-0.75: 0.1917 - recall-0.80: 0.0873 - recall-0.85: 0.0224 - recall-0.90: 0.0012 - recall-0.95: 0.0000e+00 - val_loss: 0.9706 - val_tp: 1483.0000 - val_fp: 982.0000 - val_tn: 6820.0000 - val_fn: 2418.0000 - val_accuracy: 0.5170 - val_precision: 0.6016 - val_precision-0.55: 0.6458 - val_precision-0.60: 0.6757 - val_precision-0.65: 0.7060 - val_precision-0.70: 0.7410 - val_precision-0.75: 0.8036 - val_precision-0.80: 0.8681 - val_precision-0.85: 0.8962 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3802 - val_recall-0.55: 0.3327 - val_recall-0.60: 0.2992 - val_recall-0.65: 0.2574 - val_recall-0.70: 0.2120 - val_recall-0.75: 0.1500 - val_recall-0.80: 0.0810 - val_recall-0.85: 0.0244 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7983 - tp: 15524.0000 - fp: 5964.0000 - tn: 47284.0000 - fn: 11100.0000 - accuracy: 0.6656 - precision: 0.7224 - precision-0.55: 0.7458 - precision-0.60: 0.7667 - precision-0.65: 0.7871 - precision-0.70: 0.8068 - precision-0.75: 0.8288 - precision-0.80: 0.8496 - precision-0.85: 0.8797 - precision-0.90: 0.8860 - precision-0.95: 1.0000 - recall: 0.5831 - recall-0.55: 0.5429 - recall-0.60: 0.4995 - recall-0.65: 0.4456 - recall-0.70: 0.3795 - recall-0.75: 0.2907 - recall-0.80: 0.1831 - recall-0.85: 0.0794 - recall-0.90: 0.0140 - recall-0.95: 1.5024e-04\n",
      "Epoch 3: val_loss improved from 0.97063 to 0.96102, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154648.h5\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.7980 - tp: 15910.0000 - fp: 6101.0000 - tn: 48513.0000 - fn: 11397.0000 - accuracy: 0.6656 - precision: 0.7228 - precision-0.55: 0.7462 - precision-0.60: 0.7670 - precision-0.65: 0.7875 - precision-0.70: 0.8072 - precision-0.75: 0.8286 - precision-0.80: 0.8506 - precision-0.85: 0.8806 - precision-0.90: 0.8889 - precision-0.95: 1.0000 - recall: 0.5826 - recall-0.55: 0.5423 - recall-0.60: 0.4988 - recall-0.65: 0.4451 - recall-0.70: 0.3791 - recall-0.75: 0.2903 - recall-0.80: 0.1828 - recall-0.85: 0.0794 - recall-0.90: 0.0141 - recall-0.95: 1.8310e-04 - val_loss: 0.9610 - val_tp: 1427.0000 - val_fp: 873.0000 - val_tn: 6929.0000 - val_fn: 2474.0000 - val_accuracy: 0.5124 - val_precision: 0.6204 - val_precision-0.55: 0.6711 - val_precision-0.60: 0.7067 - val_precision-0.65: 0.7308 - val_precision-0.70: 0.7742 - val_precision-0.75: 0.8205 - val_precision-0.80: 0.8709 - val_precision-0.85: 0.8596 - val_precision-0.90: 1.0000 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3658 - val_recall-0.55: 0.3212 - val_recall-0.60: 0.2792 - val_recall-0.65: 0.2338 - val_recall-0.70: 0.1846 - val_recall-0.75: 0.1312 - val_recall-0.80: 0.0813 - val_recall-0.85: 0.0392 - val_recall-0.90: 0.0013 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7884 - tp: 15600.0000 - fp: 5801.0000 - tn: 47447.0000 - fn: 11024.0000 - accuracy: 0.6698 - precision: 0.7289 - precision-0.55: 0.7514 - precision-0.60: 0.7703 - precision-0.65: 0.7892 - precision-0.70: 0.8077 - precision-0.75: 0.8250 - precision-0.80: 0.8472 - precision-0.85: 0.8649 - precision-0.90: 0.8710 - precision-0.95: 1.0000 - recall: 0.5859 - recall-0.55: 0.5446 - recall-0.60: 0.5012 - recall-0.65: 0.4558 - recall-0.70: 0.3970 - recall-0.75: 0.3214 - recall-0.80: 0.2263 - recall-0.85: 0.1133 - recall-0.90: 0.0246 - recall-0.95: 5.6340e-04\n",
      "Epoch 4: val_loss did not improve from 0.96102\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.7881 - tp: 16005.0000 - fp: 5942.0000 - tn: 48672.0000 - fn: 11302.0000 - accuracy: 0.6706 - precision: 0.7293 - precision-0.55: 0.7517 - precision-0.60: 0.7706 - precision-0.65: 0.7892 - precision-0.70: 0.8078 - precision-0.75: 0.8249 - precision-0.80: 0.8469 - precision-0.85: 0.8651 - precision-0.90: 0.8716 - precision-0.95: 1.0000 - recall: 0.5861 - recall-0.55: 0.5444 - recall-0.60: 0.5010 - recall-0.65: 0.4555 - recall-0.70: 0.3968 - recall-0.75: 0.3211 - recall-0.80: 0.2259 - recall-0.85: 0.1137 - recall-0.90: 0.0249 - recall-0.95: 5.8593e-04 - val_loss: 0.9724 - val_tp: 1514.0000 - val_fp: 947.0000 - val_tn: 6855.0000 - val_fn: 2387.0000 - val_accuracy: 0.5153 - val_precision: 0.6152 - val_precision-0.55: 0.6523 - val_precision-0.60: 0.6841 - val_precision-0.65: 0.7220 - val_precision-0.70: 0.7614 - val_precision-0.75: 0.7989 - val_precision-0.80: 0.8505 - val_precision-0.85: 0.8621 - val_precision-0.90: 0.8302 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3881 - val_recall-0.55: 0.3404 - val_recall-0.60: 0.2943 - val_recall-0.65: 0.2530 - val_recall-0.70: 0.2061 - val_recall-0.75: 0.1548 - val_recall-0.80: 0.0933 - val_recall-0.85: 0.0577 - val_recall-0.90: 0.0113 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7798 - tp: 16098.0000 - fp: 5950.0000 - tn: 48664.0000 - fn: 11209.0000 - accuracy: 0.6731 - precision: 0.7301 - precision-0.55: 0.7517 - precision-0.60: 0.7714 - precision-0.65: 0.7930 - precision-0.70: 0.8133 - precision-0.75: 0.8313 - precision-0.80: 0.8525 - precision-0.85: 0.8688 - precision-0.90: 0.9018 - precision-0.95: 0.8462 - recall: 0.5895 - recall-0.55: 0.5500 - recall-0.60: 0.5082 - recall-0.65: 0.4636 - recall-0.70: 0.4090 - recall-0.75: 0.3376 - recall-0.80: 0.2444 - recall-0.85: 0.1302 - recall-0.90: 0.0309 - recall-0.95: 4.0283e-04\n",
      "Epoch 5: val_loss did not improve from 0.96102\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.7798 - tp: 16098.0000 - fp: 5950.0000 - tn: 48664.0000 - fn: 11209.0000 - accuracy: 0.6731 - precision: 0.7301 - precision-0.55: 0.7517 - precision-0.60: 0.7714 - precision-0.65: 0.7930 - precision-0.70: 0.8133 - precision-0.75: 0.8313 - precision-0.80: 0.8525 - precision-0.85: 0.8688 - precision-0.90: 0.9018 - precision-0.95: 0.8462 - recall: 0.5895 - recall-0.55: 0.5500 - recall-0.60: 0.5082 - recall-0.65: 0.4636 - recall-0.70: 0.4090 - recall-0.75: 0.3376 - recall-0.80: 0.2444 - recall-0.85: 0.1302 - recall-0.90: 0.0309 - recall-0.95: 4.0283e-04 - val_loss: 0.9701 - val_tp: 1516.0000 - val_fp: 955.0000 - val_tn: 6847.0000 - val_fn: 2385.0000 - val_accuracy: 0.5140 - val_precision: 0.6135 - val_precision-0.55: 0.6583 - val_precision-0.60: 0.6872 - val_precision-0.65: 0.7206 - val_precision-0.70: 0.7623 - val_precision-0.75: 0.8021 - val_precision-0.80: 0.8397 - val_precision-0.85: 0.8710 - val_precision-0.90: 0.8136 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3886 - val_recall-0.55: 0.3422 - val_recall-0.60: 0.2917 - val_recall-0.65: 0.2512 - val_recall-0.70: 0.2097 - val_recall-0.75: 0.1559 - val_recall-0.80: 0.0954 - val_recall-0.85: 0.0623 - val_recall-0.90: 0.0123 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7752 - tp: 16120.0000 - fp: 5918.0000 - tn: 48696.0000 - fn: 11187.0000 - accuracy: 0.6743 - precision: 0.7315 - precision-0.55: 0.7556 - precision-0.60: 0.7762 - precision-0.65: 0.7943 - precision-0.70: 0.8133 - precision-0.75: 0.8341 - precision-0.80: 0.8504 - precision-0.85: 0.8697 - precision-0.90: 0.8947 - precision-0.95: 1.0000 - recall: 0.5903 - recall-0.55: 0.5491 - recall-0.60: 0.5078 - recall-0.65: 0.4620 - recall-0.70: 0.4089 - recall-0.75: 0.3371 - recall-0.80: 0.2503 - recall-0.85: 0.1367 - recall-0.90: 0.0314 - recall-0.95: 4.0283e-04\n",
      "Epoch 6: val_loss did not improve from 0.96102\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.7752 - tp: 16120.0000 - fp: 5918.0000 - tn: 48696.0000 - fn: 11187.0000 - accuracy: 0.6743 - precision: 0.7315 - precision-0.55: 0.7556 - precision-0.60: 0.7762 - precision-0.65: 0.7943 - precision-0.70: 0.8133 - precision-0.75: 0.8341 - precision-0.80: 0.8504 - precision-0.85: 0.8697 - precision-0.90: 0.8947 - precision-0.95: 1.0000 - recall: 0.5903 - recall-0.55: 0.5491 - recall-0.60: 0.5078 - recall-0.65: 0.4620 - recall-0.70: 0.4089 - recall-0.75: 0.3371 - recall-0.80: 0.2503 - recall-0.85: 0.1367 - recall-0.90: 0.0314 - recall-0.95: 4.0283e-04 - val_loss: 0.9709 - val_tp: 1541.0000 - val_fp: 969.0000 - val_tn: 6833.0000 - val_fn: 2360.0000 - val_accuracy: 0.5150 - val_precision: 0.6139 - val_precision-0.55: 0.6535 - val_precision-0.60: 0.6904 - val_precision-0.65: 0.7280 - val_precision-0.70: 0.7695 - val_precision-0.75: 0.8063 - val_precision-0.80: 0.8437 - val_precision-0.85: 0.8696 - val_precision-0.90: 0.7966 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3950 - val_recall-0.55: 0.3432 - val_recall-0.60: 0.2938 - val_recall-0.65: 0.2504 - val_recall-0.70: 0.2046 - val_recall-0.75: 0.1515 - val_recall-0.80: 0.0941 - val_recall-0.85: 0.0615 - val_recall-0.90: 0.0120 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7728 - tp: 16098.0000 - fp: 5860.0000 - tn: 48754.0000 - fn: 11209.0000 - accuracy: 0.6742 - precision: 0.7331 - precision-0.55: 0.7565 - precision-0.60: 0.7757 - precision-0.65: 0.7948 - precision-0.70: 0.8135 - precision-0.75: 0.8360 - precision-0.80: 0.8568 - precision-0.85: 0.8657 - precision-0.90: 0.9060 - precision-0.95: 1.0000 - recall: 0.5895 - recall-0.55: 0.5480 - recall-0.60: 0.5061 - recall-0.65: 0.4622 - recall-0.70: 0.4087 - recall-0.75: 0.3425 - recall-0.80: 0.2543 - recall-0.85: 0.1355 - recall-0.90: 0.0321 - recall-0.95: 2.9297e-04\n",
      "Epoch 7: val_loss did not improve from 0.96102\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.7728 - tp: 16098.0000 - fp: 5860.0000 - tn: 48754.0000 - fn: 11209.0000 - accuracy: 0.6742 - precision: 0.7331 - precision-0.55: 0.7565 - precision-0.60: 0.7757 - precision-0.65: 0.7948 - precision-0.70: 0.8135 - precision-0.75: 0.8360 - precision-0.80: 0.8568 - precision-0.85: 0.8657 - precision-0.90: 0.9060 - precision-0.95: 1.0000 - recall: 0.5895 - recall-0.55: 0.5480 - recall-0.60: 0.5061 - recall-0.65: 0.4622 - recall-0.70: 0.4087 - recall-0.75: 0.3425 - recall-0.80: 0.2543 - recall-0.85: 0.1355 - recall-0.90: 0.0321 - recall-0.95: 2.9297e-04 - val_loss: 0.9757 - val_tp: 1586.0000 - val_fp: 1030.0000 - val_tn: 6772.0000 - val_fn: 2315.0000 - val_accuracy: 0.5183 - val_precision: 0.6063 - val_precision-0.55: 0.6422 - val_precision-0.60: 0.6759 - val_precision-0.65: 0.7121 - val_precision-0.70: 0.7594 - val_precision-0.75: 0.7944 - val_precision-0.80: 0.8361 - val_precision-0.85: 0.8800 - val_precision-0.90: 0.8481 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4066 - val_recall-0.55: 0.3538 - val_recall-0.60: 0.3063 - val_recall-0.65: 0.2612 - val_recall-0.70: 0.2176 - val_recall-0.75: 0.1664 - val_recall-0.80: 0.1046 - val_recall-0.85: 0.0677 - val_recall-0.90: 0.0172 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7702 - tp: 16233.0000 - fp: 5870.0000 - tn: 48744.0000 - fn: 11074.0000 - accuracy: 0.6784 - precision: 0.7344 - precision-0.55: 0.7562 - precision-0.60: 0.7768 - precision-0.65: 0.7957 - precision-0.70: 0.8123 - precision-0.75: 0.8349 - precision-0.80: 0.8555 - precision-0.85: 0.8703 - precision-0.90: 0.9023 - precision-0.95: 1.0000 - recall: 0.5945 - recall-0.55: 0.5523 - recall-0.60: 0.5120 - recall-0.65: 0.4659 - recall-0.70: 0.4137 - recall-0.75: 0.3484 - recall-0.80: 0.2603 - recall-0.85: 0.1430 - recall-0.90: 0.0365 - recall-0.95: 1.8310e-04\n",
      "Epoch 8: val_loss did not improve from 0.96102\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.7702 - tp: 16233.0000 - fp: 5870.0000 - tn: 48744.0000 - fn: 11074.0000 - accuracy: 0.6784 - precision: 0.7344 - precision-0.55: 0.7562 - precision-0.60: 0.7768 - precision-0.65: 0.7957 - precision-0.70: 0.8123 - precision-0.75: 0.8349 - precision-0.80: 0.8555 - precision-0.85: 0.8703 - precision-0.90: 0.9023 - precision-0.95: 1.0000 - recall: 0.5945 - recall-0.55: 0.5523 - recall-0.60: 0.5120 - recall-0.65: 0.4659 - recall-0.70: 0.4137 - recall-0.75: 0.3484 - recall-0.80: 0.2603 - recall-0.85: 0.1430 - recall-0.90: 0.0365 - recall-0.95: 1.8310e-04 - val_loss: 0.9861 - val_tp: 1610.0000 - val_fp: 1112.0000 - val_tn: 6690.0000 - val_fn: 2291.0000 - val_accuracy: 0.5155 - val_precision: 0.5915 - val_precision-0.55: 0.6272 - val_precision-0.60: 0.6629 - val_precision-0.65: 0.7019 - val_precision-0.70: 0.7482 - val_precision-0.75: 0.7942 - val_precision-0.80: 0.8313 - val_precision-0.85: 0.8818 - val_precision-0.90: 0.8333 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4127 - val_recall-0.55: 0.3666 - val_recall-0.60: 0.3130 - val_recall-0.65: 0.2674 - val_recall-0.70: 0.2179 - val_recall-0.75: 0.1671 - val_recall-0.80: 0.1048 - val_recall-0.85: 0.0669 - val_recall-0.90: 0.0154 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 216 720 709 588 589 581 217 721 312]\n",
      "Epoch 8: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0476 - tp: 1156.0000 - fp: 1093.0000 - tn: 6709.0000 - fn: 2745.0000 - accuracy: 0.4732 - precision: 0.5140 - precision-0.55: 0.5319 - precision-0.60: 0.5403 - precision-0.65: 0.5749 - precision-0.70: 0.6092 - precision-0.75: 0.6463 - precision-0.80: 0.5882 - precision-0.85: 0.6471 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.2963 - recall-0.55: 0.2179 - recall-0.60: 0.1410 - recall-0.65: 0.0787 - recall-0.70: 0.0443 - recall-0.75: 0.0244 - recall-0.80: 0.0103 - recall-0.85: 0.0028 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      1935\n",
      "           1       0.41      0.06      0.10       866\n",
      "           2       0.33      0.55      0.42      1100\n",
      "\n",
      "    accuracy                           0.47      3901\n",
      "   macro avg       0.45      0.41      0.38      3901\n",
      "weighted avg       0.49      0.47      0.44      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0   P1    P2  Total    RP0    RP1    RP2\n",
      "0      1190   47   698   1935  0.615  0.024  0.361\n",
      "1       303   49   514    866  0.350  0.057  0.594\n",
      "2       470   23   607   1100  0.427  0.021  0.552\n",
      "Total  1963  119  1819   3901  0.503  0.031  0.466\n",
      "\n",
      ">>>>>> FOLD 8\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 31208, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 18578(59.53%)\n",
      "Label 1: 6196(19.85%)\n",
      "Label 2: 6434(20.62%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 1935(49.6%)\n",
      "Label 1: 866(22.2%)\n",
      "Label 2: 1100(28.2%)\n",
      "\n",
      "Test:\n",
      "Label 0: 2510(64.34%)\n",
      "Label 1: 676(17.33%)\n",
      "Label 2: 715(18.33%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.7194852690640631, -0.3785888933460594, -0.34089638708501147]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.9326 - tp: 16911.0000 - fp: 9830.0000 - tn: 60388.0000 - fn: 18198.0000 - accuracy: 0.5852 - precision: 0.6324 - precision-0.55: 0.6523 - precision-0.60: 0.6736 - precision-0.65: 0.6966 - precision-0.70: 0.7163 - precision-0.75: 0.7332 - precision-0.80: 0.7199 - precision-0.85: 0.7551 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4817 - recall-0.55: 0.4157 - recall-0.60: 0.3275 - recall-0.65: 0.2235 - recall-0.70: 0.1198 - recall-0.75: 0.0439 - recall-0.80: 0.0104 - recall-0.85: 0.0011 - recall-0.90: 5.6965e-05 - recall-0.95: 0.0000e+00    \n",
      "Epoch 1: val_loss improved from inf to 1.00823, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 6s 104ms/step - loss: 0.9326 - tp: 16911.0000 - fp: 9830.0000 - tn: 60388.0000 - fn: 18198.0000 - accuracy: 0.5852 - precision: 0.6324 - precision-0.55: 0.6523 - precision-0.60: 0.6736 - precision-0.65: 0.6966 - precision-0.70: 0.7163 - precision-0.75: 0.7332 - precision-0.80: 0.7199 - precision-0.85: 0.7551 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4817 - recall-0.55: 0.4157 - recall-0.60: 0.3275 - recall-0.65: 0.2235 - recall-0.70: 0.1198 - recall-0.75: 0.0439 - recall-0.80: 0.0104 - recall-0.85: 0.0011 - recall-0.90: 5.6965e-05 - recall-0.95: 0.0000e+00 - val_loss: 1.0082 - val_tp: 808.0000 - val_fp: 522.0000 - val_tn: 7280.0000 - val_fn: 3093.0000 - val_accuracy: 0.5386 - val_precision: 0.6075 - val_precision-0.55: 0.6132 - val_precision-0.60: 0.6250 - val_precision-0.65: 0.4667 - val_precision-0.70: 0.0000e+00 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.2071 - val_recall-0.55: 0.0736 - val_recall-0.60: 0.0167 - val_recall-0.65: 0.0018 - val_recall-0.70: 0.0000e+00 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.8425 - tp: 17248.0000 - fp: 7231.0000 - tn: 55185.0000 - fn: 13960.0000 - accuracy: 0.6371 - precision: 0.7046 - precision-0.55: 0.7301 - precision-0.60: 0.7531 - precision-0.65: 0.7775 - precision-0.70: 0.8009 - precision-0.75: 0.8324 - precision-0.80: 0.8476 - precision-0.85: 0.8637 - precision-0.90: 0.9130 - precision-0.95: 0.0000e+00 - recall: 0.5527 - recall-0.55: 0.5104 - recall-0.60: 0.4565 - recall-0.65: 0.3866 - recall-0.70: 0.2951 - recall-0.75: 0.1903 - recall-0.80: 0.0875 - recall-0.85: 0.0205 - recall-0.90: 0.0013 - recall-0.95: 0.0000e+00 \n",
      "Epoch 2: val_loss did not improve from 1.00823\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.8425 - tp: 17248.0000 - fp: 7231.0000 - tn: 55185.0000 - fn: 13960.0000 - accuracy: 0.6371 - precision: 0.7046 - precision-0.55: 0.7301 - precision-0.60: 0.7531 - precision-0.65: 0.7775 - precision-0.70: 0.8009 - precision-0.75: 0.8324 - precision-0.80: 0.8476 - precision-0.85: 0.8637 - precision-0.90: 0.9130 - precision-0.95: 0.0000e+00 - recall: 0.5527 - recall-0.55: 0.5104 - recall-0.60: 0.4565 - recall-0.65: 0.3866 - recall-0.70: 0.2951 - recall-0.75: 0.1903 - recall-0.80: 0.0875 - recall-0.85: 0.0205 - recall-0.90: 0.0013 - recall-0.95: 0.0000e+00 - val_loss: 1.0220 - val_tp: 714.0000 - val_fp: 512.0000 - val_tn: 7290.0000 - val_fn: 3187.0000 - val_accuracy: 0.5060 - val_precision: 0.5824 - val_precision-0.55: 0.6033 - val_precision-0.60: 0.6407 - val_precision-0.65: 0.7021 - val_precision-0.70: 0.6667 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.1830 - val_recall-0.55: 0.0951 - val_recall-0.60: 0.0379 - val_recall-0.65: 0.0085 - val_recall-0.70: 5.1269e-04 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.8171 - tp: 17349.0000 - fp: 6901.0000 - tn: 55515.0000 - fn: 13859.0000 - accuracy: 0.6489 - precision: 0.7154 - precision-0.55: 0.7391 - precision-0.60: 0.7623 - precision-0.65: 0.7815 - precision-0.70: 0.8025 - precision-0.75: 0.8270 - precision-0.80: 0.8495 - precision-0.85: 0.8674 - precision-0.90: 0.8907 - precision-0.95: 1.0000 - recall: 0.5559 - recall-0.55: 0.5120 - recall-0.60: 0.4688 - recall-0.65: 0.4172 - recall-0.70: 0.3522 - recall-0.75: 0.2695 - recall-0.80: 0.1711 - recall-0.85: 0.0706 - recall-0.90: 0.0107 - recall-0.95: 6.4086e-05\n",
      "Epoch 3: val_loss improved from 1.00823 to 1.00548, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.8171 - tp: 17349.0000 - fp: 6901.0000 - tn: 55515.0000 - fn: 13859.0000 - accuracy: 0.6489 - precision: 0.7154 - precision-0.55: 0.7391 - precision-0.60: 0.7623 - precision-0.65: 0.7815 - precision-0.70: 0.8025 - precision-0.75: 0.8270 - precision-0.80: 0.8495 - precision-0.85: 0.8674 - precision-0.90: 0.8907 - precision-0.95: 1.0000 - recall: 0.5559 - recall-0.55: 0.5120 - recall-0.60: 0.4688 - recall-0.65: 0.4172 - recall-0.70: 0.3522 - recall-0.75: 0.2695 - recall-0.80: 0.1711 - recall-0.85: 0.0706 - recall-0.90: 0.0107 - recall-0.95: 6.4086e-05 - val_loss: 1.0055 - val_tp: 1001.0000 - val_fp: 703.0000 - val_tn: 7099.0000 - val_fn: 2900.0000 - val_accuracy: 0.5291 - val_precision: 0.5874 - val_precision-0.55: 0.6111 - val_precision-0.60: 0.6329 - val_precision-0.65: 0.6667 - val_precision-0.70: 0.5625 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.2566 - val_recall-0.55: 0.1559 - val_recall-0.60: 0.0769 - val_recall-0.65: 0.0272 - val_recall-0.70: 0.0023 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8092 - tp: 17120.0000 - fp: 6770.0000 - tn: 54670.0000 - fn: 13600.0000 - accuracy: 0.6521 - precision: 0.7166 - precision-0.55: 0.7419 - precision-0.60: 0.7618 - precision-0.65: 0.7825 - precision-0.70: 0.8035 - precision-0.75: 0.8240 - precision-0.80: 0.8471 - precision-0.85: 0.8646 - precision-0.90: 0.9289 - precision-0.95: 1.0000 - recall: 0.5573 - recall-0.55: 0.5178 - recall-0.60: 0.4751 - recall-0.65: 0.4292 - recall-0.70: 0.3718 - recall-0.75: 0.2980 - recall-0.80: 0.2067 - recall-0.85: 0.0981 - recall-0.90: 0.0204 - recall-0.95: 1.6276e-04\n",
      "Epoch 4: val_loss improved from 1.00548 to 1.00476, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.8091 - tp: 17384.0000 - fp: 6877.0000 - tn: 55539.0000 - fn: 13824.0000 - accuracy: 0.6518 - precision: 0.7165 - precision-0.55: 0.7417 - precision-0.60: 0.7616 - precision-0.65: 0.7822 - precision-0.70: 0.8038 - precision-0.75: 0.8246 - precision-0.80: 0.8478 - precision-0.85: 0.8660 - precision-0.90: 0.9287 - precision-0.95: 1.0000 - recall: 0.5570 - recall-0.55: 0.5176 - recall-0.60: 0.4751 - recall-0.65: 0.4292 - recall-0.70: 0.3721 - recall-0.75: 0.2984 - recall-0.80: 0.2069 - recall-0.85: 0.0981 - recall-0.90: 0.0204 - recall-0.95: 1.9226e-04 - val_loss: 1.0048 - val_tp: 980.0000 - val_fp: 666.0000 - val_tn: 7136.0000 - val_fn: 2921.0000 - val_accuracy: 0.5314 - val_precision: 0.5954 - val_precision-0.55: 0.6136 - val_precision-0.60: 0.6250 - val_precision-0.65: 0.6667 - val_precision-0.70: 0.6364 - val_precision-0.75: 0.5000 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.2512 - val_recall-0.55: 0.1482 - val_recall-0.60: 0.0679 - val_recall-0.65: 0.0226 - val_recall-0.70: 0.0018 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8015 - tp: 17194.0000 - fp: 6629.0000 - tn: 54811.0000 - fn: 13526.0000 - accuracy: 0.6561 - precision: 0.7217 - precision-0.55: 0.7481 - precision-0.60: 0.7695 - precision-0.65: 0.7902 - precision-0.70: 0.8112 - precision-0.75: 0.8298 - precision-0.80: 0.8519 - precision-0.85: 0.8731 - precision-0.90: 0.9021 - precision-0.95: 0.8000 - recall: 0.5597 - recall-0.55: 0.5179 - recall-0.60: 0.4730 - recall-0.65: 0.4272 - recall-0.70: 0.3713 - recall-0.75: 0.2970 - recall-0.80: 0.2088 - recall-0.85: 0.1019 - recall-0.90: 0.0198 - recall-0.95: 1.3021e-04\n",
      "Epoch 5: val_loss improved from 1.00476 to 0.99037, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.8012 - tp: 17480.0000 - fp: 6728.0000 - tn: 55688.0000 - fn: 13728.0000 - accuracy: 0.6562 - precision: 0.7221 - precision-0.55: 0.7485 - precision-0.60: 0.7699 - precision-0.65: 0.7905 - precision-0.70: 0.8114 - precision-0.75: 0.8300 - precision-0.80: 0.8519 - precision-0.85: 0.8727 - precision-0.90: 0.9001 - precision-0.95: 0.8000 - recall: 0.5601 - recall-0.55: 0.5184 - recall-0.60: 0.4732 - recall-0.65: 0.4274 - recall-0.70: 0.3715 - recall-0.75: 0.2973 - recall-0.80: 0.2093 - recall-0.85: 0.1022 - recall-0.90: 0.0199 - recall-0.95: 1.2817e-04 - val_loss: 0.9904 - val_tp: 1307.0000 - val_fp: 958.0000 - val_tn: 6844.0000 - val_fn: 2594.0000 - val_accuracy: 0.5586 - val_precision: 0.5770 - val_precision-0.55: 0.5862 - val_precision-0.60: 0.6108 - val_precision-0.65: 0.6416 - val_precision-0.70: 0.5921 - val_precision-0.75: 0.5000 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3350 - val_recall-0.55: 0.2284 - val_recall-0.60: 0.1300 - val_recall-0.65: 0.0569 - val_recall-0.70: 0.0115 - val_recall-0.75: 5.1269e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7968 - tp: 17327.0000 - fp: 6606.0000 - tn: 54834.0000 - fn: 13393.0000 - accuracy: 0.6599 - precision: 0.7240 - precision-0.55: 0.7472 - precision-0.60: 0.7692 - precision-0.65: 0.7897 - precision-0.70: 0.8095 - precision-0.75: 0.8315 - precision-0.80: 0.8487 - precision-0.85: 0.8674 - precision-0.90: 0.9036 - precision-0.95: 0.8571 - recall: 0.5640 - recall-0.55: 0.5196 - recall-0.60: 0.4773 - recall-0.65: 0.4335 - recall-0.70: 0.3817 - recall-0.75: 0.3134 - recall-0.80: 0.2263 - recall-0.85: 0.1182 - recall-0.90: 0.0253 - recall-0.95: 1.9531e-04\n",
      "Epoch 6: val_loss improved from 0.99037 to 0.98693, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.7972 - tp: 17583.0000 - fp: 6708.0000 - tn: 55708.0000 - fn: 13625.0000 - accuracy: 0.6595 - precision: 0.7238 - precision-0.55: 0.7470 - precision-0.60: 0.7691 - precision-0.65: 0.7894 - precision-0.70: 0.8090 - precision-0.75: 0.8311 - precision-0.80: 0.8484 - precision-0.85: 0.8673 - precision-0.90: 0.9042 - precision-0.95: 0.8571 - recall: 0.5634 - recall-0.55: 0.5190 - recall-0.60: 0.4767 - recall-0.65: 0.4328 - recall-0.70: 0.3811 - recall-0.75: 0.3131 - recall-0.80: 0.2259 - recall-0.85: 0.1180 - recall-0.90: 0.0254 - recall-0.95: 1.9226e-04 - val_loss: 0.9869 - val_tp: 1264.0000 - val_fp: 858.0000 - val_tn: 6944.0000 - val_fn: 2637.0000 - val_accuracy: 0.5591 - val_precision: 0.5957 - val_precision-0.55: 0.6184 - val_precision-0.60: 0.6229 - val_precision-0.65: 0.7019 - val_precision-0.70: 0.5882 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3240 - val_recall-0.55: 0.2135 - val_recall-0.60: 0.1156 - val_recall-0.65: 0.0477 - val_recall-0.70: 0.0051 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7929 - tp: 17329.0000 - fp: 6515.0000 - tn: 54925.0000 - fn: 13391.0000 - accuracy: 0.6604 - precision: 0.7268 - precision-0.55: 0.7498 - precision-0.60: 0.7711 - precision-0.65: 0.7905 - precision-0.70: 0.8106 - precision-0.75: 0.8341 - precision-0.80: 0.8573 - precision-0.85: 0.8696 - precision-0.90: 0.9080 - precision-0.95: 1.0000 - recall: 0.5641 - recall-0.55: 0.5198 - recall-0.60: 0.4771 - recall-0.65: 0.4328 - recall-0.70: 0.3828 - recall-0.75: 0.3149 - recall-0.80: 0.2302 - recall-0.85: 0.1209 - recall-0.90: 0.0260 - recall-0.95: 1.9531e-04\n",
      "Epoch 7: val_loss did not improve from 0.98693\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.7928 - tp: 17611.0000 - fp: 6606.0000 - tn: 55810.0000 - fn: 13597.0000 - accuracy: 0.6607 - precision: 0.7272 - precision-0.55: 0.7504 - precision-0.60: 0.7719 - precision-0.65: 0.7911 - precision-0.70: 0.8111 - precision-0.75: 0.8344 - precision-0.80: 0.8578 - precision-0.85: 0.8694 - precision-0.90: 0.9064 - precision-0.95: 1.0000 - recall: 0.5643 - recall-0.55: 0.5198 - recall-0.60: 0.4771 - recall-0.65: 0.4326 - recall-0.70: 0.3825 - recall-0.75: 0.3144 - recall-0.80: 0.2299 - recall-0.85: 0.1203 - recall-0.90: 0.0258 - recall-0.95: 1.9226e-04 - val_loss: 0.9931 - val_tp: 1184.0000 - val_fp: 810.0000 - val_tn: 6992.0000 - val_fn: 2717.0000 - val_accuracy: 0.5488 - val_precision: 0.5938 - val_precision-0.55: 0.6214 - val_precision-0.60: 0.6426 - val_precision-0.65: 0.6772 - val_precision-0.70: 0.6364 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3035 - val_recall-0.55: 0.1910 - val_recall-0.60: 0.0982 - val_recall-0.65: 0.0328 - val_recall-0.70: 0.0036 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7903 - tp: 17378.0000 - fp: 6474.0000 - tn: 54966.0000 - fn: 13342.0000 - accuracy: 0.6626 - precision: 0.7286 - precision-0.55: 0.7525 - precision-0.60: 0.7726 - precision-0.65: 0.7909 - precision-0.70: 0.8124 - precision-0.75: 0.8357 - precision-0.80: 0.8561 - precision-0.85: 0.8708 - precision-0.90: 0.8997 - precision-0.95: 1.0000 - recall: 0.5657 - recall-0.55: 0.5224 - recall-0.60: 0.4783 - recall-0.65: 0.4333 - recall-0.70: 0.3831 - recall-0.75: 0.3192 - recall-0.80: 0.2340 - recall-0.85: 0.1284 - recall-0.90: 0.0280 - recall-0.95: 1.6276e-04\n",
      "Epoch 8: val_loss did not improve from 0.98693\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.7903 - tp: 17654.0000 - fp: 6580.0000 - tn: 55836.0000 - fn: 13554.0000 - accuracy: 0.6625 - precision: 0.7285 - precision-0.55: 0.7526 - precision-0.60: 0.7726 - precision-0.65: 0.7909 - precision-0.70: 0.8125 - precision-0.75: 0.8357 - precision-0.80: 0.8557 - precision-0.85: 0.8714 - precision-0.90: 0.9007 - precision-0.95: 1.0000 - recall: 0.5657 - recall-0.55: 0.5226 - recall-0.60: 0.4785 - recall-0.65: 0.4335 - recall-0.70: 0.3831 - recall-0.75: 0.3193 - recall-0.80: 0.2343 - recall-0.85: 0.1283 - recall-0.90: 0.0279 - recall-0.95: 1.6022e-04 - val_loss: 0.9948 - val_tp: 1102.0000 - val_fp: 738.0000 - val_tn: 7064.0000 - val_fn: 2799.0000 - val_accuracy: 0.5414 - val_precision: 0.5989 - val_precision-0.55: 0.6216 - val_precision-0.60: 0.6453 - val_precision-0.65: 0.7252 - val_precision-0.70: 0.6667 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.2825 - val_recall-0.55: 0.1697 - val_recall-0.60: 0.0825 - val_recall-0.65: 0.0244 - val_recall-0.70: 0.0015 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7874 - tp: 17368.0000 - fp: 6341.0000 - tn: 55099.0000 - fn: 13352.0000 - accuracy: 0.6653 - precision: 0.7325 - precision-0.55: 0.7573 - precision-0.60: 0.7779 - precision-0.65: 0.7972 - precision-0.70: 0.8145 - precision-0.75: 0.8361 - precision-0.80: 0.8537 - precision-0.85: 0.8713 - precision-0.90: 0.9077 - precision-0.95: 0.7500 - recall: 0.5654 - recall-0.55: 0.5210 - recall-0.60: 0.4760 - recall-0.65: 0.4307 - recall-0.70: 0.3803 - recall-0.75: 0.3179 - recall-0.80: 0.2323 - recall-0.85: 0.1272 - recall-0.90: 0.0262 - recall-0.95: 9.7656e-05\n",
      "Epoch 9: val_loss improved from 0.98693 to 0.98309, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154706.h5\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.7872 - tp: 17654.0000 - fp: 6450.0000 - tn: 55966.0000 - fn: 13554.0000 - accuracy: 0.6654 - precision: 0.7324 - precision-0.55: 0.7571 - precision-0.60: 0.7778 - precision-0.65: 0.7974 - precision-0.70: 0.8144 - precision-0.75: 0.8357 - precision-0.80: 0.8536 - precision-0.85: 0.8710 - precision-0.90: 0.9084 - precision-0.95: 0.7500 - recall: 0.5657 - recall-0.55: 0.5211 - recall-0.60: 0.4764 - recall-0.65: 0.4314 - recall-0.70: 0.3809 - recall-0.75: 0.3183 - recall-0.80: 0.2325 - recall-0.85: 0.1276 - recall-0.90: 0.0267 - recall-0.95: 9.6129e-05 - val_loss: 0.9831 - val_tp: 1337.0000 - val_fp: 895.0000 - val_tn: 6907.0000 - val_fn: 2564.0000 - val_accuracy: 0.5565 - val_precision: 0.5990 - val_precision-0.55: 0.6223 - val_precision-0.60: 0.6230 - val_precision-0.65: 0.7087 - val_precision-0.70: 0.6296 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3427 - val_recall-0.55: 0.2328 - val_recall-0.60: 0.1318 - val_recall-0.65: 0.0605 - val_recall-0.70: 0.0087 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7852 - tp: 17665.0000 - fp: 6457.0000 - tn: 55959.0000 - fn: 13543.0000 - accuracy: 0.6666 - precision: 0.7323 - precision-0.55: 0.7562 - precision-0.60: 0.7762 - precision-0.65: 0.7944 - precision-0.70: 0.8176 - precision-0.75: 0.8383 - precision-0.80: 0.8612 - precision-0.85: 0.8753 - precision-0.90: 0.8901 - precision-0.95: 1.0000 - recall: 0.5660 - recall-0.55: 0.5228 - recall-0.60: 0.4774 - recall-0.65: 0.4331 - recall-0.70: 0.3827 - recall-0.75: 0.3184 - recall-0.80: 0.2345 - recall-0.85: 0.1282 - recall-0.90: 0.0244 - recall-0.95: 3.2043e-05\n",
      "Epoch 10: val_loss did not improve from 0.98309\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.7852 - tp: 17665.0000 - fp: 6457.0000 - tn: 55959.0000 - fn: 13543.0000 - accuracy: 0.6666 - precision: 0.7323 - precision-0.55: 0.7562 - precision-0.60: 0.7762 - precision-0.65: 0.7944 - precision-0.70: 0.8176 - precision-0.75: 0.8383 - precision-0.80: 0.8612 - precision-0.85: 0.8753 - precision-0.90: 0.8901 - precision-0.95: 1.0000 - recall: 0.5660 - recall-0.55: 0.5228 - recall-0.60: 0.4774 - recall-0.65: 0.4331 - recall-0.70: 0.3827 - recall-0.75: 0.3184 - recall-0.80: 0.2345 - recall-0.85: 0.1282 - recall-0.90: 0.0244 - recall-0.95: 3.2043e-05 - val_loss: 0.9888 - val_tp: 1291.0000 - val_fp: 920.0000 - val_tn: 6882.0000 - val_fn: 2610.0000 - val_accuracy: 0.5627 - val_precision: 0.5839 - val_precision-0.55: 0.6117 - val_precision-0.60: 0.6337 - val_precision-0.65: 0.7295 - val_precision-0.70: 0.4839 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3309 - val_recall-0.55: 0.2169 - val_recall-0.60: 0.1233 - val_recall-0.65: 0.0526 - val_recall-0.70: 0.0038 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7825 - tp: 17671.0000 - fp: 6384.0000 - tn: 56032.0000 - fn: 13537.0000 - accuracy: 0.6669 - precision: 0.7346 - precision-0.55: 0.7580 - precision-0.60: 0.7786 - precision-0.65: 0.7973 - precision-0.70: 0.8167 - precision-0.75: 0.8379 - precision-0.80: 0.8596 - precision-0.85: 0.8720 - precision-0.90: 0.9047 - precision-0.95: 0.8000 - recall: 0.5662 - recall-0.55: 0.5223 - recall-0.60: 0.4771 - recall-0.65: 0.4333 - recall-0.70: 0.3832 - recall-0.75: 0.3206 - recall-0.80: 0.2385 - recall-0.85: 0.1306 - recall-0.90: 0.0274 - recall-0.95: 1.2817e-04\n",
      "Epoch 11: val_loss did not improve from 0.98309\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.7825 - tp: 17671.0000 - fp: 6384.0000 - tn: 56032.0000 - fn: 13537.0000 - accuracy: 0.6669 - precision: 0.7346 - precision-0.55: 0.7580 - precision-0.60: 0.7786 - precision-0.65: 0.7973 - precision-0.70: 0.8167 - precision-0.75: 0.8379 - precision-0.80: 0.8596 - precision-0.85: 0.8720 - precision-0.90: 0.9047 - precision-0.95: 0.8000 - recall: 0.5662 - recall-0.55: 0.5223 - recall-0.60: 0.4771 - recall-0.65: 0.4333 - recall-0.70: 0.3832 - recall-0.75: 0.3206 - recall-0.80: 0.2385 - recall-0.85: 0.1306 - recall-0.90: 0.0274 - recall-0.95: 1.2817e-04 - val_loss: 0.9863 - val_tp: 1280.0000 - val_fp: 873.0000 - val_tn: 6929.0000 - val_fn: 2621.0000 - val_accuracy: 0.5570 - val_precision: 0.5945 - val_precision-0.55: 0.6206 - val_precision-0.60: 0.6369 - val_precision-0.65: 0.7148 - val_precision-0.70: 0.7368 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3281 - val_recall-0.55: 0.2143 - val_recall-0.60: 0.1205 - val_recall-0.65: 0.0508 - val_recall-0.70: 0.0072 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 12/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7802 - tp: 17436.0000 - fp: 6311.0000 - tn: 55129.0000 - fn: 13284.0000 - accuracy: 0.6697 - precision: 0.7342 - precision-0.55: 0.7590 - precision-0.60: 0.7791 - precision-0.65: 0.7988 - precision-0.70: 0.8168 - precision-0.75: 0.8378 - precision-0.80: 0.8586 - precision-0.85: 0.8753 - precision-0.90: 0.8919 - precision-0.95: 1.0000 - recall: 0.5676 - recall-0.55: 0.5234 - recall-0.60: 0.4804 - recall-0.65: 0.4351 - recall-0.70: 0.3839 - recall-0.75: 0.3228 - recall-0.80: 0.2436 - recall-0.85: 0.1418 - recall-0.90: 0.0339 - recall-0.95: 9.7656e-05\n",
      "Epoch 12: val_loss did not improve from 0.98309\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.7805 - tp: 17708.0000 - fp: 6415.0000 - tn: 56001.0000 - fn: 13500.0000 - accuracy: 0.6693 - precision: 0.7341 - precision-0.55: 0.7589 - precision-0.60: 0.7788 - precision-0.65: 0.7984 - precision-0.70: 0.8168 - precision-0.75: 0.8376 - precision-0.80: 0.8585 - precision-0.85: 0.8747 - precision-0.90: 0.8921 - precision-0.95: 1.0000 - recall: 0.5674 - recall-0.55: 0.5232 - recall-0.60: 0.4803 - recall-0.65: 0.4351 - recall-0.70: 0.3840 - recall-0.75: 0.3228 - recall-0.80: 0.2436 - recall-0.85: 0.1418 - recall-0.90: 0.0339 - recall-0.95: 9.6129e-05 - val_loss: 0.9891 - val_tp: 1290.0000 - val_fp: 890.0000 - val_tn: 6912.0000 - val_fn: 2611.0000 - val_accuracy: 0.5586 - val_precision: 0.5917 - val_precision-0.55: 0.6149 - val_precision-0.60: 0.6316 - val_precision-0.65: 0.7254 - val_precision-0.70: 0.5789 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3307 - val_recall-0.55: 0.2215 - val_recall-0.60: 0.1248 - val_recall-0.65: 0.0549 - val_recall-0.70: 0.0056 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 13/200\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.7797 - tp: 17517.0000 - fp: 6339.0000 - tn: 55101.0000 - fn: 13203.0000 - accuracy: 0.6690 - precision: 0.7343 - precision-0.55: 0.7582 - precision-0.60: 0.7794 - precision-0.65: 0.7984 - precision-0.70: 0.8186 - precision-0.75: 0.8387 - precision-0.80: 0.8592 - precision-0.85: 0.8817 - precision-0.90: 0.8825 - precision-0.95: 0.0000e+00 - recall: 0.5702 - recall-0.55: 0.5266 - recall-0.60: 0.4843 - recall-0.65: 0.4378 - recall-0.70: 0.3869 - recall-0.75: 0.3227 - recall-0.80: 0.2401 - recall-0.85: 0.1366 - recall-0.90: 0.0298 - recall-0.95: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from 0.98309\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.7793 - tp: 17790.0000 - fp: 6435.0000 - tn: 55981.0000 - fn: 13418.0000 - accuracy: 0.6689 - precision: 0.7344 - precision-0.55: 0.7586 - precision-0.60: 0.7797 - precision-0.65: 0.7989 - precision-0.70: 0.8193 - precision-0.75: 0.8393 - precision-0.80: 0.8605 - precision-0.85: 0.8826 - precision-0.90: 0.8836 - precision-0.95: 0.0000e+00 - recall: 0.5700 - recall-0.55: 0.5265 - recall-0.60: 0.4840 - recall-0.65: 0.4376 - recall-0.70: 0.3866 - recall-0.75: 0.3226 - recall-0.80: 0.2399 - recall-0.85: 0.1364 - recall-0.90: 0.0297 - recall-0.95: 0.0000e+00 - val_loss: 0.9884 - val_tp: 1200.0000 - val_fp: 795.0000 - val_tn: 7007.0000 - val_fn: 2701.0000 - val_accuracy: 0.5529 - val_precision: 0.6015 - val_precision-0.55: 0.6318 - val_precision-0.60: 0.6479 - val_precision-0.65: 0.7358 - val_precision-0.70: 0.7500 - val_precision-0.75: 0.5000 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3076 - val_recall-0.55: 0.1997 - val_recall-0.60: 0.1061 - val_recall-0.65: 0.0400 - val_recall-0.70: 0.0046 - val_recall-0.75: 5.1269e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7772 - tp: 17881.0000 - fp: 6400.0000 - tn: 56016.0000 - fn: 13327.0000 - accuracy: 0.6708 - precision: 0.7364 - precision-0.55: 0.7588 - precision-0.60: 0.7802 - precision-0.65: 0.7993 - precision-0.70: 0.8197 - precision-0.75: 0.8425 - precision-0.80: 0.8612 - precision-0.85: 0.8785 - precision-0.90: 0.9018 - precision-0.95: 1.0000 - recall: 0.5730 - recall-0.55: 0.5281 - recall-0.60: 0.4825 - recall-0.65: 0.4383 - recall-0.70: 0.3876 - recall-0.75: 0.3266 - recall-0.80: 0.2464 - recall-0.85: 0.1411 - recall-0.90: 0.0333 - recall-0.95: 1.6022e-04\n",
      "Epoch 14: val_loss did not improve from 0.98309\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.7772 - tp: 17881.0000 - fp: 6400.0000 - tn: 56016.0000 - fn: 13327.0000 - accuracy: 0.6708 - precision: 0.7364 - precision-0.55: 0.7588 - precision-0.60: 0.7802 - precision-0.65: 0.7993 - precision-0.70: 0.8197 - precision-0.75: 0.8425 - precision-0.80: 0.8612 - precision-0.85: 0.8785 - precision-0.90: 0.9018 - precision-0.95: 1.0000 - recall: 0.5730 - recall-0.55: 0.5281 - recall-0.60: 0.4825 - recall-0.65: 0.4383 - recall-0.70: 0.3876 - recall-0.75: 0.3266 - recall-0.80: 0.2464 - recall-0.85: 0.1411 - recall-0.90: 0.0333 - recall-0.95: 1.6022e-04 - val_loss: 0.9931 - val_tp: 1186.0000 - val_fp: 808.0000 - val_tn: 6994.0000 - val_fn: 2715.0000 - val_accuracy: 0.5552 - val_precision: 0.5948 - val_precision-0.55: 0.6220 - val_precision-0.60: 0.6618 - val_precision-0.65: 0.7398 - val_precision-0.70: 0.6500 - val_precision-0.75: 0.3333 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3040 - val_recall-0.55: 0.1902 - val_recall-0.60: 0.1048 - val_recall-0.65: 0.0372 - val_recall-0.70: 0.0033 - val_recall-0.75: 2.5634e-04 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 720 216 709 721 576 579  84 577 693]\n",
      "Epoch 14: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9539 - tp: 1679.0000 - fp: 872.0000 - tn: 6930.0000 - fn: 2222.0000 - accuracy: 0.5924 - precision: 0.6582 - precision-0.55: 0.6694 - precision-0.60: 0.7078 - precision-0.65: 0.7302 - precision-0.70: 0.7434 - precision-0.75: 0.7778 - precision-0.80: 0.8684 - precision-0.85: 0.0000e+00 - precision-0.90: 0.0000e+00 - precision-0.95: 0.0000e+00 - recall: 0.4304 - recall-0.55: 0.3302 - recall-0.60: 0.2384 - recall-0.65: 0.1561 - recall-0.70: 0.0869 - recall-0.75: 0.0413 - recall-0.80: 0.0085 - recall-0.85: 0.0000e+00 - recall-0.90: 0.0000e+00 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.75      2510\n",
      "           1       0.18      0.10      0.13       676\n",
      "           2       0.34      0.15      0.21       715\n",
      "\n",
      "    accuracy                           0.59      3901\n",
      "   macro avg       0.39      0.37      0.36      3901\n",
      "weighted avg       0.52      0.59      0.54      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0   P1   P2  Total    RP0    RP1    RP2\n",
      "0      2138  230  142   2510  0.852  0.092  0.057\n",
      "1       543   66   67    676  0.803  0.098  0.099\n",
      "2       537   71  107    715  0.751  0.099  0.150\n",
      "Total  3218  367  316   3901  0.825  0.094  0.081\n",
      "\n",
      ">>>>>> FOLD 9\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 35109, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 20513(58.43%)\n",
      "Label 1: 7062(20.11%)\n",
      "Label 2: 7534(21.46%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 2510(64.34%)\n",
      "Label 1: 676(17.33%)\n",
      "Label 2: 715(18.33%)\n",
      "\n",
      "Test:\n",
      "Label 0: 2356(60.39%)\n",
      "Label 1: 687(17.61%)\n",
      "Label 2: 858(21.99%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.6893210839693629, -0.3770094498695751, -0.312311638421165]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9395 - tp: 18690.0000 - fp: 10598.0000 - tn: 67422.0000 - fn: 20320.0000 - accuracy: 0.5890 - precision: 0.6381 - precision-0.55: 0.6573 - precision-0.60: 0.6831 - precision-0.65: 0.7122 - precision-0.70: 0.7400 - precision-0.75: 0.7597 - precision-0.80: 0.7806 - precision-0.85: 0.8462 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4791 - recall-0.55: 0.4089 - recall-0.60: 0.3226 - recall-0.65: 0.2222 - recall-0.70: 0.1233 - recall-0.75: 0.0501 - recall-0.80: 0.0119 - recall-0.85: 0.0011 - recall-0.90: 2.5634e-05 - recall-0.95: 0.0000e+00    \n",
      "Epoch 1: val_loss improved from inf to 0.95127, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154735.h5\n",
      "35/35 [==============================] - 6s 97ms/step - loss: 0.9395 - tp: 18690.0000 - fp: 10598.0000 - tn: 67422.0000 - fn: 20320.0000 - accuracy: 0.5890 - precision: 0.6381 - precision-0.55: 0.6573 - precision-0.60: 0.6831 - precision-0.65: 0.7122 - precision-0.70: 0.7400 - precision-0.75: 0.7597 - precision-0.80: 0.7806 - precision-0.85: 0.8462 - precision-0.90: 1.0000 - precision-0.95: 0.0000e+00 - recall: 0.4791 - recall-0.55: 0.4089 - recall-0.60: 0.3226 - recall-0.65: 0.2222 - recall-0.70: 0.1233 - recall-0.75: 0.0501 - recall-0.80: 0.0119 - recall-0.85: 0.0011 - recall-0.90: 2.5634e-05 - recall-0.95: 0.0000e+00 - val_loss: 0.9513 - val_tp: 1380.0000 - val_fp: 723.0000 - val_tn: 7079.0000 - val_fn: 2521.0000 - val_accuracy: 0.6147 - val_precision: 0.6562 - val_precision-0.55: 0.6893 - val_precision-0.60: 0.6859 - val_precision-0.65: 0.6355 - val_precision-0.70: 0.8333 - val_precision-0.75: 0.0000e+00 - val_precision-0.80: 0.0000e+00 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.3538 - val_recall-0.55: 0.2110 - val_recall-0.60: 0.0884 - val_recall-0.65: 0.0174 - val_recall-0.70: 0.0013 - val_recall-0.75: 0.0000e+00 - val_recall-0.80: 0.0000e+00 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8567 - tp: 18436.0000 - fp: 8098.0000 - tn: 62120.0000 - fn: 16673.0000 - accuracy: 0.6255 - precision: 0.6948 - precision-0.55: 0.7201 - precision-0.60: 0.7470 - precision-0.65: 0.7762 - precision-0.70: 0.8010 - precision-0.75: 0.8308 - precision-0.80: 0.8504 - precision-0.85: 0.8794 - precision-0.90: 0.9155 - precision-0.95: 0.0000e+00 - recall: 0.5251 - recall-0.55: 0.4769 - recall-0.60: 0.4233 - recall-0.65: 0.3584 - recall-0.70: 0.2760 - recall-0.75: 0.1829 - recall-0.80: 0.0878 - recall-0.85: 0.0243 - recall-0.90: 0.0019 - recall-0.95: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 0.95127 to 0.93477, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154735.h5\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 0.8567 - tp: 18436.0000 - fp: 8098.0000 - tn: 62120.0000 - fn: 16673.0000 - accuracy: 0.6255 - precision: 0.6948 - precision-0.55: 0.7201 - precision-0.60: 0.7470 - precision-0.65: 0.7762 - precision-0.70: 0.8010 - precision-0.75: 0.8308 - precision-0.80: 0.8504 - precision-0.85: 0.8794 - precision-0.90: 0.9155 - precision-0.95: 0.0000e+00 - recall: 0.5251 - recall-0.55: 0.4769 - recall-0.60: 0.4233 - recall-0.65: 0.3584 - recall-0.70: 0.2760 - recall-0.75: 0.1829 - recall-0.80: 0.0878 - recall-0.85: 0.0243 - recall-0.90: 0.0019 - recall-0.95: 0.0000e+00 - val_loss: 0.9348 - val_tp: 1747.0000 - val_fp: 942.0000 - val_tn: 6860.0000 - val_fn: 2154.0000 - val_accuracy: 0.6152 - val_precision: 0.6497 - val_precision-0.55: 0.6756 - val_precision-0.60: 0.7006 - val_precision-0.65: 0.7230 - val_precision-0.70: 0.7172 - val_precision-0.75: 0.7010 - val_precision-0.80: 0.8571 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4478 - val_recall-0.55: 0.3609 - val_recall-0.60: 0.2597 - val_recall-0.65: 0.1646 - val_recall-0.70: 0.0715 - val_recall-0.75: 0.0174 - val_recall-0.80: 0.0015 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8344 - tp: 18692.0000 - fp: 7845.0000 - tn: 61787.0000 - fn: 16124.0000 - accuracy: 0.6373 - precision: 0.7044 - precision-0.55: 0.7271 - precision-0.60: 0.7524 - precision-0.65: 0.7756 - precision-0.70: 0.8025 - precision-0.75: 0.8265 - precision-0.80: 0.8450 - precision-0.85: 0.8639 - precision-0.90: 0.8934 - precision-0.95: 1.0000 - recall: 0.5369 - recall-0.55: 0.4901 - recall-0.60: 0.4426 - recall-0.65: 0.3884 - recall-0.70: 0.3248 - recall-0.75: 0.2495 - recall-0.80: 0.1587 - recall-0.85: 0.0673 - recall-0.90: 0.0108 - recall-0.95: 5.7445e-05   \n",
      "Epoch 3: val_loss did not improve from 0.93477\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.8344 - tp: 18849.0000 - fp: 7906.0000 - tn: 62312.0000 - fn: 16260.0000 - accuracy: 0.6372 - precision: 0.7045 - precision-0.55: 0.7273 - precision-0.60: 0.7526 - precision-0.65: 0.7760 - precision-0.70: 0.8031 - precision-0.75: 0.8270 - precision-0.80: 0.8448 - precision-0.85: 0.8637 - precision-0.90: 0.8915 - precision-0.95: 1.0000 - recall: 0.5369 - recall-0.55: 0.4901 - recall-0.60: 0.4426 - recall-0.65: 0.3885 - recall-0.70: 0.3251 - recall-0.75: 0.2499 - recall-0.80: 0.1590 - recall-0.85: 0.0675 - recall-0.90: 0.0108 - recall-0.95: 5.6965e-05 - val_loss: 0.9377 - val_tp: 1722.0000 - val_fp: 874.0000 - val_tn: 6928.0000 - val_fn: 2179.0000 - val_accuracy: 0.6086 - val_precision: 0.6633 - val_precision-0.55: 0.6781 - val_precision-0.60: 0.7009 - val_precision-0.65: 0.7236 - val_precision-0.70: 0.7332 - val_precision-0.75: 0.7273 - val_precision-0.80: 0.8421 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4414 - val_recall-0.55: 0.3489 - val_recall-0.60: 0.2571 - val_recall-0.65: 0.1738 - val_recall-0.70: 0.0895 - val_recall-0.75: 0.0308 - val_recall-0.80: 0.0041 - val_recall-0.85: 2.5634e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8269 - tp: 18903.0000 - fp: 7783.0000 - tn: 62435.0000 - fn: 16206.0000 - accuracy: 0.6419 - precision: 0.7083 - precision-0.55: 0.7334 - precision-0.60: 0.7559 - precision-0.65: 0.7759 - precision-0.70: 0.8006 - precision-0.75: 0.8249 - precision-0.80: 0.8475 - precision-0.85: 0.8604 - precision-0.90: 0.8852 - precision-0.95: 1.0000 - recall: 0.5384 - recall-0.55: 0.4918 - recall-0.60: 0.4442 - recall-0.65: 0.3924 - recall-0.70: 0.3374 - recall-0.75: 0.2688 - recall-0.80: 0.1826 - recall-0.85: 0.0858 - recall-0.90: 0.0154 - recall-0.95: 8.5448e-05\n",
      "Epoch 4: val_loss improved from 0.93477 to 0.92684, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154735.h5\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 0.8269 - tp: 18903.0000 - fp: 7783.0000 - tn: 62435.0000 - fn: 16206.0000 - accuracy: 0.6419 - precision: 0.7083 - precision-0.55: 0.7334 - precision-0.60: 0.7559 - precision-0.65: 0.7759 - precision-0.70: 0.8006 - precision-0.75: 0.8249 - precision-0.80: 0.8475 - precision-0.85: 0.8604 - precision-0.90: 0.8852 - precision-0.95: 1.0000 - recall: 0.5384 - recall-0.55: 0.4918 - recall-0.60: 0.4442 - recall-0.65: 0.3924 - recall-0.70: 0.3374 - recall-0.75: 0.2688 - recall-0.80: 0.1826 - recall-0.85: 0.0858 - recall-0.90: 0.0154 - recall-0.95: 8.5448e-05 - val_loss: 0.9268 - val_tp: 1860.0000 - val_fp: 949.0000 - val_tn: 6853.0000 - val_fn: 2041.0000 - val_accuracy: 0.6193 - val_precision: 0.6622 - val_precision-0.55: 0.6769 - val_precision-0.60: 0.6894 - val_precision-0.65: 0.7156 - val_precision-0.70: 0.7429 - val_precision-0.75: 0.7331 - val_precision-0.80: 0.7500 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4768 - val_recall-0.55: 0.4007 - val_recall-0.60: 0.3038 - val_recall-0.65: 0.2161 - val_recall-0.70: 0.1282 - val_recall-0.75: 0.0528 - val_recall-0.80: 0.0115 - val_recall-0.85: 5.1269e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8184 - tp: 18770.0000 - fp: 7514.0000 - tn: 62118.0000 - fn: 16046.0000 - accuracy: 0.6467 - precision: 0.7141 - precision-0.55: 0.7394 - precision-0.60: 0.7597 - precision-0.65: 0.7827 - precision-0.70: 0.8048 - precision-0.75: 0.8326 - precision-0.80: 0.8556 - precision-0.85: 0.8694 - precision-0.90: 0.8950 - precision-0.95: 1.0000 - recall: 0.5391 - recall-0.55: 0.4923 - recall-0.60: 0.4436 - recall-0.65: 0.3923 - recall-0.70: 0.3376 - recall-0.75: 0.2726 - recall-0.80: 0.1878 - recall-0.85: 0.0897 - recall-0.90: 0.0174 - recall-0.95: 8.6167e-05\n",
      "Epoch 5: val_loss improved from 0.92684 to 0.91145, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154735.h5\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 0.8184 - tp: 18939.0000 - fp: 7584.0000 - tn: 62634.0000 - fn: 16170.0000 - accuracy: 0.6470 - precision: 0.7141 - precision-0.55: 0.7393 - precision-0.60: 0.7597 - precision-0.65: 0.7826 - precision-0.70: 0.8047 - precision-0.75: 0.8325 - precision-0.80: 0.8553 - precision-0.85: 0.8687 - precision-0.90: 0.8930 - precision-0.95: 1.0000 - recall: 0.5394 - recall-0.55: 0.4926 - recall-0.60: 0.4439 - recall-0.65: 0.3926 - recall-0.70: 0.3379 - recall-0.75: 0.2728 - recall-0.80: 0.1877 - recall-0.85: 0.0895 - recall-0.90: 0.0173 - recall-0.95: 8.5448e-05 - val_loss: 0.9115 - val_tp: 2066.0000 - val_fp: 1082.0000 - val_tn: 6720.0000 - val_fn: 1835.0000 - val_accuracy: 0.6298 - val_precision: 0.6563 - val_precision-0.55: 0.6752 - val_precision-0.60: 0.6810 - val_precision-0.65: 0.6987 - val_precision-0.70: 0.7213 - val_precision-0.75: 0.7444 - val_precision-0.80: 0.7458 - val_precision-0.85: 0.7273 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5296 - val_recall-0.55: 0.4722 - val_recall-0.60: 0.3925 - val_recall-0.65: 0.2943 - val_recall-0.70: 0.1984 - val_recall-0.75: 0.1023 - val_recall-0.80: 0.0338 - val_recall-0.85: 0.0021 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8142 - tp: 19143.0000 - fp: 7653.0000 - tn: 62565.0000 - fn: 15966.0000 - accuracy: 0.6486 - precision: 0.7144 - precision-0.55: 0.7390 - precision-0.60: 0.7615 - precision-0.65: 0.7836 - precision-0.70: 0.8088 - precision-0.75: 0.8327 - precision-0.80: 0.8535 - precision-0.85: 0.8706 - precision-0.90: 0.9075 - precision-0.95: 0.5000 - recall: 0.5452 - recall-0.55: 0.4966 - recall-0.60: 0.4484 - recall-0.65: 0.3987 - recall-0.70: 0.3419 - recall-0.75: 0.2759 - recall-0.80: 0.1939 - recall-0.85: 0.0966 - recall-0.90: 0.0176 - recall-0.95: 2.8483e-05 \n",
      "Epoch 6: val_loss did not improve from 0.91145\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.8142 - tp: 19143.0000 - fp: 7653.0000 - tn: 62565.0000 - fn: 15966.0000 - accuracy: 0.6486 - precision: 0.7144 - precision-0.55: 0.7390 - precision-0.60: 0.7615 - precision-0.65: 0.7836 - precision-0.70: 0.8088 - precision-0.75: 0.8327 - precision-0.80: 0.8535 - precision-0.85: 0.8706 - precision-0.90: 0.9075 - precision-0.95: 0.5000 - recall: 0.5452 - recall-0.55: 0.4966 - recall-0.60: 0.4484 - recall-0.65: 0.3987 - recall-0.70: 0.3419 - recall-0.75: 0.2759 - recall-0.80: 0.1939 - recall-0.85: 0.0966 - recall-0.90: 0.0176 - recall-0.95: 2.8483e-05 - val_loss: 0.9172 - val_tp: 1931.0000 - val_fp: 965.0000 - val_tn: 6837.0000 - val_fn: 1970.0000 - val_accuracy: 0.6232 - val_precision: 0.6668 - val_precision-0.55: 0.6771 - val_precision-0.60: 0.6914 - val_precision-0.65: 0.7113 - val_precision-0.70: 0.7421 - val_precision-0.75: 0.7479 - val_precision-0.80: 0.7327 - val_precision-0.85: 0.7500 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4950 - val_recall-0.55: 0.4278 - val_recall-0.60: 0.3394 - val_recall-0.65: 0.2451 - val_recall-0.70: 0.1505 - val_recall-0.75: 0.0692 - val_recall-0.80: 0.0190 - val_recall-0.85: 7.6903e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 7/200\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8105 - tp: 18943.0000 - fp: 7450.0000 - tn: 62182.0000 - fn: 15873.0000 - accuracy: 0.6522 - precision: 0.7177 - precision-0.55: 0.7401 - precision-0.60: 0.7628 - precision-0.65: 0.7856 - precision-0.70: 0.8089 - precision-0.75: 0.8364 - precision-0.80: 0.8598 - precision-0.85: 0.8711 - precision-0.90: 0.8885 - precision-0.95: 1.0000 - recall: 0.5441 - recall-0.55: 0.4961 - recall-0.60: 0.4486 - recall-0.65: 0.4002 - recall-0.70: 0.3468 - recall-0.75: 0.2830 - recall-0.80: 0.2066 - recall-0.85: 0.1081 - recall-0.90: 0.0222 - recall-0.95: 2.8722e-05\n",
      "Epoch 7: val_loss did not improve from 0.91145\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.8103 - tp: 19112.0000 - fp: 7507.0000 - tn: 62711.0000 - fn: 15997.0000 - accuracy: 0.6524 - precision: 0.7180 - precision-0.55: 0.7403 - precision-0.60: 0.7630 - precision-0.65: 0.7857 - precision-0.70: 0.8087 - precision-0.75: 0.8364 - precision-0.80: 0.8602 - precision-0.85: 0.8718 - precision-0.90: 0.8889 - precision-0.95: 1.0000 - recall: 0.5444 - recall-0.55: 0.4962 - recall-0.60: 0.4487 - recall-0.65: 0.4004 - recall-0.70: 0.3469 - recall-0.75: 0.2832 - recall-0.80: 0.2066 - recall-0.85: 0.1080 - recall-0.90: 0.0221 - recall-0.95: 2.8483e-05 - val_loss: 0.9157 - val_tp: 1972.0000 - val_fp: 995.0000 - val_tn: 6807.0000 - val_fn: 1929.0000 - val_accuracy: 0.6273 - val_precision: 0.6646 - val_precision-0.55: 0.6773 - val_precision-0.60: 0.6834 - val_precision-0.65: 0.7066 - val_precision-0.70: 0.7468 - val_precision-0.75: 0.7610 - val_precision-0.80: 0.7712 - val_precision-0.85: 0.6250 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5055 - val_recall-0.55: 0.4401 - val_recall-0.60: 0.3520 - val_recall-0.65: 0.2556 - val_recall-0.70: 0.1625 - val_recall-0.75: 0.0800 - val_recall-0.80: 0.0233 - val_recall-0.85: 0.0013 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 8/200\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8081 - tp: 18998.0000 - fp: 7512.0000 - tn: 62120.0000 - fn: 15818.0000 - accuracy: 0.6531 - precision: 0.7166 - precision-0.55: 0.7409 - precision-0.60: 0.7636 - precision-0.65: 0.7870 - precision-0.70: 0.8100 - precision-0.75: 0.8343 - precision-0.80: 0.8562 - precision-0.85: 0.8740 - precision-0.90: 0.8870 - precision-0.95: 1.0000 - recall: 0.5457 - recall-0.55: 0.4966 - recall-0.60: 0.4491 - recall-0.65: 0.4000 - recall-0.70: 0.3462 - recall-0.75: 0.2847 - recall-0.80: 0.2067 - recall-0.85: 0.1078 - recall-0.90: 0.0198 - recall-0.95: 1.1489e-04\n",
      "Epoch 8: val_loss did not improve from 0.91145\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.8082 - tp: 19153.0000 - fp: 7575.0000 - tn: 62643.0000 - fn: 15956.0000 - accuracy: 0.6528 - precision: 0.7166 - precision-0.55: 0.7409 - precision-0.60: 0.7635 - precision-0.65: 0.7872 - precision-0.70: 0.8103 - precision-0.75: 0.8349 - precision-0.80: 0.8565 - precision-0.85: 0.8740 - precision-0.90: 0.8863 - precision-0.95: 1.0000 - recall: 0.5455 - recall-0.55: 0.4967 - recall-0.60: 0.4493 - recall-0.65: 0.4001 - recall-0.70: 0.3465 - recall-0.75: 0.2848 - recall-0.80: 0.2066 - recall-0.85: 0.1077 - recall-0.90: 0.0198 - recall-0.95: 1.1393e-04 - val_loss: 0.9254 - val_tp: 1864.0000 - val_fp: 933.0000 - val_tn: 6869.0000 - val_fn: 2037.0000 - val_accuracy: 0.6188 - val_precision: 0.6664 - val_precision-0.55: 0.6746 - val_precision-0.60: 0.7016 - val_precision-0.65: 0.7291 - val_precision-0.70: 0.7469 - val_precision-0.75: 0.7345 - val_precision-0.80: 0.7460 - val_precision-0.85: 1.0000 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4778 - val_recall-0.55: 0.3932 - val_recall-0.60: 0.3086 - val_recall-0.65: 0.2166 - val_recall-0.70: 0.1233 - val_recall-0.75: 0.0518 - val_recall-0.80: 0.0120 - val_recall-0.85: 5.1269e-04 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 9/200\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8062 - tp: 18989.0000 - fp: 7486.0000 - tn: 62146.0000 - fn: 15827.0000 - accuracy: 0.6537 - precision: 0.7172 - precision-0.55: 0.7433 - precision-0.60: 0.7685 - precision-0.65: 0.7915 - precision-0.70: 0.8140 - precision-0.75: 0.8382 - precision-0.80: 0.8574 - precision-0.85: 0.8731 - precision-0.90: 0.8895 - precision-0.95: 1.0000 - recall: 0.5454 - recall-0.55: 0.4961 - recall-0.60: 0.4465 - recall-0.65: 0.3963 - recall-0.70: 0.3455 - recall-0.75: 0.2833 - recall-0.80: 0.2064 - recall-0.85: 0.1091 - recall-0.90: 0.0217 - recall-0.95: 2.8722e-05\n",
      "Epoch 9: val_loss did not improve from 0.91145\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 0.8059 - tp: 19164.0000 - fp: 7542.0000 - tn: 62676.0000 - fn: 15945.0000 - accuracy: 0.6539 - precision: 0.7176 - precision-0.55: 0.7434 - precision-0.60: 0.7686 - precision-0.65: 0.7916 - precision-0.70: 0.8144 - precision-0.75: 0.8385 - precision-0.80: 0.8575 - precision-0.85: 0.8730 - precision-0.90: 0.8898 - precision-0.95: 1.0000 - recall: 0.5458 - recall-0.55: 0.4965 - recall-0.60: 0.4469 - recall-0.65: 0.3964 - recall-0.70: 0.3456 - recall-0.75: 0.2834 - recall-0.80: 0.2064 - recall-0.85: 0.1089 - recall-0.90: 0.0216 - recall-0.95: 2.8483e-05 - val_loss: 0.9150 - val_tp: 1936.0000 - val_fp: 981.0000 - val_tn: 6821.0000 - val_fn: 1965.0000 - val_accuracy: 0.6262 - val_precision: 0.6637 - val_precision-0.55: 0.6777 - val_precision-0.60: 0.6889 - val_precision-0.65: 0.7145 - val_precision-0.70: 0.7474 - val_precision-0.75: 0.7594 - val_precision-0.80: 0.7981 - val_precision-0.85: 0.5714 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4963 - val_recall-0.55: 0.4296 - val_recall-0.60: 0.3417 - val_recall-0.65: 0.2463 - val_recall-0.70: 0.1479 - val_recall-0.75: 0.0728 - val_recall-0.80: 0.0213 - val_recall-0.85: 0.0010 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8032 - tp: 19199.0000 - fp: 7489.0000 - tn: 62729.0000 - fn: 15910.0000 - accuracy: 0.6567 - precision: 0.7194 - precision-0.55: 0.7426 - precision-0.60: 0.7681 - precision-0.65: 0.7926 - precision-0.70: 0.8160 - precision-0.75: 0.8385 - precision-0.80: 0.8563 - precision-0.85: 0.8754 - precision-0.90: 0.8902 - precision-0.95: 1.0000 - recall: 0.5468 - recall-0.55: 0.4979 - recall-0.60: 0.4493 - recall-0.65: 0.4025 - recall-0.70: 0.3522 - recall-0.75: 0.2903 - recall-0.80: 0.2149 - recall-0.85: 0.1199 - recall-0.90: 0.0245 - recall-0.95: 8.5448e-05\n",
      "Epoch 10: val_loss did not improve from 0.91145\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.8032 - tp: 19199.0000 - fp: 7489.0000 - tn: 62729.0000 - fn: 15910.0000 - accuracy: 0.6567 - precision: 0.7194 - precision-0.55: 0.7426 - precision-0.60: 0.7681 - precision-0.65: 0.7926 - precision-0.70: 0.8160 - precision-0.75: 0.8385 - precision-0.80: 0.8563 - precision-0.85: 0.8754 - precision-0.90: 0.8902 - precision-0.95: 1.0000 - recall: 0.5468 - recall-0.55: 0.4979 - recall-0.60: 0.4493 - recall-0.65: 0.4025 - recall-0.70: 0.3522 - recall-0.75: 0.2903 - recall-0.80: 0.2149 - recall-0.85: 0.1199 - recall-0.90: 0.0245 - recall-0.95: 8.5448e-05 - val_loss: 0.9189 - val_tp: 1899.0000 - val_fp: 968.0000 - val_tn: 6834.0000 - val_fn: 2002.0000 - val_accuracy: 0.6234 - val_precision: 0.6624 - val_precision-0.55: 0.6755 - val_precision-0.60: 0.6946 - val_precision-0.65: 0.7182 - val_precision-0.70: 0.7462 - val_precision-0.75: 0.7436 - val_precision-0.80: 0.8235 - val_precision-0.85: 0.6667 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.4868 - val_recall-0.55: 0.4184 - val_recall-0.60: 0.3335 - val_recall-0.65: 0.2346 - val_recall-0.70: 0.1371 - val_recall-0.75: 0.0669 - val_recall-0.80: 0.0215 - val_recall-0.85: 0.0010 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 216 720 709 721 312 217 710 727 576]\n",
      "Epoch 10: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9243 - tp: 2313.0000 - fp: 1245.0000 - tn: 6557.0000 - fn: 1588.0000 - accuracy: 0.6378 - precision: 0.6501 - precision-0.55: 0.6600 - precision-0.60: 0.6705 - precision-0.65: 0.6820 - precision-0.70: 0.6899 - precision-0.75: 0.7005 - precision-0.80: 0.6848 - precision-0.85: 0.6682 - precision-0.90: 0.3611 - precision-0.95: 0.0000e+00 - recall: 0.5929 - recall-0.55: 0.5658 - recall-0.60: 0.5378 - recall-0.65: 0.5053 - recall-0.70: 0.4535 - recall-0.75: 0.3712 - recall-0.80: 0.2128 - recall-0.85: 0.0728 - recall-0.90: 0.0033 - recall-0.95: 0.0000e+00\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78      2356\n",
      "           1       0.51      0.06      0.11       687\n",
      "           2       0.50      0.14      0.21       858\n",
      "\n",
      "    accuracy                           0.64      3901\n",
      "   macro avg       0.55      0.40      0.37      3901\n",
      "weighted avg       0.59      0.64      0.54      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1   P2  Total    RP0    RP1    RP2\n",
      "0      2327   8   21   2356  0.988  0.003  0.009\n",
      "1       547  44   96    687  0.796  0.064  0.140\n",
      "2       707  34  117    858  0.824  0.040  0.136\n",
      "Total  3581  86  234   3901  0.918  0.022  0.060\n",
      "\n",
      ">>>>>> FOLD 10\n",
      "\n",
      "\n",
      "DATA IN FOLD\n",
      "Train: 39010, Validation: 3901, Test: 3901\n",
      "\n",
      "Train:\n",
      "Label 0: 23023(59.02%)\n",
      "Label 1: 7738(19.84%)\n",
      "Label 2: 8249(21.15%)\n",
      "\n",
      "Validation:\n",
      "Label 0: 2356(60.39%)\n",
      "Label 1: 687(17.61%)\n",
      "Label 2: 858(21.99%)\n",
      "\n",
      "Test:\n",
      "Label 0: 3136(80.39%)\n",
      "Label 1: 395(10.13%)\n",
      "Label 2: 370(9.48%)\n",
      "\n",
      "=============\n",
      "CLASSIFIER PARAMS:\n",
      "hu:500\n",
      "output_bias:[0.7055840561156329, -0.38476640386828953, -0.3208176792679952]\n",
      "loss:categorical_crossentropy\n",
      "dropout:True\n",
      "dropout_rate:0.3\n",
      "learning_rate:0.0001\n",
      "gpu:False\n",
      "set_class_weight:False\n",
      "save_check_point:True\n",
      "early_stopping:True\n",
      "patience:5\n",
      "epochs:200\n",
      "shuffle_when_train:True\n",
      "batch_size:1024\n",
      "class_weight:None\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.9405 - tp: 21536.0000 - fp: 12267.0000 - tn: 73359.0000 - fn: 21277.0000 - accuracy: 0.5967 - precision: 0.6371 - precision-0.55: 0.6543 - precision-0.60: 0.6737 - precision-0.65: 0.6942 - precision-0.70: 0.7098 - precision-0.75: 0.7222 - precision-0.80: 0.7207 - precision-0.85: 0.6884 - precision-0.90: 0.3784 - precision-0.95: 0.0000e+00 - recall: 0.5030 - recall-0.55: 0.4390 - recall-0.60: 0.3578 - recall-0.65: 0.2591 - recall-0.70: 0.1599 - recall-0.75: 0.0815 - recall-0.80: 0.0310 - recall-0.85: 0.0079 - recall-0.90: 3.2700e-04 - recall-0.95: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.90950, saving model to ../logs/model/model_multi_dnn_checkpoint_20230129-154758.h5\n",
      "39/39 [==============================] - 6s 91ms/step - loss: 0.9403 - tp: 21585.0000 - fp: 12286.0000 - tn: 73536.0000 - fn: 21326.0000 - accuracy: 0.5967 - precision: 0.6373 - precision-0.55: 0.6545 - precision-0.60: 0.6739 - precision-0.65: 0.6944 - precision-0.70: 0.7098 - precision-0.75: 0.7222 - precision-0.80: 0.7205 - precision-0.85: 0.6884 - precision-0.90: 0.3784 - precision-0.95: 0.0000e+00 - recall: 0.5030 - recall-0.55: 0.4391 - recall-0.60: 0.3580 - recall-0.65: 0.2593 - recall-0.70: 0.1599 - recall-0.75: 0.0815 - recall-0.80: 0.0310 - recall-0.85: 0.0079 - recall-0.90: 3.2626e-04 - recall-0.95: 0.0000e+00 - val_loss: 0.9095 - val_tp: 2219.0000 - val_fp: 1193.0000 - val_tn: 6609.0000 - val_fn: 1682.0000 - val_accuracy: 0.6270 - val_precision: 0.6504 - val_precision-0.55: 0.6590 - val_precision-0.60: 0.6732 - val_precision-0.65: 0.6961 - val_precision-0.70: 0.6879 - val_precision-0.75: 0.6450 - val_precision-0.80: 0.2500 - val_precision-0.85: 0.0000e+00 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5688 - val_recall-0.55: 0.5217 - val_recall-0.60: 0.4514 - val_recall-0.65: 0.3253 - val_recall-0.70: 0.1633 - val_recall-0.75: 0.0382 - val_recall-0.80: 2.5634e-04 - val_recall-0.85: 0.0000e+00 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 2/200\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.8609 - tp: 20628.0000 - fp: 9289.0000 - tn: 68535.0000 - fn: 18284.0000 - accuracy: 0.6286 - precision: 0.6895 - precision-0.55: 0.7140 - precision-0.60: 0.7377 - precision-0.65: 0.7634 - precision-0.70: 0.7900 - precision-0.75: 0.8193 - precision-0.80: 0.8477 - precision-0.85: 0.8664 - precision-0.90: 0.9259 - precision-0.95: 0.0000e+00 - recall: 0.5301 - recall-0.55: 0.4819 - recall-0.60: 0.4248 - recall-0.65: 0.3544 - recall-0.70: 0.2727 - recall-0.75: 0.1796 - recall-0.80: 0.0884 - recall-0.85: 0.0252 - recall-0.90: 0.0019 - recall-0.95: 0.0000e+00\n",
      "Epoch 2: val_loss did not improve from 0.90950\n",
      "39/39 [==============================] - 2s 53ms/step - loss: 0.8608 - tp: 20682.0000 - fp: 9306.0000 - tn: 68714.0000 - fn: 18328.0000 - accuracy: 0.6286 - precision: 0.6897 - precision-0.55: 0.7142 - precision-0.60: 0.7379 - precision-0.65: 0.7636 - precision-0.70: 0.7902 - precision-0.75: 0.8194 - precision-0.80: 0.8480 - precision-0.85: 0.8668 - precision-0.90: 0.9268 - precision-0.95: 0.0000e+00 - recall: 0.5302 - recall-0.55: 0.4819 - recall-0.60: 0.4249 - recall-0.65: 0.3546 - recall-0.70: 0.2729 - recall-0.75: 0.1797 - recall-0.80: 0.0885 - recall-0.85: 0.0252 - recall-0.90: 0.0019 - recall-0.95: 0.0000e+00 - val_loss: 0.9169 - val_tp: 2277.0000 - val_fp: 1233.0000 - val_tn: 6569.0000 - val_fn: 1624.0000 - val_accuracy: 0.6314 - val_precision: 0.6487 - val_precision-0.55: 0.6534 - val_precision-0.60: 0.6584 - val_precision-0.65: 0.6734 - val_precision-0.70: 0.6900 - val_precision-0.75: 0.7076 - val_precision-0.80: 0.6962 - val_precision-0.85: 0.6438 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5837 - val_recall-0.55: 0.5624 - val_recall-0.60: 0.5306 - val_recall-0.65: 0.4847 - val_recall-0.70: 0.4212 - val_recall-0.75: 0.3045 - val_recall-0.80: 0.1351 - val_recall-0.85: 0.0264 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 3/200\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.8422 - tp: 20878.0000 - fp: 8959.0000 - tn: 68865.0000 - fn: 18034.0000 - accuracy: 0.6384 - precision: 0.6997 - precision-0.55: 0.7228 - precision-0.60: 0.7459 - precision-0.65: 0.7670 - precision-0.70: 0.7901 - precision-0.75: 0.8201 - precision-0.80: 0.8408 - precision-0.85: 0.8583 - precision-0.90: 0.9042 - precision-0.95: 1.0000 - recall: 0.5365 - recall-0.55: 0.4904 - recall-0.60: 0.4396 - recall-0.65: 0.3814 - recall-0.70: 0.3146 - recall-0.75: 0.2371 - recall-0.80: 0.1470 - recall-0.85: 0.0598 - recall-0.90: 0.0099 - recall-0.95: 5.1398e-05\n",
      "Epoch 3: val_loss did not improve from 0.90950\n",
      "39/39 [==============================] - 2s 50ms/step - loss: 0.8420 - tp: 20939.0000 - fp: 8976.0000 - tn: 69044.0000 - fn: 18071.0000 - accuracy: 0.6385 - precision: 0.6999 - precision-0.55: 0.7229 - precision-0.60: 0.7459 - precision-0.65: 0.7669 - precision-0.70: 0.7901 - precision-0.75: 0.8202 - precision-0.80: 0.8411 - precision-0.85: 0.8586 - precision-0.90: 0.9047 - precision-0.95: 1.0000 - recall: 0.5368 - recall-0.55: 0.4905 - recall-0.60: 0.4396 - recall-0.65: 0.3815 - recall-0.70: 0.3147 - recall-0.75: 0.2372 - recall-0.80: 0.1471 - recall-0.85: 0.0598 - recall-0.90: 0.0100 - recall-0.95: 5.1269e-05 - val_loss: 0.9334 - val_tp: 2330.0000 - val_fp: 1262.0000 - val_tn: 6540.0000 - val_fn: 1571.0000 - val_accuracy: 0.6321 - val_precision: 0.6487 - val_precision-0.55: 0.6512 - val_precision-0.60: 0.6558 - val_precision-0.65: 0.6650 - val_precision-0.70: 0.6783 - val_precision-0.75: 0.7007 - val_precision-0.80: 0.7055 - val_precision-0.85: 0.6834 - val_precision-0.90: 0.3913 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5973 - val_recall-0.55: 0.5775 - val_recall-0.60: 0.5524 - val_recall-0.65: 0.5170 - val_recall-0.70: 0.4730 - val_recall-0.75: 0.3973 - val_recall-0.80: 0.2610 - val_recall-0.85: 0.0874 - val_recall-0.90: 0.0023 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 4/200\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.8328 - tp: 21024.0000 - fp: 8884.0000 - tn: 68940.0000 - fn: 17888.0000 - accuracy: 0.6421 - precision: 0.7030 - precision-0.55: 0.7266 - precision-0.60: 0.7492 - precision-0.65: 0.7717 - precision-0.70: 0.7942 - precision-0.75: 0.8223 - precision-0.80: 0.8500 - precision-0.85: 0.8644 - precision-0.90: 0.8919 - precision-0.95: 1.0000 - recall: 0.5403 - recall-0.55: 0.4921 - recall-0.60: 0.4428 - recall-0.65: 0.3876 - recall-0.70: 0.3268 - recall-0.75: 0.2555 - recall-0.80: 0.1702 - recall-0.85: 0.0785 - recall-0.90: 0.0136 - recall-0.95: 7.7097e-05\n",
      "Epoch 4: val_loss did not improve from 0.90950\n",
      "39/39 [==============================] - 2s 51ms/step - loss: 0.8327 - tp: 21077.0000 - fp: 8905.0000 - tn: 69115.0000 - fn: 17933.0000 - accuracy: 0.6421 - precision: 0.7030 - precision-0.55: 0.7266 - precision-0.60: 0.7492 - precision-0.65: 0.7718 - precision-0.70: 0.7942 - precision-0.75: 0.8225 - precision-0.80: 0.8501 - precision-0.85: 0.8646 - precision-0.90: 0.8908 - precision-0.95: 1.0000 - recall: 0.5403 - recall-0.55: 0.4921 - recall-0.60: 0.4428 - recall-0.65: 0.3877 - recall-0.70: 0.3268 - recall-0.75: 0.2556 - recall-0.80: 0.1702 - recall-0.85: 0.0785 - recall-0.90: 0.0136 - recall-0.95: 7.6903e-05 - val_loss: 0.9261 - val_tp: 2322.0000 - val_fp: 1263.0000 - val_tn: 6539.0000 - val_fn: 1579.0000 - val_accuracy: 0.6345 - val_precision: 0.6477 - val_precision-0.55: 0.6538 - val_precision-0.60: 0.6611 - val_precision-0.65: 0.6706 - val_precision-0.70: 0.6840 - val_precision-0.75: 0.7027 - val_precision-0.80: 0.7077 - val_precision-0.85: 0.6872 - val_precision-0.90: 0.1429 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5952 - val_recall-0.55: 0.5755 - val_recall-0.60: 0.5460 - val_recall-0.65: 0.5094 - val_recall-0.70: 0.4612 - val_recall-0.75: 0.3830 - val_recall-0.80: 0.2358 - val_recall-0.85: 0.0687 - val_recall-0.90: 2.5634e-04 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8281 - tp: 21203.0000 - fp: 8798.0000 - tn: 69222.0000 - fn: 17807.0000 - accuracy: 0.6446 - precision: 0.7067 - precision-0.55: 0.7282 - precision-0.60: 0.7492 - precision-0.65: 0.7723 - precision-0.70: 0.7967 - precision-0.75: 0.8224 - precision-0.80: 0.8479 - precision-0.85: 0.8686 - precision-0.90: 0.9067 - precision-0.95: 1.0000 - recall: 0.5435 - recall-0.55: 0.4937 - recall-0.60: 0.4442 - recall-0.65: 0.3895 - recall-0.70: 0.3282 - recall-0.75: 0.2579 - recall-0.80: 0.1750 - recall-0.85: 0.0834 - recall-0.90: 0.0157 - recall-0.95: 2.5634e-05\n",
      "Epoch 5: val_loss did not improve from 0.90950\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.8281 - tp: 21203.0000 - fp: 8798.0000 - tn: 69222.0000 - fn: 17807.0000 - accuracy: 0.6446 - precision: 0.7067 - precision-0.55: 0.7282 - precision-0.60: 0.7492 - precision-0.65: 0.7723 - precision-0.70: 0.7967 - precision-0.75: 0.8224 - precision-0.80: 0.8479 - precision-0.85: 0.8686 - precision-0.90: 0.9067 - precision-0.95: 1.0000 - recall: 0.5435 - recall-0.55: 0.4937 - recall-0.60: 0.4442 - recall-0.65: 0.3895 - recall-0.70: 0.3282 - recall-0.75: 0.2579 - recall-0.80: 0.1750 - recall-0.85: 0.0834 - recall-0.90: 0.0157 - recall-0.95: 2.5634e-05 - val_loss: 0.9190 - val_tp: 2295.0000 - val_fp: 1221.0000 - val_tn: 6581.0000 - val_fn: 1606.0000 - val_accuracy: 0.6362 - val_precision: 0.6527 - val_precision-0.55: 0.6571 - val_precision-0.60: 0.6640 - val_precision-0.65: 0.6740 - val_precision-0.70: 0.6894 - val_precision-0.75: 0.7020 - val_precision-0.80: 0.7053 - val_precision-0.85: 0.7129 - val_precision-0.90: 0.0000e+00 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5883 - val_recall-0.55: 0.5634 - val_recall-0.60: 0.5340 - val_recall-0.65: 0.4976 - val_recall-0.70: 0.4460 - val_recall-0.75: 0.3581 - val_recall-0.80: 0.1982 - val_recall-0.85: 0.0554 - val_recall-0.90: 0.0000e+00 - val_recall-0.95: 0.0000e+00\n",
      "Epoch 6/200\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.8229 - tp: 21168.0000 - fp: 8652.0000 - tn: 69172.0000 - fn: 17744.0000 - accuracy: 0.6473 - precision: 0.7099 - precision-0.55: 0.7328 - precision-0.60: 0.7543 - precision-0.65: 0.7777 - precision-0.70: 0.8013 - precision-0.75: 0.8253 - precision-0.80: 0.8528 - precision-0.85: 0.8696 - precision-0.90: 0.8950 - precision-0.95: 1.0000 - recall: 0.5440 - recall-0.55: 0.4948 - recall-0.60: 0.4444 - recall-0.65: 0.3896 - recall-0.70: 0.3284 - recall-0.75: 0.2572 - recall-0.80: 0.1756 - recall-0.85: 0.0859 - recall-0.90: 0.0138 - recall-0.95: 2.5699e-05\n",
      "Epoch 6: val_loss did not improve from 0.90950\n",
      "39/39 [==============================] - 2s 48ms/step - loss: 0.8227 - tp: 21223.0000 - fp: 8674.0000 - tn: 69346.0000 - fn: 17787.0000 - accuracy: 0.6474 - precision: 0.7099 - precision-0.55: 0.7329 - precision-0.60: 0.7544 - precision-0.65: 0.7778 - precision-0.70: 0.8013 - precision-0.75: 0.8254 - precision-0.80: 0.8531 - precision-0.85: 0.8698 - precision-0.90: 0.8950 - precision-0.95: 1.0000 - recall: 0.5440 - recall-0.55: 0.4949 - recall-0.60: 0.4445 - recall-0.65: 0.3897 - recall-0.70: 0.3284 - recall-0.75: 0.2572 - recall-0.80: 0.1757 - recall-0.85: 0.0860 - recall-0.90: 0.0138 - recall-0.95: 2.5634e-05 - val_loss: 0.9327 - val_tp: 2328.0000 - val_fp: 1249.0000 - val_tn: 6553.0000 - val_fn: 1573.0000 - val_accuracy: 0.6352 - val_precision: 0.6508 - val_precision-0.55: 0.6538 - val_precision-0.60: 0.6595 - val_precision-0.65: 0.6657 - val_precision-0.70: 0.6804 - val_precision-0.75: 0.7001 - val_precision-0.80: 0.7028 - val_precision-0.85: 0.6690 - val_precision-0.90: 0.4865 - val_precision-0.95: 0.0000e+00 - val_recall: 0.5968 - val_recall-0.55: 0.5781 - val_recall-0.60: 0.5550 - val_recall-0.65: 0.5211 - val_recall-0.70: 0.4786 - val_recall-0.75: 0.4117 - val_recall-0.80: 0.2856 - val_recall-0.85: 0.0995 - val_recall-0.90: 0.0046 - val_recall-0.95: 0.0000e+00\n",
      "Most important variables:  [708 216 720 709 721 312 217 228 722 204]\n",
      "Epoch 6: early stopping\n",
      "122/122 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6173 - tp: 3135.0000 - fp: 715.0000 - tn: 7087.0000 - fn: 766.0000 - accuracy: 0.8070 - precision: 0.8143 - precision-0.55: 0.8159 - precision-0.60: 0.8165 - precision-0.65: 0.8181 - precision-0.70: 0.8208 - precision-0.75: 0.8253 - precision-0.80: 0.8349 - precision-0.85: 0.8573 - precision-0.90: 0.8900 - precision-0.95: 0.9312 - recall: 0.8036 - recall-0.55: 0.8031 - recall-0.60: 0.8008 - recall-0.65: 0.7990 - recall-0.70: 0.7916 - recall-0.75: 0.7785 - recall-0.80: 0.7478 - recall-0.85: 0.6778 - recall-0.90: 0.5332 - recall-0.95: 0.3056\n",
      "\n",
      "=============\n",
      "CLASSIFICATION REPORT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89      3136\n",
      "           1       0.00      0.00      0.00       395\n",
      "           2       0.54      0.04      0.07       370\n",
      "\n",
      "    accuracy                           0.81      3901\n",
      "   macro avg       0.45      0.34      0.32      3901\n",
      "weighted avg       0.70      0.81      0.72      3901\n",
      "\n",
      "\n",
      "=============\n",
      "CONFUSION MATRIX:\n",
      "         P0  P1  P2  Total    RP0  RP1    RP2\n",
      "0      3135   0   1   3136  1.000  0.0  0.000\n",
      "1       385   0  10    395  0.975  0.0  0.025\n",
      "2       357   0  13    370  0.965  0.0  0.035\n",
      "Total  3877   0  24   3901  0.994  0.0  0.006\n",
      "\n",
      ">>>>>>\n",
      "EVALUATION SUMMARY:\n",
      "\n",
      "       loss  accuracy  precision  recall  precision-0.65  recall-0.65  \\\n",
      "1     1.389     0.269      0.241   0.130           0.271        0.073   \n",
      "2     0.636     0.773      0.805   0.755           0.834        0.715   \n",
      "3     0.841     0.662      0.698   0.610           0.745        0.531   \n",
      "4     0.787     0.707      0.725   0.677           0.738        0.609   \n",
      "5     0.594     0.797      0.813   0.767           0.845        0.714   \n",
      "6     1.017     0.502      0.574   0.368           0.748        0.160   \n",
      "7     1.048     0.473      0.514   0.296           0.575        0.079   \n",
      "8     0.954     0.592      0.658   0.430           0.730        0.156   \n",
      "9     0.924     0.638      0.650   0.593           0.682        0.505   \n",
      "10    0.617     0.807      0.814   0.804           0.818        0.799   \n",
      "mean  0.881     0.622      0.649   0.543           0.699        0.434   \n",
      "std   0.244     0.170      0.176   0.227           0.170        0.288   \n",
      "min   0.594     0.269      0.241   0.130           0.271        0.073   \n",
      "max   1.389     0.807      0.814   0.804           0.845        0.799   \n",
      "\n",
      "      precision-0.80  recall-0.80  precision-0.95  recall-0.95  \n",
      "1              0.322        0.017           0.000        0.000  \n",
      "2              0.860        0.543           0.000        0.000  \n",
      "3              0.787        0.339           0.000        0.000  \n",
      "4              0.772        0.421           0.000        0.000  \n",
      "5              0.907        0.451           0.000        0.000  \n",
      "6              0.865        0.051           0.000        0.000  \n",
      "7              0.588        0.010           0.000        0.000  \n",
      "8              0.868        0.008           0.000        0.000  \n",
      "9              0.685        0.213           0.000        0.000  \n",
      "10             0.835        0.748           0.931        0.306  \n",
      "mean           0.749        0.280           0.093        0.031  \n",
      "std            0.179        0.261           0.294        0.097  \n",
      "min            0.322        0.008           0.000        0.000  \n",
      "max            0.907        0.748           0.931        0.306  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3new/envs/tensor/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andy/anaconda3new/envs/tensor/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andy/anaconda3new/envs/tensor/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_PRINT_METRICS = [\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"precision-0.65\",\n",
    "    \"recall-0.65\",\n",
    "    \"precision-0.80\",\n",
    "    \"recall-0.80\",\n",
    "    \"precision-0.95\",\n",
    "    \"recall-0.95\"\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "results = dnn.evaluate_classifier_k_folds(\n",
    "    hu = 500,\n",
    "    fm = fm,\n",
    "    fold_number = 10,\n",
    "    batch_size = 1024,\n",
    "    set_class_weight = False,\n",
    "    save_check_point = True,\n",
    "    early_stop = True,\n",
    "    rebalance = None,\n",
    "    split_type=\"time_series_split\",\n",
    "    metrics=DEFAULT_PRINT_METRICS,\n",
    "    set_initial_bias = True,\n",
    "    dropout = True,\n",
    "    dropout_rate = 0.3,\n",
    "    shuffle_when_train = True,\n",
    "    gpu = False,\n",
    "    write_to_file = True\n",
    ")\n",
    "results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.df[\"gold_lag_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"precision-0.65\",\n",
    "    \"recall-0.65\",\n",
    "    \"precision-0.80\",\n",
    "    \"recall-0.80\",\n",
    "    \"precision-0.95\",\n",
    "    \"recall-0.95\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "results = dnn.evaluate_classifier(\n",
    "    hu=100,\n",
    "    fm=fm,\n",
    "    laps=1,\n",
    "    batch_size=20,\n",
    "    set_class_weight=False,\n",
    "    save_check_point=False,\n",
    "    early_stopping=True,\n",
    "    shuffle_before_split=False,\n",
    "    dropout=True,\n",
    "    dropout_rate=0.3,\n",
    "    gpu=False,\n",
    "    metrics=metric_list,\n",
    "    write_to_file=True\n",
    ")\n",
    "results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../out/evaluate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dnn.MultiDNNClassifer()\n",
    "\n",
    "filename = \"../logs/report/{}.txt\".format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "report_file = open(filename,'w')\n",
    "\n",
    "dataset = classifier.prepare_data(\n",
    "    data = fm.df,\n",
    "    cols = fm.cols,\n",
    "    shuffle_before_split= False,\n",
    "    categorical_label=True,\n",
    "    rebalance=\"over\",\n",
    "    target_col=\"trade_signal\",\n",
    "    file = report_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = tr_utils.init_imbalanced_bias(\n",
    "    y_train=dataset[1]\n",
    ")\n",
    "\n",
    "classifier.configure(\n",
    "    hu = 100, \n",
    "    dropout=True, \n",
    "    dropout_rate = 0.3,\n",
    "    input_dim=len(fm.cols),\n",
    "    output_bias=initial_bias,\n",
    "    class_num=3\n",
    ")\n",
    "\n",
    "test_result = classifier.run(\n",
    "    gpu = False,\n",
    "    dataset = dataset,\n",
    "    epochs = 500,\n",
    "    shuffle_when_train = False,\n",
    "    patience = 5,\n",
    "    early_stop = True,\n",
    "    save_check_point = True,\n",
    "    set_class_weight = False,\n",
    "    batch_size = 128,\n",
    "    file = report_file\n",
    ")\n",
    "\n",
    "var_df = pd.DataFrame(data=classifier.viann_callback.varScores, index = fm.cols)\n",
    "var_df.columns = [\"var\"]\n",
    "var_df.sort_values(by=[\"var\"],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b58b1819899e409cec63cea36e334f732dfc50db3a5ecdff48b63b0a8eb4970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
