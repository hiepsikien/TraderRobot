{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(lags, sub_lags, vol_lags, scaler):\n",
    "    \n",
    "    if scaler == 0:\n",
    "        my_scaler = MaxAbsScaler()\n",
    "    elif scaler == 1:\n",
    "        my_scaler = MinMaxScaler()\n",
    "    elif scaler == 2:\n",
    "        my_scaler = StandardScaler()\n",
    "    else:\n",
    "        my_scaler = MaxAbsScaler()\n",
    "\n",
    "    #Import target currency\n",
    "    data = pd.read_csv(\"ETHUSDT-1d.csv\", index_col=\"Open Time\")\n",
    "    data = data[[\"Close\",\"Volumn\"]]\n",
    "    data[\"return\"] = data[\"Close\"].div(data[\"Close\"].shift(1))\n",
    "    data[\"log_return\"] = np.log(data[\"return\"])\n",
    "    data[\"direction\"] = np.sign(data[\"log_return\"])\n",
    "\n",
    "\n",
    "    cols = []\n",
    "    \n",
    "    for lag in range(1,lags+1):\n",
    "        col = \"lag{}\".format(lag)\n",
    "        data[col] = data[\"log_return\"].shift(lag)\n",
    "        cols.append(col)\n",
    "\n",
    "    #Add volumn info\n",
    "    data[\"log_volumn_change\"] = np.log(data[\"Volumn\"].div(data[\"Volumn\"].shift(1)))\n",
    "    for lag in range(1,vol_lags+1):\n",
    "        col = \"volumn lag{}\".format(lag)\n",
    "        data[col] = data[\"log_volumn_change\"].shift(lag)\n",
    "        cols.append(col)\n",
    "\n",
    "    #Import leading/correlated currency\n",
    "    data_btc = pd.read_csv(\"BTCUSDT-1d.csv\", index_col=\"Open Time\")\n",
    "    data_btc = data_btc[[\"Close\"]]\n",
    "    data_btc.columns = [\"BTC Close\"]\n",
    "    data_btc[\"BTC return\"] = data_btc[\"BTC Close\"].div(data_btc[\"BTC Close\"].shift(1))\n",
    "    data_btc[\"BTC log_return\"] = np.log(data_btc[\"BTC return\"])\n",
    "\n",
    "    for lag in range(1,sub_lags+1):\n",
    "        col = \"btc lag{}\".format(lag)\n",
    "        data[col] = data_btc[\"BTC log_return\"].shift(lag)\n",
    "        cols.append(col)\n",
    "\n",
    "    #Merge target and correlated currencies info to a big dataframe\n",
    "    merged_df = pd.concat([data, data_btc], join=\"inner\", axis = 1)\n",
    "    merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_df.dropna(inplace=True)\n",
    "\n",
    "    merged_df.to_csv(\"merged.csv\")\n",
    "\n",
    "\n",
    "    #Nomarlized data\n",
    "    normalized_cols = []\n",
    "    for col in cols:\n",
    "        # print(\"Nomalizing col: {}\".format(col))\n",
    "        normalized_col = \"nom \" + col\n",
    "        array = merged_df[col].to_frame()\n",
    "        try:\n",
    "            my_scaler.fit(array)\n",
    "            merged_df[normalized_col] = my_scaler.transform(array)\n",
    "            normalized_cols.append(normalized_col)\n",
    "        except:\n",
    "            print(\"An exception occured\")\n",
    "\n",
    "    return merged_df, normalized_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_svm(data, cols, lap_number):\n",
    "    accuracy_scores =[]\n",
    "    clf = svm.SVC()\n",
    "    for i in range(0,lap_number):\n",
    "        print(\"Lap {}: \".format(i+1))\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data[cols],data.direction,test_size=0.3)\n",
    "        clf.fit(X = x_train, y = y_train)\n",
    "        print(\"Trained. Testing...\")\n",
    "        y_pred = clf.predict(X = x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        print(\"Accuracy Score: {}\".format(accuracy))\n",
    "    score_array = np.array(accuracy_scores)\n",
    "    mean = score_array.mean()\n",
    "    std = score_array.std()\n",
    "    print(\"Average: {}, Std: {}\".format(mean,std))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def prepare_and_run_svm(lags,sub_lags=0,vol_lags=0,scaler=0,lap_number=5):\n",
    "    print(\"Lags={}, Sub_lags={}, Vol_lags={}, Scaler={}\".format(lags,sub_lags,vol_lags,scaler))\n",
    "    (data, cols) = prepare_data(lags=lags,sub_lags=sub_lags,vol_lags=vol_lags,scaler=scaler)\n",
    "    (mean, std) = test_svm(data=data,cols=cols,lap_number=lap_number)\n",
    "    return(mean,std)\n",
    "\n",
    "def optimize_svm(args):\n",
    "\n",
    "    lag_range = range(1,args[0])\n",
    "    sub_lag_range = range(0,args[1])\n",
    "    vol_lag_range = range(0,args[2])\n",
    "    scaler_range = range(0,args[3])\n",
    "    lap_number = args[4]\n",
    "\n",
    "    combs = list(product(lag_range,sub_lag_range,vol_lag_range,scaler_range))\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for comb in combs:\n",
    "        (lags, sub_lags, vol_lags, scaler) = comb\n",
    "        (mean, std) = prepare_and_run_svm(lags=lags, sub_lags=sub_lags, vol_lags=vol_lags,scaler=scaler,lap_number=lap_number)\n",
    "        result = (lags,sub_lags,vol_lags,scaler,lap_number,mean,std)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lags = 12\n",
    "max_sub_lags = 6\n",
    "max_vol_lags = 3\n",
    "max_scaler = 3\n",
    "lap_number = 3\n",
    "\n",
    "args = [max_lags,max_sub_lags,max_vol_lags,max_scaler,lap_number]\n",
    "\n",
    "results = optimize_svm(args=args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lags=16, Sub_lags=0, Vol_lags=0, Scaler=0\n",
      "Lap 1: \n",
      "Trained. Testing...\n",
      "Accuracy Score: 0.5034246575342466\n",
      "Lap 2: \n",
      "Trained. Testing...\n",
      "Accuracy Score: 0.535958904109589\n",
      "Lap 3: \n",
      "Trained. Testing...\n",
      "Accuracy Score: 0.5136986301369864\n",
      "Lap 4: \n",
      "Trained. Testing...\n",
      "Accuracy Score: 0.4828767123287671\n",
      "Lap 5: \n",
      "Trained. Testing...\n",
      "Accuracy Score: 0.5154109589041096\n",
      "Average: 0.5102739726027397, Std: 0.01729367283966109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5102739726027397, 0.01729367283966109)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_and_run_svm(lags = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "068ea7741ce38d3fb9b274d22846bd3d9ade9aa2a6123ac7a263f7ca72b4296b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
